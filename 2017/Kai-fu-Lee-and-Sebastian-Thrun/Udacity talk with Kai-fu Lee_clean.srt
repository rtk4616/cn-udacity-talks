1
00:00:00,020 --> 00:00:03,610
优达学城 李开复专访
Udacity Talks with Kai-fu Lee

2
00:01:08,860 --> 00:01:09,880
你好
Nihao.

3
00:01:14,390 --> 00:01:20,480
真让人难以置信 我竟然能在北京的创新工厂
It is a unbelievable pleasure to be here in Beijing in Sinovation

4
00:01:20,480 --> 00:01:24,220
碰到我一直以来的好友
with my good friend and long time friend

5
00:01:24,600 --> 00:01:26,060
李开复博士
Dr. Kai-fu Lee.

6
00:01:26,970 --> 00:01:29,760
我一直都很喜欢中国
I always love to be in China,

7
00:01:29,940 --> 00:01:32,340
你也知道 中国估计是
because you know China is

8
00:01:32,360 --> 00:01:35,320
当今最有创造力的国家
perhaps the most innovative country today.

9
00:01:36,060 --> 00:01:39,510
全球的大科技公司
If you look at big Tech companies on the planet,

10
00:01:39,840 --> 00:01:41,790
十个中有四个是中国人创办的
four out of ten are Chinese,

11
00:01:42,400 --> 00:01:44,250
没有欧洲公司
there is no European company,

12
00:01:44,270 --> 00:01:46,410
没有南美公司
there is no southern American company,

13
00:01:46,690 --> 00:01:49,070
却有出色的中国公司
but there are amazing Chinese companies.

14
00:01:49,090 --> 00:01:50,890
感谢开复
Thanks to Kai-fu,

15
00:01:51,220 --> 00:01:54,380
开复是中国最具实力
whom I consider the most important

16
00:01:54,400 --> 00:01:58,120
最有才华的投资者
and most talented investor in all China.

17
00:01:58,340 --> 00:02:01,190
这永远是不平凡的一年的开始
This is always a fantastic start of a year;

18
00:02:01,210 --> 00:02:04,150
就算是参观这里的新兴企业也能令人振奋
it is always great to visit start-up companies here.

19
00:02:04,170 --> 00:02:07,210
我认为正是你们卓越的创新力和开拓力
I think you rival the Silicon Valley

20
00:02:07,330 --> 00:02:11,630
使得你们能与硅谷匹敌
in your ability to innovate and build an amazing business.

21
00:02:12,640 --> 00:02:14,420
我是这场对话的主持人
I'm here the moderator.

22
00:02:14,970 --> 00:02:18,270
1991年我遇到了开复
I've met Kai-fu in 1991,

23
00:02:18,430 --> 00:02:20,910
当时他在宾夕法尼亚州匹兹堡的
when he was in the faculty of a college in Pittsburgh

24
00:02:20,930 --> 00:02:24,200
卡内基梅隆大学任教
of Pennsylvania called Carnegie Mellon University.

25
00:02:24,660 --> 00:02:27,950
就在 5307 号
He was in 5307,

26
00:02:28,850 --> 00:02:30,180
一个有窗户的办公室
a window office,

27
00:02:30,420 --> 00:02:32,990
正好在我的无窗实验室旁边
right next to my windowless lab,

28
00:02:33,010 --> 00:02:35,630
我当时在那里当旁听生
where I was acting as a visiting student.

29
00:02:36,210 --> 00:02:39,620
开复是卡内基梅隆大学语音识别
Kai-fu was the preeminent researcher

30
00:02:39,790 --> 00:02:44,100
和游戏方面的杰出研究专家
on speech recognition and gaming playing at Carnegie Mellon.

31
00:02:44,120 --> 00:02:46,380
他既是恶魔又是上帝
He was a demon and god.

32
00:02:46,800 --> 00:02:49,740
我有幸和他谈了几次
I got a chance to talk to him a few times,

33
00:02:49,760 --> 00:02:53,300
当我把他的系统应用于卡内基梅隆大学的
when I adopted his system to one of the very first

34
00:02:53,320 --> 00:02:55,540
第一个语音可控设备之后
speech controllable device in Carnegie Mellon.

35
00:02:55,690 --> 00:02:56,560
最重要的是
And most of all,

36
00:02:56,580 --> 00:02:57,560
我见识到了李开复博士
over the years I have learnt

37
00:02:57,580 --> 00:03:00,550
这么多年来卓越的洞察力
Dr. Kai-fu Lee has an insight.

38
00:03:00,690 --> 00:03:02,440
他的内心
He is, in his heart,

39
00:03:02,680 --> 00:03:05,640
像一个16岁的孩子一样充满热情
as yound as a 16-year old, and as enthusiasm,

40
00:03:05,750 --> 00:03:08,090
又像一位500岁的老人一样睿智
but as wise as a 500-year old.

41
00:03:08,250 --> 00:03:09,500
欢迎开复
Welcome Kai-fu.

42
00:03:09,760 --> 00:03:11,120
谢谢 谢谢塞巴斯蒂安
Thank you. Thank you Sebastian.

43
00:03:11,140 --> 00:03:12,560
你太客气了
You are too kind.

44
00:03:12,580 --> 00:03:14,660
我可是塞巴斯蒂安的忠实粉丝
I'm a huge fan of Sebastian,

45
00:03:14,830 --> 00:03:20,370
因为他参与开发了谷歌、谷歌地图
for the work he has done at Google or for the maps

46
00:03:20,390 --> 00:03:25,550
谷歌自驾车、谷歌 X实验室和优达学城
as well as for the self-driving car and Google X and Udacity

47
00:03:25,570 --> 00:03:28,090
以及人们口耳相传的一些新事物
and some new things people rumor about.

48
00:03:28,470 --> 00:03:29,410
嘘…..
shhhhhhhh.

49
00:03:29,430 --> 00:03:31,450
我对他做的每件事情都有所关注
I follow up every thing he does.

50
00:03:31,770 --> 00:03:32,310
别说啦
don't talk of that.

51
00:03:32,330 --> 00:03:34,260
好的 秘密 秘密
OK. Secret, secret.

52
00:03:35,250 --> 00:03:37,030
我是这里的主持人
I am here the moderator.

53
00:03:37,140 --> 00:03:38,560
今天的主角是李开复
Today is all about Kai-fu Lee.

54
00:03:38,940 --> 00:03:40,880
我们每个月都会开展一期
This is a series of Udacity Talks

55
00:03:40,900 --> 00:03:42,880
优达学城专访
which we do every month or so,

56
00:03:43,040 --> 00:03:46,140
我们会邀请如李开复等知名人士
where we bring luminaries like Kai-fu Lee to everybody,

57
00:03:46,160 --> 00:03:47,790
来与大家（大部分是我们的学生）交流
most our students and among our students

58
00:03:47,810 --> 00:03:49,370
我选取了我们学生提出的一些问题
I picked up some questions

59
00:03:49,680 --> 00:03:51,520
与李开复互动
to interact with Kai-fu Lee.

60
00:03:51,540 --> 00:03:53,440
但在此之前 我想问您几个问题
But before that I want to ask you a few questions.

61
00:03:53,460 --> 00:03:55,750
我想回归本源
So I want to go back to the basics,

62
00:03:55,770 --> 00:03:59,820
因为在我看来 人们通常将您视为
because I think people will view as an amazing investor

63
00:03:59,840 --> 00:04:01,860
一名出色的投资者和商业领袖
and an amazing business leader in China.

64
00:04:01,880 --> 00:04:04,120
但是他们并不太了解您是怎么起家的
But they don't really know what you start out with.

65
00:04:04,290 --> 00:04:06,020
您曾经是一名黑客对吗?
You were a hacker right?

66
00:04:06,300 --> 00:04:07,320
对 是的
yes, I was.

67
00:04:07,340 --> 00:04:10,070
其实我曾经研究过你的代码
actually I worked on your code.

68
00:04:10,090 --> 00:04:10,570
哦？
oho!

69
00:04:10,590 --> 00:04:12,010
那个程序叫做“比尔”
and the program was called Bill

70
00:04:12,980 --> 00:04:14,500
它是游戏奥赛罗
it was Othello game.

71
00:04:14,770 --> 00:04:20,560
1984年
In 1984,

72
00:04:20,580 --> 00:04:24,180
我是卡内基梅隆大学的二年级研究生
I was a second-year graduate student at Carnegie Mellon.

73
00:04:24,550 --> 00:04:28,720
我教一群高中生编程
I taught a bunch of high school students how to program.

74
00:04:28,740 --> 00:04:30,750
其中一个学生真的很聪明
One of the students was really smart.

75
00:04:30,770 --> 00:04:32,720
他叫 Sanjoy Mahajan
His name is Sanjoy Mahajan.

76
00:04:32,850 --> 00:04:34,480
后来 我和他一起开发了
And then I worked with him to

77
00:04:34,500 --> 00:04:36,200
一个奥赛罗游戏程序
build an Othellogame program.

78
00:04:36,220 --> 00:04:38,380
然后我们说 我们可以把它
And then we said well we could make it

79
00:04:38,400 --> 00:04:39,810
变得像世界冠军一样棒
as good as world champion.

80
00:04:40,000 --> 00:04:42,620
所以我们接着一起研究
So we went ahead and he and I worked together.

81
00:04:42,640 --> 00:04:45,340
在卡内基梅隆大学 我们没有资金
At Carnegie Mellon we had no funding

82
00:04:45,360 --> 00:04:47,950
只是为了好玩
just for fun developed this program

83
00:04:47,970 --> 00:04:49,920
这个程序很快就被开发出来了
that was very fast

84
00:04:49,940 --> 00:04:52,610
成了世界冠军比尔
and did the world champion called Bill.

85
00:04:52,630 --> 00:04:54,390
为什么叫比尔呢？
why it was called Bill?

86
00:04:54,410 --> 00:04:57,570
因为《奥赛罗》是一个
I called it Bill because Othello is a play

87
00:04:57,590 --> 00:04:59,160
莎士比亚戏剧
written by Shakespeare

88
00:04:59,180 --> 00:05:01,490
莎士比亚的姓是威廉
and Shakespeare's first name is William

89
00:05:01,510 --> 00:05:04,330
而比尔是威廉的简称
and Bill is the short for William.

90
00:05:04,880 --> 00:05:08,640
这段不可思议的历史值得为世人所知
this is an untold history but the world should know.

91
00:05:08,660 --> 00:05:11,640
我们谈过谷歌阿尔法围棋
We talked about Google Alpha Go

92
00:05:12,720 --> 00:05:17,040
它去年打败了世界围棋冠军
beating the world champion in Go last year.

93
00:05:17,060 --> 00:05:19,930
大约在20年前
In 1997, about 20 years ago,

94
00:05:19,950 --> 00:05:22,890
卡内基梅隆大学的后代"深蓝"
Deep Blue, an offspring of Carnegie Mellon,

95
00:05:22,910 --> 00:05:24,400
战胜了 Gary Kasparov
beat Gary Kasparov

96
00:05:24,420 --> 00:05:26,700
当时的国际象棋世界冠军
who was then considered the world champion in chess,

97
00:05:26,720 --> 00:05:28,200
尽管存在一些争议
though there were debates about it.

98
00:05:28,220 --> 00:05:33,400
但在此之前
But before that, Samuel the checkers game,

99
00:05:34,330 --> 00:05:37,130
塞缪尔的西洋跳棋程序击败了一名
there was a great success in Carnegie Mellon that was

100
00:05:37,150 --> 00:05:39,930
真正的跳棋大师
a strong authentic player was beaten by a virtual program.

101
00:05:39,950 --> 00:05:40,780
那是您的杰作吗？
Is that yours?

102
00:05:40,800 --> 00:05:41,930
那是一个微型程序
that was a micro program.

103
00:05:41,950 --> 00:05:43,520
所以在 AI 游戏的历史上
so you were a reigning champion

104
00:05:43,540 --> 00:05:46,010
您一度是个卫冕冠军
in the history of AI games

105
00:05:46,030 --> 00:05:50,090
这是另一个非常受欢迎的游戏
well it was another very popular game.

106
00:05:50,280 --> 00:05:52,000
我的确因为它在人工智能方面
I did get a publication

107
00:05:52,020 --> 00:05:53,640
获得了一些知名度
in Artificial Intelligence.

108
00:05:53,660 --> 00:05:54,180
太棒了
that was great.

109
00:05:54,200 --> 00:05:55,490
看你的代码
I looked at your code

110
00:05:55,510 --> 00:06:00,120
就能领略你精彩的编程方式
and I can tell the way you encoded was just brilliant.

111
00:06:00,140 --> 00:06:02,570
这是一个生成你自己的代码的程序
It was a program to generate your own code.

112
00:06:02,590 --> 00:06:04,490
一段能生成代码的代码
It was a code generating code.

113
00:06:04,680 --> 00:06:06,280
这是一个预编程
it's a pre-programing.

114
00:06:06,300 --> 00:06:08,120
基本上在计算机科学方面
Basically in computer science,

115
00:06:08,820 --> 00:06:11,390
人们希望最大限度地减少繁琐的计算量
you want to minimize a massive amount of computing

116
00:06:11,410 --> 00:06:14,200
因而创建了可以查找的表格
so you create tables that you could look up

117
00:06:14,220 --> 00:06:16,940
并快速处理事务
and rapidly do things fast.

118
00:06:16,960 --> 00:06:18,410
据我了解
As I understand it,

119
00:06:20,130 --> 00:06:22,690
CMU 开发了一个新的德州扑克智能系统
CMU has a new Texas Hold'em poker player,

120
00:06:22,710 --> 00:06:25,700
我认为这也有着巨大的潜力
I think they also generate a large space.

121
00:06:25,720 --> 00:06:27,780
我觉得你30年前的开发
I think there are going to be footsteps

122
00:06:27,800 --> 00:06:29,500
给了他们一些启发
that you started 30 years earlier.

123
00:06:29,520 --> 00:06:30,300
他们学习了你的经验
That kind of learning.

124
00:06:30,320 --> 00:06:31,060
是的
Yes.

125
00:06:31,610 --> 00:06:35,510
然后你转到了一个叫 SPHINX 的程序
Then you moved on to something called SPHINX,

126
00:06:35,670 --> 00:06:38,610
这可是世界上第一个真人发音
which was the world very first speaker voice

127
00:06:38,630 --> 00:06:40,060
和语音识别系统
and speech recognition system.

128
00:06:40,080 --> 00:06:41,030
你是怎么做到的？
How did that happen?

129
00:06:41,780 --> 00:06:43,600
我去了卡内基梅隆大学
well I went to Carnegie Mellon

130
00:06:43,620 --> 00:06:51,780
遇到了我们的系主任
and I met with our department chair,

131
00:06:58,030 --> 00:07:02,850
尼克尔·哈博曼
Nichole Harborman.

132
00:07:02,870 --> 00:07:05,850
尼克尔说十分欢迎开复
Nicole said Kai-fu welcome

133
00:07:05,870 --> 00:07:07,950
我说您对我有什么期望吗？
and I said what do you expect from me?

134
00:07:08,210 --> 00:07:11,900
他说我希望你在你所研究的领域创作一篇
He said I want you to write the best thesis

135
00:07:11,920 --> 00:07:12,780
最棒的论文
in your area

136
00:07:12,800 --> 00:07:14,650
我希望你无论做什么研究
and I want you to be the best in the world

137
00:07:14,670 --> 00:07:16,140
都是世界上最棒的
in whatever thesis you do.

138
00:07:16,490 --> 00:07:18,100
我说这真的很难
I said that is really hard

139
00:07:18,120 --> 00:07:19,290
我不大可能是最棒的
and I cannot be the best.

140
00:07:19,310 --> 00:07:21,330
他说你可以选择一个较窄的领域
He said you can pick a narrower area

141
00:07:21,350 --> 00:07:22,360
你就能做到
and you will be the best.

142
00:07:22,380 --> 00:07:24,980
语言识别这种狭窄的区域？
it doesn't matter a narrow area like speech recognition?

143
00:07:25,000 --> 00:07:26,010
谁在乎呢?
who care

144
00:07:26,030 --> 00:07:26,940
真是个糟糕的选择 呵呵
what a bad choice. hehehe

145
00:07:26,960 --> 00:07:28,540
他说 "要在你的领域做出最好的研究成果
he just said, "write the best thesis in your area,

146
00:07:28,560 --> 00:07:31,770
否则你就白来卡内基梅隆了"
otherwise this is not what Carnegie Mellon is about".

147
00:07:31,910 --> 00:07:34,290
之后 我去和拉吉·瑞迪
Then I went to work with Raj Reddy on

148
00:07:34,910 --> 00:07:36,380
一起研究语音识别
speech recognition.

149
00:07:36,540 --> 00:07:40,890
拉吉建议我使用
Raj was suggesting that I should use Expert System

150
00:07:40,910 --> 00:07:41,870
专家系统
for speech recognition.

151
00:07:45,040 --> 00:07:47,090
嗯 我非常尊重拉吉
well, I respect Raj greatly.

152
00:07:47,240 --> 00:07:52,580
那时候这个技术既流行
At that time, it was a very popular technology

153
00:07:52,600 --> 00:07:54,010
又容易上手
and it is plausible.

154
00:07:54,030 --> 00:07:57,440
一个叫 Victor Zhu 的人编写了一些新颖的程序
A guy named Victor Zhu writes special programs.

155
00:07:57,460 --> 00:08:00,430
所以拉吉说 哎 我们来效仿 Victor Zhu 吧
So Raj said well let's just emulate the Victor Zhu.

156
00:08:00,550 --> 00:08:02,940
所以我们干了一年
So I did that for one year

157
00:08:02,960 --> 00:08:05,190
的确发表了一些成果
and we really published what we did

158
00:08:05,210 --> 00:08:07,090
我发现我们走到了死胡同
and I saw it was an deadend

159
00:08:07,110 --> 00:08:08,310
再走下去是没用的
and it wasn't going to work.

160
00:08:08,470 --> 00:08:10,340
所以我不得不面对一个问题
So I had to face the issue,

161
00:08:10,360 --> 00:08:13,360
我是否真的挑战了我的博士生导师
do I actually challenge my Ph.D advisor

162
00:08:13,380 --> 00:08:14,990
尝试了不同的东西
and try something different

163
00:08:15,170 --> 00:08:16,750
或者按照他所说的
or do what he says

164
00:08:16,770 --> 00:08:21,460
研究了我的系主任说的不要做的事情
and graduate what my department chair said not to do.

165
00:08:21,480 --> 00:08:22,940
所以我挣扎了一下 说
So I struggled a bit and said

166
00:08:22,960 --> 00:08:25,710
"额 我真的想在这个领域里
"well, I really wanted to be the best thesis

167
00:08:25,730 --> 00:08:27,730
有所成就
in this sub-category

168
00:08:27,940 --> 00:08:30,700
但我不知道怎么改进"
but I didn't know how to make it better",

169
00:08:30,720 --> 00:08:33,900
所以幸运的是 我遇到了彼得·布朗
so it was lucky that I met Peter Brown,

170
00:08:34,090 --> 00:08:39,150
另一个在 IBM 学习的 CMU 学生
who was another CMU student studying at IBM,

171
00:08:39,170 --> 00:08:42,210
他回来告诉了我隐马尔可夫模型
so he came back and told me the hidden Markov models

172
00:08:42,380 --> 00:08:44,480
隐马尔可夫模型在当时
hidden Markov models at that time

173
00:08:44,500 --> 00:08:46,340
可是一个神秘的新事物
had been a cryptic new thing.

174
00:08:46,500 --> 00:08:47,870
是的 没人知道它
it was. No one knew about it.

175
00:08:47,890 --> 00:08:49,590
它不是专家系统
It wasn't Expert System.

176
00:08:49,610 --> 00:08:50,760
没有用于机器学习的代码规则
It has no rules of code in it for machine learning.

177
00:08:50,780 --> 00:08:51,610
对
right.

178
00:08:51,630 --> 00:08:55,020
令人惊奇的是 你有一台机器
It was fascinating that you had a machine

179
00:08:55,040 --> 00:08:58,640
向它丢进一些数据 它会学习一些东西
that you could throw data and it learns what A and B and C.

180
00:08:58,660 --> 00:09:02,100
它是现在深度学习的简洁版
It is kind of a simple version of deep learning today.

181
00:09:02,120 --> 00:09:04,340
所以用了一个周末以后
So I implemented it over a weekend

182
00:09:04,360 --> 00:09:06,370
我发现它太神奇了
and I saw that it was amazing.

183
00:09:06,390 --> 00:09:07,710
我试过 Toy 数据
I tried to Toy Data.

184
00:09:07,730 --> 00:09:09,340
那应该有用
I saw that should work.

185
00:09:09,590 --> 00:09:15,940
我基本上会喝很多咖啡
I basically drank a lot of coffee

186
00:09:15,960 --> 00:09:18,810
去找导师
and went to my advisor and said

187
00:09:18,830 --> 00:09:21,540
说：“拉吉 我喜欢语音识别
"Raj, I love speech recognition

188
00:09:21,560 --> 00:09:23,700
但我不会去用专家系统”
but I'm not gonna use Exper System"

189
00:09:24,140 --> 00:09:25,760
他说 你想做什么
and he said what do you want to do.

190
00:09:25,780 --> 00:09:27,770
我说我想用隐马尔可夫模型
I said I gonna use hidden Markov models

191
00:09:27,920 --> 00:09:30,310
虽然那不一定有用
I am not sure that would work

192
00:09:30,330 --> 00:09:32,100
我们争论了一会
and we debated for a while.

193
00:09:32,120 --> 00:09:34,490
最后 他认识到我很固执
In the end, he saw that I was stubborn.

194
00:09:34,510 --> 00:09:37,170
所以他说了一些话 这些话让我铭记终生
So he said something I remember my whole life.

195
00:09:37,190 --> 00:09:39,860
他说 “开复 我不同意你的观点
He said, "Kaifu, Idon't agree with you,

196
00:09:39,880 --> 00:09:40,870
但我支持你”
but I support you".

197
00:09:41,580 --> 00:09:45,240
我认为这不仅是教授做过的
That I think was not the only most generous thing

198
00:09:45,260 --> 00:09:46,690
最宽厚的事
a professor could do,

199
00:09:46,710 --> 00:09:49,940
而且是一种令人赞叹的领导力
but also an amazing style of leadership.

200
00:09:50,080 --> 00:09:52,030
如果你想领导聪明的人
If you want to lead smart people,

201
00:09:52,050 --> 00:09:53,730
不要告诉他们要做什么
you cannot tell them what to do,

202
00:09:53,750 --> 00:09:55,150
而要引导他们发挥自己的热情
you have to lead them to use their passion.

203
00:09:55,330 --> 00:09:55,700
谢谢你
Thank you.

204
00:09:55,720 --> 00:09:57,970
老实说 拉吉 如果你在看专访
Honestly, Raj if you were watching,

205
00:09:57,990 --> 00:09:58,980
记得我们爱你
we love you.

206
00:09:59,390 --> 00:10:00,720
你对卡内基梅隆的贡献
You work more for Carnegie Mellon

207
00:10:00,740 --> 00:10:01,380
比任何人都多
than anybody else.

208
00:10:01,400 --> 00:10:02,860
当我来到卡内基梅隆
I had been in the same theme

209
00:10:02,880 --> 00:10:04,660
我一直研究同一个课题
when I came to the Carnegie Mellon

210
00:10:04,680 --> 00:10:05,740
从来没有和你直接合作过
I had never worked with you directly,

211
00:10:05,760 --> 00:10:07,120
和其他人合作
I worked with somebody else.

212
00:10:07,360 --> 00:10:09,390
但我们俩的办公室是紧挨着的
But I was literally next door to your office.

213
00:10:10,000 --> 00:10:14,840
彼得·布朗是一个有信誉影响力的人
Peter Brown is a person who had credit impact.

214
00:10:15,590 --> 00:10:17,930
彼得很低调
Peter is very low profile.

215
00:10:18,060 --> 00:10:19,300
不过你要是去谷歌搜他
But if you google him

216
00:10:19,320 --> 00:10:23,050
你会发现他在 IBM 语音组工作
you will see that he worked in the IBM speech group.

217
00:10:23,070 --> 00:10:24,930
他和鲍勃·默瑟做了第一个
He and Bob Mercer did the first

218
00:10:24,950 --> 00:10:27,910
统计机器翻译项目
statistical machine translation.

219
00:10:28,090 --> 00:10:30,350
神奇的是 那时候 每个人翻译的时候
It was fascinating at that time everybody

220
00:10:30,370 --> 00:10:32,320
都死抠语法
translated by syntax,

221
00:10:32,340 --> 00:10:35,930
导致翻译的版本差强人意
translated never quite what you want.

222
00:10:35,950 --> 00:10:39,330
彼得和鲍勃说 我们用包模型
And Peter and Bob said is let's use the Bag Model,

223
00:10:39,350 --> 00:10:41,550
让我们把单词全部整合到一起
let's take every word and do a mapping

224
00:10:41,570 --> 00:10:43,280
来做两种语言里的单词的一一映射吧
of the word into another language.

225
00:10:43,420 --> 00:10:45,150
我们再用另一种语言模型
Let's take another language model

226
00:10:45,170 --> 00:10:48,910
把新的包放到一句话里
to put the new bags into one sentence.

227
00:10:49,060 --> 00:10:52,690
语言学的东西是很玄乎的
The linguist thing is heretical;

228
00:10:52,710 --> 00:10:53,800
你怎么可能做到这些呢？
how did you possibly do that?

229
00:10:53,820 --> 00:10:54,967
这种做法把某物
This regards

230
00:10:54,987 --> 00:10:56,150
当成了一种语言
Something like a language.

231
00:10:56,170 --> 00:10:57,400
它们更有用
They work better.

232
00:10:57,420 --> 00:10:58,510
所以他们用这个
So they used this.

233
00:10:58,530 --> 00:11:01,740
我记得加拿大的国会辩论
I remember the Canadianparliamentary debates,

234
00:11:01,760 --> 00:11:03,190
由于辩论内容直接从英文
because they were literally translated

235
00:11:03,210 --> 00:11:04,430
翻译成了法文
literally from English to French.

236
00:11:04,450 --> 00:11:06,360
需要一个巨大的语料库 对吧？
This is huge corpus of data, right?

237
00:11:06,380 --> 00:11:10,550
是的 因为当时没有很多双语资料
Yes. Becauseat that time there was not much bilingual data.

238
00:11:10,570 --> 00:11:14,030
加拿大国会一直都有能力
Canada was a country where the parliament

239
00:11:14,050 --> 00:11:16,510
直接产出高质量的译文
has always a direct translation of very high quality one.

240
00:11:16,530 --> 00:11:17,760
所以他们做到了这些
So they did that.

241
00:11:17,780 --> 00:11:19,680
您是世界上第一位
you are one of the first machine learning people

242
00:11:19,700 --> 00:11:20,440
机器学习者
in the world.

243
00:11:20,460 --> 00:11:20,800
对
Yes.

244
00:11:20,820 --> 00:11:23,050
他们就像你在卡内基梅隆研究语音识别一样
as you were at Carnegie Mellon for speech recognition

245
00:11:23,070 --> 00:11:24,760
只是做了不同的语言翻译
but they did different language translation.

246
00:11:24,780 --> 00:11:27,390
这是世界上第一台应用这个原理的机器
The first machine in the world to put the principle

247
00:11:27,520 --> 00:11:30,480
接着它推动了谷歌和其他人打造了一流的
that then drove Google and others to build their amazing

248
00:11:30,640 --> 00:11:31,660
语言翻译引擎
language translation engines.

249
00:11:31,680 --> 00:11:34,150
没错 IBM 有很多天才
that's right. IBM has amazing people.

250
00:11:34,170 --> 00:11:35,290
而作为一个旁观者
And, as a side note,

251
00:11:35,310 --> 00:11:36,680
鲍勃·默瑟和彼得·布朗
Bob Mercer and Peter Brown

252
00:11:36,700 --> 00:11:39,330
加入了 Resonance Technology
went off to join Resonance Technology,

253
00:11:39,450 --> 00:11:42,240
它的对冲基金可能拥有
which was probably the highest return

254
00:11:42,490 --> 00:11:44,300
世界上最高的回报定量
quantitative hedge fund in the world.

255
00:11:44,320 --> 00:11:47,660
每年都有30-50％的回报
It's like 30-50% return every year.

256
00:11:47,680 --> 00:11:49,240
是的 他们有两个基金
Yes. They have two funds.

257
00:11:49,260 --> 00:11:51,270
他们自己的钱的基金的回报是 71%
For their own money they made 71%

258
00:11:52,580 --> 00:11:55,060
全世界其他人的钱的基金回报是 30-50％
for the rest of the world they made 30-50%.

259
00:11:55,680 --> 00:11:56,940
他们做得很好
They did very very well.

260
00:11:56,960 --> 00:12:00,600
哈哈 我自己的投资只有5％的收益
I only make 5% in my daily trading activities.

261
00:12:01,100 --> 00:12:05,440
然后你去了微软
Then you went to Microsoft

262
00:12:05,460 --> 00:12:08,340
当我问你的时候 你提到的第一件事
and when I asked you about the very first thing

263
00:12:08,360 --> 00:12:10,960
是你解雇了70名语言学家
you mention is you fired 70 linguists.

264
00:12:11,820 --> 00:12:15,660
你声称你的名誉将毁于一旦
You claim you fame to fire.

265
00:12:15,890 --> 00:12:17,510
关键不是我的名誉
it is not my fame.

266
00:12:17,530 --> 00:12:19,380
其实那是个非常困难的时期
Actually it was a very difficult period.

267
00:12:19,400 --> 00:12:22,020
因为我最初去微软
Because I went to Microsoft initially to

268
00:12:22,040 --> 00:12:23,990
是建立微软中国研究院
found Microsoft Research China,

269
00:12:24,010 --> 00:12:25,460
他们有大量的资金
which had huge amount of funds

270
00:12:25,480 --> 00:12:28,220
雇了很多人去做有趣的事情
and hired a lot of people to do fun things.

271
00:12:28,240 --> 00:12:30,360
总是件有趣的事 雇人
It is always fun to hire people

272
00:12:30,380 --> 00:12:32,510
召集像您这样的人才
and bring people who are like you

273
00:12:32,530 --> 00:12:34,620
赋予他们自由并与他们一起工作
and give them freedom and work with them.

274
00:12:34,640 --> 00:12:36,870
那就是我们当时在微软中国研究院做的事
That was we did in Microsoft Research China.

275
00:12:36,890 --> 00:12:37,687
这也是我们今天在创新工厂
That is what we do today

276
00:12:37,707 --> 00:12:39,390
合资企业做的事
in Sinovation Ventures.

277
00:12:39,410 --> 00:12:43,270
但是不幸的是 大概是因为我做得太好了
But unfortunately, I guess I did good enough jobs,

278
00:12:43,290 --> 00:12:45,450
比尔·盖茨说 “开复很不错
said Bill Gates, "well Kai-fu is pretty good,

279
00:12:45,470 --> 00:12:47,170
我们把他拉回来
let's pull him back to

280
00:12:47,190 --> 00:12:50,460
给他一些有问题的团队
and let's give him some problematic teams

281
00:12:50,480 --> 00:12:51,670
看看他会怎么做”
and see what he does."

282
00:12:51,690 --> 00:12:54,050
给我的其中一支团队
And one of the teams he asked me to lead

283
00:12:54,070 --> 00:12:55,630
是自然语言小组
was the natural language group,

284
00:12:55,790 --> 00:13:01,290
叫 NLG 这个团队一共大概有 110 人
known as NLG. It was a team for about 110 people.

285
00:13:01,310 --> 00:13:02,530
我猜都是博士 对吧？
PhD I guess, right?

286
00:13:02,550 --> 00:13:05,830
110 个人基本上全是博士
110, mostly PhD.

287
00:13:07,270 --> 00:13:09,340
其中70％是语言学家
70% of them are linguists,

288
00:13:10,300 --> 00:13:12,630
但不一定是计算语言学家
not necessarily computational linguists,

289
00:13:12,650 --> 00:13:14,000
也不一定懂计算
some are computational, some are not,

290
00:13:14,020 --> 00:13:16,440
基本上他们没有写过任何代码
but basically they didn't write any code

291
00:13:16,460 --> 00:13:18,170
也不懂算法
they didn't understand algorithms.

292
00:13:18,190 --> 00:13:21,100
但是他们确实
But they did work very hard to

293
00:13:21,120 --> 00:13:24,500
非常努力地完善每个英文句子
make every English sentence parcel as well as possible

294
00:13:24,520 --> 00:13:27,160
还写了一些检测语法错误的规则
and they wrote rules to detect grammar errors.

295
00:13:27,180 --> 00:13:28,560
所以出来的产品不算差
So the product isn't bad.

296
00:13:28,640 --> 00:13:30,310
如果你用 Microsoft Word
If you use Microsoft Words,

297
00:13:30,470 --> 00:13:32,410
语法检查功能也还行
the grammar checker isn't bad.

298
00:13:32,430 --> 00:13:34,540
他们修复了相当多的错误
They fix a fair amount of errors.

299
00:13:34,740 --> 00:13:38,210
但比尔说“开复 带着这110个人
But Bill says "Kai-fu, take these 110 people

300
00:13:38,230 --> 00:13:43,080
去研究自然语言对话技术吧”
and turn them into a natural language dialog technology".

301
00:13:43,360 --> 00:13:44,630
我跟团队谈了谈
I talked to the team

302
00:13:44,650 --> 00:13:45,870
了解了这个技术
and I looked to the technology

303
00:13:45,890 --> 00:13:47,510
然后说我没办法做这个
and I said there was no way

304
00:13:47,530 --> 00:13:51,300
因为更多的语言学家不能解决问题
because the future cannot possibly be more linguistics

305
00:13:51,320 --> 00:13:53,200
需要更多的统计学家
and there should be more statistics.

306
00:13:53,340 --> 00:13:55,020
更准确地说
Just to put it correctly.

307
00:13:55,040 --> 00:13:57,800
你曾经带领过70位世界级的语言学家
You took 70 world class linguists

308
00:13:57,820 --> 00:14:01,900
而他们供职于最受推崇的微软公司
who were hired by the most revered company - Microsoft.

309
00:14:01,920 --> 00:14:02,410
是的
Yes.

310
00:14:05,320 --> 00:14:09,040
你觉得在这个小统计公式里
And you felt the little statistic formula,

311
00:14:09,060 --> 00:14:11,760
其中有抽象的模式和数据
there was abstruct patterns and data

312
00:14:11,780 --> 00:14:14,390
源于70名顶尖的专家 是吗？
that would be the 70 super smart experts. Yes?

313
00:14:14,410 --> 00:14:16,200
是的
Yes, I did.

314
00:14:16,220 --> 00:14:21,730
他们没有重新研究语法检查
They didn't re-implement the grammar checker

315
00:14:21,750 --> 00:14:23,850
而是投入到了其他任何任务上
but on any other tasks yes they did.

316
00:14:23,990 --> 00:14:26,160
所以回到数据上来说
so machine learning, back to the data,

317
00:14:26,180 --> 00:14:28,860
你第一个捕捉到了机器学习
you were one of the very first striking eyes to witness

318
00:14:28,880 --> 00:14:31,280
能击败人类专家的地方
where she beats human experts.

319
00:14:31,510 --> 00:14:32,750
是的 不过当然
Yes, but of course

320
00:14:32,770 --> 00:14:35,270
微软有很多人非常擅长机器学习
Microsoft has a lot of people who are very good

321
00:14:35,290 --> 00:14:37,730
比如
in machine learning like.

322
00:14:37,750 --> 00:14:39,320
我不是唯一的那个
I wasn't alone.

323
00:14:39,340 --> 00:14:41,050
但不幸的是
But the group I inherited

324
00:14:41,070 --> 00:14:43,400
我接手的那个团队第一步走错了
unfortunately had a wrong first step.

325
00:14:43,420 --> 00:14:46,500
要想解雇70个人是很难的
It was very difficult to fire 70 people

326
00:14:46,520 --> 00:14:48,420
这会对他们的家人产生极大的影响
and that had an impact to their family

327
00:14:48,440 --> 00:14:50,810
他们不理解我的决定
and they didn't understand my decision

328
00:14:50,990 --> 00:14:52,500
我们争论了很多次
and we had a lot of fighting

329
00:14:52,520 --> 00:14:53,920
他们还向比尔抱怨
and they complained to Bill.

330
00:14:53,940 --> 00:14:55,780
还好我们终于完成了项目构建
But we ended up the building,

331
00:14:55,900 --> 00:14:58,430
如果你用 Windows Support
if you use the Windows Support today,

332
00:14:58,450 --> 00:15:01,400
你可以手动输入你的问题
you type a question to say you have a problem

333
00:15:01,420 --> 00:15:04,500
而如何修复这个问题
and how to fix something that was based

334
00:15:04,520 --> 00:15:06,260
最终是基于我构建的系统
eventually on the system I built.

335
00:15:06,280 --> 00:15:08,110
它的确很有用也很稳健
And it works. It is robust.

336
00:15:08,300 --> 00:15:10,340
这是个智能系统
It is a very smart system.

337
00:15:10,360 --> 00:15:12,700
不可能在语言系统的
It couldn't have been possible

338
00:15:12,720 --> 00:15:14,720
框架下构建起来
to have been built under linguist system.

339
00:15:14,740 --> 00:15:15,600
的确令人佩服
it's quite amazing,

340
00:15:15,620 --> 00:15:18,900
因为你是我所在领域的杰出科学家之一
because you are one of the eminent scientists in my field.

341
00:15:18,920 --> 00:15:23,080
人们专程来卡内基梅隆只为了和你握手
People come to Carnegie Mellon to shake your hand.

342
00:15:23,100 --> 00:15:23,790
不 没那回事
No, not at all.

343
00:15:23,810 --> 00:15:26,030
之后 您当了经理
and then you became a manager

344
00:15:26,050 --> 00:15:28,690
做统计相关业务
and you did statistic business,

345
00:15:28,710 --> 00:15:30,750
这个转变还比较大
which is a quite shift of career.

346
00:15:30,970 --> 00:15:34,210
您后来去了一个搜索引擎公司
And then you moved to a search engine company,

347
00:15:34,350 --> 00:15:35,290
不过名字我忘了
whose name I forgot.

348
00:15:35,310 --> 00:15:35,860
哈哈哈
Hahaha.

349
00:15:35,880 --> 00:15:37,220
能再告诉我们叫什么名字吗？
what's the name again

350
00:15:37,870 --> 00:15:38,590
谷歌
Google.

351
00:15:41,100 --> 00:15:42,680
那么继续.
Then press forward now,

352
00:15:42,700 --> 00:15:45,510
你自己有一些资金
you have your own fund,

353
00:15:46,670 --> 00:15:50,780
一组公司
a mount of money, you have a portfolio of companies,

354
00:15:50,930 --> 00:15:52,650
个人孵化中心
your incubation center

355
00:15:52,670 --> 00:15:53,930
是你令高效的人工智能
and you make efficient artificial intelligence

356
00:15:53,950 --> 00:15:55,040
成为迄今为止最轰动的事
the biggest thing ever,

357
00:15:55,180 --> 00:15:58,020
但你同时也会投资 我知道
but you also fund, I know,

358
00:15:58,040 --> 00:16:00,050
我们已经展示了
we already showed girls

359
00:16:00,070 --> 00:16:03,690
一些事业有成的女孩
who have aspiring career.

360
00:16:03,710 --> 00:16:04,730
发生了什么？
What's happening?

361
00:16:05,260 --> 00:16:06,340
嗯
well,

362
00:16:06,360 --> 00:16:09,960
我在2009年创立了创新工厂合资公司
I founded Sinovation Ventures in 2009.

363
00:16:09,980 --> 00:16:12,460
这不是"罪恶的欢呼" 而是"标志的欢呼"
it is not "sin ovation" but "sign ovation"

364
00:16:12,480 --> 00:16:13,770
嗯 我称之为"标志的欢呼"
well I call it "sign ovation",

365
00:16:13,790 --> 00:16:14,860
因为我们没犯罪
because we don't sin.

366
00:16:14,880 --> 00:16:16,010
呵呵
hehe

367
00:16:16,030 --> 00:16:19,280
我们没什么罪 我们尽量不这样
Well, we don't sin very much. We try not to.

368
00:16:19,650 --> 00:16:22,030
我以为这是"罪恶的欢呼"呢
I thought it was "sin ovation".

369
00:16:22,210 --> 00:16:24,050
也许是因为发音很像？
easy to pronounce, perhaps?

370
00:16:24,070 --> 00:16:26,040
但 Sino 是中国的意思
But Sino is like China.

371
00:16:26,060 --> 00:16:27,830
对 我知道
It is good. I know.

372
00:16:28,340 --> 00:16:31,150
当我们创办创新工厂合资公司时
when we started the Sinovation Ventures,

373
00:16:31,170 --> 00:16:33,910
我们想做所有的技术投资
we wanted to do all tech investing.

374
00:16:34,150 --> 00:16:38,270
但当时大部分中国技术是模仿国外的
But at that time, much of tech in China were still copycats.

375
00:16:38,880 --> 00:16:42,980
在这个阶段 人们想投资
It wasn't at a stage where you could really find to fund

376
00:16:43,000 --> 00:16:46,180
一个AI公司、科技公司、数据库公司
an AI company or a tech company or a database company

377
00:16:46,200 --> 00:16:47,020
或其他公司是很难的
or something.

378
00:16:47,940 --> 00:16:50,240
因为市场规模大
Because the market is large

379
00:16:50,390 --> 00:16:53,670
产品需求量大
and the need for product is large

380
00:16:53,690 --> 00:16:55,680
但创造力
but the degree of creativity

381
00:16:56,250 --> 00:16:58,800
和知识深度不够
and the depth of knowledge wasn't there.

382
00:16:58,970 --> 00:17:00,470
所以我们不得不说 好吧
So we had to say, ok,

383
00:17:00,490 --> 00:17:03,570
我们拿了投资者的钱就得赚钱
we took investors money we got to make money

384
00:17:03,590 --> 00:17:06,520
所以我们要投资任何能赚钱的地方
so we gonna invest whatever makes money.

385
00:17:07,260 --> 00:17:09,190
我们擅长
What we are good at is

386
00:17:09,380 --> 00:17:12,130
技术方面
things that are propelled by technology.

387
00:17:12,150 --> 00:17:15,200
所以我们把钱用在了
So we would invest in anything that fits

388
00:17:15,220 --> 00:17:19,780
手机、AI和任何其他热点上
the exponential wave of mobile, AI, any other wave.

389
00:17:19,800 --> 00:17:23,160
所以我们投资了一些不寻常的公司
So we invested in some very unusual companies

390
00:17:23,180 --> 00:17:25,630
比如 SNH48
like the SNH48.

391
00:17:25,650 --> 00:17:29,420
所以你用美金还是人民币投资？
so you take American money or take Chinese money?

392
00:17:29,440 --> 00:17:30,460
我们两个都用
we take both.

393
00:17:30,690 --> 00:17:33,460
SNH48 不算一个真正意义上的技术公司吧
SNH48 is not an exact tech company.

394
00:17:34,360 --> 00:17:36,530
你知道他们有一些技术
There is some tech, you know

395
00:17:37,190 --> 00:17:41,410
这是个众包的大数据公司
It's a crowd sourcing, big data company.

396
00:17:41,430 --> 00:17:42,590
别不好意思 这公司很棒
Don't be ashamed, it is great.

397
00:17:42,910 --> 00:17:46,340
是的 我真的很惊讶
Yes. I was really surprised

398
00:17:46,360 --> 00:17:47,930
塞巴斯蒂安竟然知道他们
Sebastian knew about them.

399
00:17:47,950 --> 00:17:51,460
我不知道你们当中谁知道 SNH48
I don't know few of your guys know SNH48.

400
00:17:51,480 --> 00:17:52,490
这已经是一种投资了
That is already an investment.

401
00:17:52,510 --> 00:17:53,940
我们是第一批投资者
We are the first investors.

402
00:17:53,960 --> 00:17:58,700
因为我们看到 观看这些电视节目
Because we saw that watching these shows on TV

403
00:17:58,720 --> 00:18:01,130
只会产生大量的收入
was only going to generate so much revenue,

404
00:18:01,150 --> 00:18:04,900
如果你能让人们参与投票和花钱
if you could have people participate and vote and pay.

405
00:18:04,920 --> 00:18:06,920
这是个更大的机遇
That is much bigger opportunity.

406
00:18:06,940 --> 00:18:09,230
那就是我们的理念
That was the concept we have.

407
00:18:09,250 --> 00:18:11,530
我们都看电视
we all watch TV and

408
00:18:11,550 --> 00:18:12,550
和游戏节目
their game shows,

409
00:18:12,570 --> 00:18:16,080
美国的人才都聚集在了一起
American talents, come together in one world.

410
00:18:16,100 --> 00:18:19,350
我有个问题
Here is a question I wondered about.

411
00:18:19,370 --> 00:18:20,250
当我还是孩子的时候
When I was a kid.

412
00:18:20,270 --> 00:18:25,830
我隐约感觉日本会统治世界
I was kind of known that Japan would rule the world,

413
00:18:25,850 --> 00:18:30,440
日本会成为动态随机存取记忆体
like, Japan became the epicenter for DRAM

414
00:18:30,460 --> 00:18:35,030
半导体行业和超强性能 CPU 的技术中心
and for most semi-conductor and very exceptional CPUs.

415
00:18:35,050 --> 00:18:38,690
日本的投资不可磨灭
And Japan made an investment which cannot disappear.

416
00:18:39,390 --> 00:18:40,960
而过去十年
And the last ten years,

417
00:18:40,980 --> 00:18:42,960
我们知道中国引领了世界
we have known the China has taken off the world.

418
00:18:42,980 --> 00:18:45,570
而且和日本有区别
And there is a difference.

419
00:18:46,160 --> 00:18:47,040
日本与中国的
What's the difference in the

420
00:18:47,060 --> 00:18:48,670
成功秘诀有什么区别？
recipe between Japan and China?

421
00:18:49,600 --> 00:18:51,480
呵呵 我不太了解日本
Well I'm not an expert in Japan.

422
00:18:51,500 --> 00:18:54,090
但是我的一个朋友最近
But one of my friends recently

423
00:18:54,110 --> 00:18:55,830
接手了一家日本公司
took over a Japanese company

424
00:18:55,980 --> 00:18:59,700
他描述了他看到的一些日本人的优缺点
and he described the good and bad things he saw.

425
00:18:59,860 --> 00:19:02,810
优点是注意细节
The good things are attention to detail.

426
00:19:02,970 --> 00:19:08,560
他们注重极小的技术问题
Extreme value of tiny technical issues

427
00:19:08,580 --> 00:19:12,810
努力确保事情完美无缺
and making sure things are done flawlessly and beautifully.

428
00:19:13,360 --> 00:19:20,040
缺点在于日本文化不是比较饥饿的文化
The problem is that it is not a very hungry culture.

429
00:19:20,210 --> 00:19:22,880
人们不对抗 只是努力工作
People don't fight and work extremely hard.

430
00:19:22,900 --> 00:19:25,350
他们的努力程度不及中国人
They work hard but not as hard as in China.

431
00:19:25,510 --> 00:19:27,310
而且 他们比较注重阶级
And also, it is very hierarchical.

432
00:19:27,560 --> 00:19:29,600
我朋友称 你知道董事会
So he described in a board meeting,

433
00:19:29,620 --> 00:19:31,880
有四个级别
you know there are four layers of tables,

434
00:19:31,900 --> 00:19:34,820
当有问题要讨论的时候
and when issues came up for discussion,

435
00:19:34,840 --> 00:19:37,570
高级副总裁会转向副总裁
the senior VP would turn around to their VPs

436
00:19:37,590 --> 00:19:39,070
问他们答案
and say what is the answer to that.

437
00:19:39,090 --> 00:19:40,840
副总裁转向董事
The VP would turn around to the directors,

438
00:19:40,860 --> 00:19:42,050
董事转向经理
and director to the managers,

439
00:19:42,070 --> 00:19:44,740
经理转向普通员工
manager would turn around to the individual contributor

440
00:19:44,760 --> 00:19:48,010
然后他们会叫某人去做事和传播信息
then they would call somebody and information propagates up.

441
00:19:48,130 --> 00:19:49,240
这就像一个我听过的游戏
it is like a hear game

442
00:19:49,260 --> 00:19:50,430
你们一直重复这个词
where you repeat the word

443
00:19:50,450 --> 00:19:53,370
直到最后你会问这是原来那个词吗？
and you gonna say this is the same word?

444
00:19:53,390 --> 00:19:56,030
是的 我认为中国的大公司
yes. I think large companies in China

445
00:19:56,050 --> 00:19:58,960
建立了等级文化
build a hierarchical culture

446
00:19:58,980 --> 00:20:01,190
管理层并没有创造自己的价值
where management didn't add their value.

447
00:20:01,210 --> 00:20:03,030
等等 你们中国有很多大公司
but, hold out, you have large companies,

448
00:20:03,050 --> 00:20:06,600
有阿里巴巴、腾讯、百度、京东
you have Alibaba, Tencent, Baidu, JD.

449
00:20:06,620 --> 00:20:08,260
这些公司怎么避免这种情况？
How do these companies avoid it?

450
00:20:08,600 --> 00:20:10,980
以阿里巴巴为例
I will take Alibaba as an example.

451
00:20:11,000 --> 00:20:13,280
我认为马云的聪明之处
I think Jack Ma is a brilliant,

452
00:20:13,300 --> 00:20:16,120
在于他重塑公司的方式
in the way he reinvents the company.

453
00:20:16,390 --> 00:20:20,100
任何不断壮大的公司都会遇到一个问题
Any company that gets big would have a problem of

454
00:20:20,120 --> 00:20:22,320
聪明人感觉自己的能力达到了上限
smart people feeling like reach their ceiling,

455
00:20:22,340 --> 00:20:24,480
好像没有进步空间了
like cannot go up anymore.

456
00:20:24,500 --> 00:20:27,680
所以马云把他的公司分成……
So Jack organizes his company in,

457
00:20:27,700 --> 00:20:31,660
我不太记得具体数字….. 25个团体
I don't how many, 25 groups,

458
00:20:31,680 --> 00:20:34,580
每个团体都是一个独立的公司
each of which is an independent company

459
00:20:34,600 --> 00:20:37,450
每个公司都有一个顶峰
with a pinnacle that is a truly

460
00:20:37,470 --> 00:20:39,840
是其所在区域真正的十亿美元的公司
billion-dollar company in its zone

461
00:20:39,860 --> 00:20:43,860
有负责管理经理的CEO
with CEO taking responsibility accountable for the managers

462
00:20:43,880 --> 00:20:45,170
马云让经理轮岗
and he rotates them

463
00:20:45,190 --> 00:20:48,220
每个人都觉得他自己是CEO
but each person feels like they are a CEO.

464
00:20:48,240 --> 00:20:51,190
他们觉得 就好像 如果你是财务总监
They feel like, it is like, if you are a financial CEO,

465
00:20:51,210 --> 00:20:53,460
你不会想离开去另一家公司
you don't want to leave and do to another company,

466
00:20:53,480 --> 00:20:56,400
因为你本来就管理着一个大公司
because you are running as big a company as you can imagine.

467
00:20:56,560 --> 00:21:01,280
然而 所有25家公司都有一致的文化
Yet, all the 25 companies have a consistent culture.

468
00:21:01,390 --> 00:21:04,600
所以他也能引领和
So he is also able to lead

469
00:21:04,620 --> 00:21:07,230
复制一点阿里巴巴的发展策略
and replicate a little bit Alibabas.

470
00:21:07,250 --> 00:21:10,260
这使他们相对灵活
That keeps them relatively nimble,

471
00:21:10,280 --> 00:21:12,650
专注 遵循一贯的文化
focused yet consistent culture.

472
00:21:12,880 --> 00:21:14,540
我认为也许
That kind of,

473
00:21:14,760 --> 00:21:17,280
Alpabet 是这种模式下的一个尝试
I think maybe Alpabet is an attempt to this.

474
00:21:17,300 --> 00:21:22,550
Alpabet和伯克希尔·哈撒韦公司
Alfabet and Berkshire Hathaway

475
00:21:22,570 --> 00:21:24,360
有相同之处
have a same flavor of it.

476
00:21:24,380 --> 00:21:27,410
是的 所以我认为我们需要创新企业模式
yes. So I think we need to innovate in corporate model,

477
00:21:27,430 --> 00:21:28,910
阿里巴巴、Alpabet
Alibaba, Alpabet,

478
00:21:28,930 --> 00:21:31,060
伯克希尔·哈撒韦就是这样做的
Berkshire Hathaway are ones that have.

479
00:21:31,080 --> 00:21:32,640
我想也许日本大公司
I think maybe the Japanese companies

480
00:21:32,660 --> 00:21:33,710
还做不到这个
when are large cannot do that.

481
00:21:33,730 --> 00:21:38,110
人工智能真是太有趣了
interesting interesting. Artificial intelligence.

482
00:21:38,130 --> 00:21:38,580
当然
Yes.

483
00:21:38,600 --> 00:21:42,890
你曾经在卡内基梅隆讲的一个话题
a topic that you started at Carnegie Mellon.

484
00:21:42,910 --> 00:21:46,110
正好也是我当时谈论的话题
I was also being around and in the same topic.

485
00:21:47,080 --> 00:21:49,850
你当时正全身心地投入工作
You have dedicated whole of your energy to it.

486
00:21:49,870 --> 00:21:52,970
工作于该地区的一家内部创业公司
You worked in a in-house start-up company in the area.

487
00:21:52,990 --> 00:21:54,790
能说说它为什么对你这么重要么
Tell about it. Why is important.

488
00:21:55,540 --> 00:21:57,450
嗯 我觉得AI很重要
well, I think AI is important.

489
00:21:57,470 --> 00:21:59,480
因为它能改变一切
Because it will change everything.

490
00:21:59,500 --> 00:22:01,610
它比手机要重要得多
It is much more important than mobile.

491
00:22:01,790 --> 00:22:03,210
手机是一个新设备
Mobile is a new devise.

492
00:22:03,230 --> 00:22:03,950
也的确很重要
It's very important.

493
00:22:03,970 --> 00:22:05,200
这是一种能将我们
It's a new device

494
00:22:05,220 --> 00:22:06,840
大多数人联系在一起的新设备
that connects most of us.

495
00:22:06,860 --> 00:22:10,790
但AI不仅仅关乎人类 还影响着商业
But AI is not just to people, but to business.

496
00:22:10,810 --> 00:22:14,420
它将重塑商业 令它从传统转向
It is going to reinvent businesses from traditional

497
00:22:14,440 --> 00:22:17,100
娱乐和互联网
to entertainment to internet.

498
00:22:17,120 --> 00:22:20,410
每个公司 每一件事都会因此受到影响
Every company, every thing, is impacted.

499
00:22:20,540 --> 00:22:22,140
塞巴斯蒂安比任何人
Sebastian, more than any body,

500
00:22:22,160 --> 00:22:23,790
都了解自动车辆
knows about autonomous vehicles.

501
00:22:23,810 --> 00:22:25,920
它将会改变交通
That is going to change the future of

502
00:22:25,940 --> 00:22:27,690
运输的未来
transportation and delivery.

503
00:22:27,950 --> 00:22:31,030
想想财务、一切与金融相关的
You think about finance, everything financial,

504
00:22:31,050 --> 00:22:36,540
银行、保险、交易、证券、投资
banking, insurance, trading, security, investment.

505
00:22:36,560 --> 00:22:38,090
他们都有硬伤
They are all built wrong.

506
00:22:38,310 --> 00:22:41,430
做这些工作的人并不擅长这些
The people doing these jobs are not good at it,

507
00:22:41,450 --> 00:22:43,410
因为总有一些磕磕绊绊
because there are a number of crunching jobs.

508
00:22:43,430 --> 00:22:45,170
人永远不可能和机器一样
People can never be machines.

509
00:22:45,190 --> 00:22:48,030
所以大多数这些人会被机器所取代
So most of these people would be replaced by machines,

510
00:22:48,050 --> 00:22:51,400
机器不仅更聪明 更准确
who are not only smarter, more accurate,

511
00:22:51,420 --> 00:22:54,210
也不会累 不会情绪化
but also they don't get tired, they are not emotional.

512
00:22:54,230 --> 00:22:58,320
机器将在全世界大大提升效率
This will create a huge amount of efficiency in the world.

513
00:22:58,340 --> 00:22:59,600
这就是我们要研究它的原因
That's why we work on it

514
00:22:59,620 --> 00:23:01,790
因为它具有巨大的经济价值
because it has so much economic value,

515
00:23:01,810 --> 00:23:05,370
而且我还可以解释其AI
but also because another role I can play

516
00:23:05,390 --> 00:23:08,230
对中国的潜在影响
is to explain its potential impact of AI in China

517
00:23:08,250 --> 00:23:11,710
因为它会冲击所有领域
because this will disrupt all the areas.

518
00:23:11,730 --> 00:23:12,190
你知道的
You know.

519
00:23:12,210 --> 00:23:14,100
我们已经在教育系统
The education system we have it wrong.

520
00:23:14,120 --> 00:23:15,900
银行系统上犯了错
The banking system is wrong.

521
00:23:15,920 --> 00:23:19,180
考虑到AI的冲击
And all these things, because of the AI disruption,

522
00:23:19,200 --> 00:23:22,640
我们需要为下一代做好准备
we need to prepare our next generations to be ready,

523
00:23:22,660 --> 00:23:25,550
因为如果他们接受的教育
because if they are being educated

524
00:23:25,570 --> 00:23:29,480
使得他们做重复性的工作
to become skilled in some repetitive work,

525
00:23:29,500 --> 00:23:31,480
就会被AI取而代之
it would be replaced by AI.

526
00:23:31,500 --> 00:23:34,160
他们需要考虑如何
They need to look at how to

527
00:23:34,180 --> 00:23:36,820
规划自己的职业和教育
plan their careers and education before that.

528
00:23:36,840 --> 00:23:40,160
另一个问题 我和你的角度一样
another question, which I have the same position as yours.

529
00:23:40,180 --> 00:23:42,130
但是我想听听你的回答
But I want to hear your answer.

530
00:23:42,320 --> 00:23:45,240
我们中间有75％的人在办公室做
75% of us work in office jobs,

531
00:23:45,550 --> 00:23:48,590
基本上是重复的工作
in basically repetitive jobs.

532
00:23:48,610 --> 00:23:49,860
所以你刚才告诉我
So you just told me

533
00:23:49,880 --> 00:23:52,110
每个人都会被电脑所取代
that each of them will be replaced by computer.

534
00:23:52,130 --> 00:23:52,940
当然
of course.

535
00:23:52,960 --> 00:23:54,390
这些人会怎么样？
what gonna happen to these people?

536
00:23:54,980 --> 00:23:57,560
好的 有几种可能的猜测
well, there are several possible speculations.

537
00:23:58,290 --> 00:23:59,780
我猜优达学城没有
I guess it comes out that Udacity hits

538
00:23:59,800 --> 00:24:00,500
培养这类人（稍微）
none of these (sort of).

539
00:24:01,200 --> 00:24:03,170
那是 如果你第一次这样做
that yes. If you first do that.

540
00:24:03,190 --> 00:24:05,610
再教育 的确是这样
Reeducation, yes.

541
00:24:06,080 --> 00:24:08,960
首先 不要太恐慌
Well, first of all. Not to panic too much.

542
00:24:08,980 --> 00:24:10,960
因为这些强大的AI机器
Because there will be taxes generated

543
00:24:10,980 --> 00:24:13,300
会产生税收
by these amazing AI machines

544
00:24:13,320 --> 00:24:15,620
税收会给人们带来收益
and taxed will feed the people.

545
00:24:15,640 --> 00:24:18,490
所以民主是社会主义的
so democracy would be socialist.

546
00:24:18,660 --> 00:24:21,470
我的意思是企业所得税可能是70％
I mean corporate gains tax might be like 70%,

547
00:24:21,490 --> 00:24:22,450
而不是30％
not 30%.

548
00:24:22,470 --> 00:24:25,750
你我都必须缴纳很多税
you and I have to pay a lot of taxes.

549
00:24:25,770 --> 00:24:27,360
但没有人会饿
But no one would go hungry.

550
00:24:27,380 --> 00:24:28,780
这就解决了一个大问题
So that solves the big problem.

551
00:24:28,800 --> 00:24:30,310
但那些被替代的人做什么呢
But what do they do.

552
00:24:30,430 --> 00:24:36,660
我认为他们应该想想一些
I think one is they think about

553
00:24:36,680 --> 00:24:39,050
需要深刻创意才能的工作
do they have deep creative talent.

554
00:24:39,070 --> 00:24:41,690
显然 有的人得到了一个机器人程序后
Obviously, someone got a program to robots

555
00:24:41,710 --> 00:24:43,460
成为了下一个毕加索
and becomes the next Picasso.

556
00:24:44,040 --> 00:24:50,140
第二 他们能否做AI不能做的事情
Secondly, can they take on something that AI cannot do.

557
00:24:50,310 --> 00:24:52,230
还有很多事情 AI做不了
There are still a lot of things that AI cannot do.

558
00:24:52,250 --> 00:24:56,810
你明白的 艺术、电影、幽默
You know. Art, movies, humor,

559
00:24:57,790 --> 00:25:01,780
手工艺、园艺
crafts, gardening.

560
00:25:02,180 --> 00:25:03,340
所有这些事情
All those things.

561
00:25:03,360 --> 00:25:05,910
都需要大量劳力
There are plenty of jobs that remain there.

562
00:25:06,390 --> 00:25:09,830
服务业的劳力需求最大
The largest quantity will be in services,

563
00:25:09,990 --> 00:25:12,970
例如 打扫、做饭
such as, you know cleaning, kitchen,

564
00:25:12,990 --> 00:25:15,880
照顾孩子和老人
taking care of the kids, taking care of elderly.

565
00:25:16,090 --> 00:25:20,610
而我认为今天的服务工作在社会上
And I think service jobs today don't get enough

566
00:25:20,860 --> 00:25:23,530
没有得到足够的重视和尊重
attention and respect in the society

567
00:25:23,550 --> 00:25:25,080
我们必须做出改变
and I think we have to change that.

568
00:25:25,210 --> 00:25:27,530
我认为日本其实是一个非常好的例子
I think Japan actually is a very positive example of that.

569
00:25:27,550 --> 00:25:28,850
如果你去日本
If you go to Japan,

570
00:25:28,870 --> 00:25:34,390
会看到那些努力做饭或切寿司的人
people who work so hard to make a bowl or to cut sushi,

571
00:25:34,410 --> 00:25:37,190
受到了神一样的待遇
they are treated like gods.

572
00:25:37,410 --> 00:25:39,270
但现在有些公司基本上
but there are now companies that basically

573
00:25:39,290 --> 00:25:40,680
都有做食物的机器人
have robots that make your food,

574
00:25:40,700 --> 00:25:42,390
叫做加利福尼亚的
that is called in California

575
00:25:42,410 --> 00:25:43,820
你可能见过
which you might know that

576
00:25:43,840 --> 00:25:45,130
在手机上订购食物
you order your food in your phone

577
00:25:45,150 --> 00:25:46,990
进入商店时食物已经准备好了
and when you enter the store, that is already ready

578
00:25:47,010 --> 00:25:48,970
准备食物的可能是机器人
and robots can prepare food for you.

579
00:25:49,110 --> 00:25:50,110
但是我们必须相信
but we have to believe.

580
00:25:50,130 --> 00:25:51,150
我是个美食家
I'm a foodie,

581
00:25:51,170 --> 00:25:54,830
我坚信人类会做出更好的食物
so. I firmly believe that humans will make better food

582
00:25:54,850 --> 00:25:56,430
如果你用心了
and if you put in your love,

583
00:25:56,450 --> 00:25:59,260
所有的日本寿司厨师用心了
that all Japanese sushi chefs put in,

584
00:25:59,280 --> 00:26:00,710
我觉得食物会变得更好吃
I think the food would taste better

585
00:26:00,730 --> 00:26:02,500
因为人们有更多的技能...
because there are more skills…

586
00:26:02,520 --> 00:26:04,980
来吧 像你说的
come on, there is a data-crunching job,

587
00:26:05,000 --> 00:26:06,240
这里有一个数据压缩的工作
in your own words.

588
00:26:06,800 --> 00:26:09,910
有台机器可以制作一千块寿司
Like, a machine can make a thousand pieces of Sushi.

589
00:26:09,930 --> 00:26:10,930
这不仅仅是切块 对吧？
well it is not just about cutting, right?

590
00:26:10,950 --> 00:26:13,110
它包括准备、选材
It includes preparing, choosing.

591
00:26:13,130 --> 00:26:15,440
我想浪漫一点
I'd like to be romantic a little bit

592
00:26:15,460 --> 00:26:17,590
认为还应该有服务行业
and think there are service jobs.

593
00:26:17,610 --> 00:26:20,550
你才是对的 我错了
And I even you are right and I'm wrong.

594
00:26:20,570 --> 00:26:21,410
呵呵
hehe

595
00:26:22,390 --> 00:26:26,900
虽然服务行业一直不受人们尊重
but even if service jobs cannot be revered,

596
00:26:26,920 --> 00:26:27,910
但是我们仍要努力
we have to try,

597
00:26:27,930 --> 00:26:30,850
毕竟大多数人将来从事的还是服务业
because most of the population will be service jobs.

598
00:26:30,870 --> 00:26:33,520
如果我们能够尊重这些人的话
If we treat these people with respect,

599
00:26:33,540 --> 00:26:36,420
还会觉得这些工作是不合需要？
if we feel these jobs are undesirable,

600
00:26:36,550 --> 00:26:41,250
还会把服务人员视为二等公民吗？
if we treat service people as second class citizens,

601
00:26:41,270 --> 00:26:42,660
不会
it won't.

602
00:26:42,680 --> 00:26:43,250
当然
I agree.

603
00:26:43,270 --> 00:26:44,510
不管怎么说
whenever we can,

604
00:26:44,530 --> 00:26:46,360
为了使服务行业得到更多人的尊重
to make service jobs more respectable,

605
00:26:46,380 --> 00:26:48,230
是时候发明一些新的东西了
maybe we have to invent some.

606
00:26:48,250 --> 00:26:50,790
比尔?盖茨在他最近的文章中
Bill gates, in his recent article,

607
00:26:50,810 --> 00:26:53,620
谈到了同情心  是这样吗？
talked about compassion. Right?

608
00:26:53,640 --> 00:26:56,770
也许机器人可以替代人类来照顾
Maybe the people displaced by robots can take care of

609
00:26:56,790 --> 00:27:00,490
流离失所的老人、残疾人
the elderly, take care of the handicapped,

610
00:27:01,310 --> 00:27:04,240
托儿所的孩子
one-on-one nursery homes.

611
00:27:04,260 --> 00:27:07,550
也许这些工作不能快速产生经济价值？
And these are not jobs generating immediate economic value?

612
00:27:07,570 --> 00:27:09,840
但是 他们酝酿出的是爱
But they generate love and they

613
00:27:09,860 --> 00:27:11,380
并帮助创建人与人之间的联系
create human to human connection.

614
00:27:11,400 --> 00:27:12,890
这是一个伟大的愿景
that is a great great vision.

615
00:27:12,910 --> 00:27:16,020
开复 我很喜欢跟你聊天
So, Kai-fu, I love talking to you.

616
00:27:16,040 --> 00:27:17,520
天哪！ 我真的学到了很多
My god. I learned so much.

617
00:27:19,040 --> 00:27:21,810
我知道的就是大概有
One of the things I will do is on behave of

618
00:27:21,830 --> 00:27:23,520
七十万学生
probably seven hundred thousand students

619
00:27:23,540 --> 00:27:25,080
正在收看直播
watching on-line right now,

620
00:27:25,190 --> 00:27:26,620
谁来给我们提问
who sent us questions,

621
00:27:26,640 --> 00:27:29,140
在节目开始之前
I guess I have piece of paper

622
00:27:29,160 --> 00:27:30,930
我准备了一张纸
that I got just before the show

623
00:27:30,950 --> 00:27:33,190
我想要把学生的问题带给你
and I love ask the students' questions to you,

624
00:27:33,210 --> 00:27:35,270
因为对优达学城的学生来说
because you have such a great situation

625
00:27:35,290 --> 00:27:37,260
这是一个非常重要的时刻
to Udacity's students at this point.

626
00:27:37,400 --> 00:27:39,470
有一个叫Josie的学生
There is a person who called Josie

627
00:27:39,490 --> 00:27:41,040
她的问题是关于人工智能（AI）的
and she is asking about AI,

628
00:27:41,060 --> 00:27:44,080
她想要问你在当今社会
and she asks in your opinion, what is the most mature

629
00:27:44,100 --> 00:27:48,530
AI技术中最成熟的应用是什么？
application of AI technology in the industry today?

630
00:27:48,670 --> 00:27:49,600
今天？
today?

631
00:27:51,500 --> 00:27:54,450
最成熟的要数搜索引擎了
Well the most mature that would have to be search engines.

632
00:27:54,470 --> 00:27:56,840
因为我们每天都在用它
Because we use it everyday.

633
00:27:56,860 --> 00:27:58,710
在搜索引擎后面
Behind the search engine,

634
00:27:58,960 --> 00:28:01,780
不仅有匹配字段来帮助获取词语
not only there is a matching words to get words,

635
00:28:01,800 --> 00:28:04,750
在点击后就会出现你想要了解的东西
but there is a learning what things people click on.

636
00:28:04,890 --> 00:28:07,280
它有一定的知识层级
It has a hierarchy of knowledge,

637
00:28:07,390 --> 00:28:12,730
就像当你去谷歌 去百度时
like when you go to Google, go to Baidu,

638
00:28:12,750 --> 00:28:14,290
我要用你的名字作为例子
and I will use your name as an example,

639
00:28:14,310 --> 00:28:17,070
如果你去谷歌搜索谁是 巴斯蒂安?特伦
if you go to Google to search who is Sebastian Thrun,

640
00:28:17,090 --> 00:28:18,840
就会出来有关你的介绍
your biography comes out

641
00:28:18,860 --> 00:28:21,050
因为它有一个和你的信息
because it has a knowledge representation,

642
00:28:21,170 --> 00:28:23,030
相匹配的知识表示
it has a matching,

643
00:28:23,050 --> 00:28:25,570
当你点击该结果时
and when you click on that result,

644
00:28:25,590 --> 00:28:28,580
就会加强搜索并得到更多的正确答案
it will get reinforced and get more answers correctly.

645
00:28:28,780 --> 00:28:30,890
在我看来 搜索引擎已经存在了
So I think search engine

646
00:28:30,910 --> 00:28:33,950
很长时间 并且经证实
has been around for a long time and proven,

647
00:28:33,970 --> 00:28:36,990
我觉得这是最成熟的例子了
I think that's certainly the most mature example.

648
00:28:37,660 --> 00:28:41,880
正如你所言
as you are visionary,

649
00:28:42,290 --> 00:28:45,330
实际上在这样一个亚马逊和新设备及移动设施
how will search engines look ten years from now

650
00:28:45,350 --> 00:28:48,530
引领潮流的时代 搜索引擎将如何应对
in the age of Amazon Echo and new devices

651
00:28:49,280 --> 00:28:51,030
接下来的这十年？
and mobile, actually.

652
00:28:52,490 --> 00:28:55,100
实际上搜索引擎算不上最成熟的技术
well, search engines actually are not very smart,

653
00:28:55,120 --> 00:28:56,020
你有没有想过？
do you think about it?

654
00:28:56,040 --> 00:28:57,080
你问一个问题
You ask one question;

655
00:28:57,100 --> 00:28:59,390
它会给出十种答案
it gives you you know ten mission answers.

656
00:28:59,530 --> 00:29:01,350
通常你会看到一个页面有十条搜索结果
Usually you look at ten in one page,

657
00:29:01,370 --> 00:29:03,200
即使你忽略第一页
even you ignore the first page,

658
00:29:03,220 --> 00:29:04,650
还是会给你十种答案
give you ten answers,

659
00:29:04,670 --> 00:29:06,330
这是一个非常棘手的问题
it's a very tricky interface.

660
00:29:06,350 --> 00:29:11,780
因为我们不知道正确答案是在哪个页面上
Because we, when the right answer is on that page

661
00:29:11,800 --> 00:29:13,130
而对于这些你本不了解的东西
and something you don't know

662
00:29:13,150 --> 00:29:14,020
你是否该会感到开心呢？
if you are happy,

663
00:29:14,040 --> 00:29:15,940
即使是弹出答案了 也许只有50-60％的
even through the pop-up answers only right

664
00:29:15,960 --> 00:29:17,800
可能性是你想要的
maybe 50-60% at the time.

665
00:29:18,180 --> 00:29:20,770
所以我想十年后
So I think ten years from now,

666
00:29:20,790 --> 00:29:23,770
我想要搜索引擎能够理解你的问题
I like the search engine to understand what you say

667
00:29:23,790 --> 00:29:24,560
并给出正确答案
and give you the answer,

668
00:29:24,580 --> 00:29:26,620
而这个答案正好是你要找的
one answer that you are looking for.

669
00:29:26,780 --> 00:29:28,330
所以你正在建立一个"聊天插件"
so you are building a "chat bar" right now,

670
00:29:28,350 --> 00:29:29,730
你想要在新的搜索引擎上
is that you want to be detective

671
00:29:29,750 --> 00:29:31,120
进行探测吗？
in terms of new search engine?

672
00:29:31,550 --> 00:29:32,490
你指的是哪个系统？
what system?

673
00:29:32,510 --> 00:29:35,200
你正在Sinovations建立
so you are building a "chat bar" right now here,

674
00:29:35,220 --> 00:29:36,780
一个"聊天插件"
in Sinovations,

675
00:29:37,220 --> 00:29:40,180
因此你是想...
that you want to be…

676
00:29:40,350 --> 00:29:41,240
呵呵 聊天插件？
hehe, Chat Bar.

677
00:29:41,260 --> 00:29:43,580
起来像是一种搜索引擎 还是...
is it like a search engine or…

678
00:29:43,600 --> 00:29:46,220
我们说过谈话不会涉及到绝密内容
we said we won't talk about your secret project,

679
00:29:46,240 --> 00:29:48,150
所以还是来谈谈其他吧
so we should talk about my secret project either.

680
00:29:48,170 --> 00:29:50,070
抱歉 我晓得了
sorry.I got it.

681
00:29:50,090 --> 00:29:51,950
下一个问题来自Ted
The next question is from Ted.

682
00:29:53,740 --> 00:29:56,570
我们都觉得AI技术是非常强大的
We all agree that AI is very powerful already.

683
00:29:56,590 --> 00:30:00,270
但Ted抱怨说
But Ted complains, he says at present,

684
00:30:00,550 --> 00:30:03,510
语音识别软件不能完全准确地
I cannot fully depend on voice recognition software to

685
00:30:03,530 --> 00:30:08,040
检测到他所说的话 尤其是中文
accurately detect what I'm saying, especially, in Chinese,

686
00:30:08,060 --> 00:30:11,130
最好是普通话  这是为什么？
it should be mandarin. Why is that?

687
00:30:13,160 --> 00:30:16,150
是这样的 语音识别系统
well, the speech recognition system

688
00:30:16,170 --> 00:30:18,000
最近已经有所改善
has been improved a lot lately.

689
00:30:18,180 --> 00:30:21,150
如果你使用的是kedaxunfei的
So if you use the newest version from

690
00:30:21,870 --> 00:30:25,520
最新版本  ifly科技或百度
kedaxunfei, ifly tech, or baidu,

691
00:30:25,540 --> 00:30:27,340
它的准确性应该是相当高的
the accuracy should be quite high.

692
00:30:28,380 --> 00:30:30,600
一个原因可能是由于你的口音
One possible reason is your accent.

693
00:30:30,620 --> 00:30:33,830
但我觉得当今大多数中国人的口音
But I kind of doubt it because most Chinese people's accent

694
00:30:33,850 --> 00:30:35,880
还是可以的
is pretty moderate today.

695
00:30:37,340 --> 00:30:38,140
这个叫Ted的
the name is Ted.

696
00:30:38,160 --> 00:30:40,270
可能是一个正在学习中文的美国人
He might be an American who is learning Chinese.

697
00:30:40,290 --> 00:30:44,510
这样啊 那么请不要讲外语
well, then. Don't speak foreign language.

698
00:30:45,240 --> 00:30:48,300
可能的话 我会给你们两个解释
It could be. I'll answer twice.

699
00:30:48,320 --> 00:30:50,010
如果作为一个中国人
If you are Chinese,

700
00:30:50,030 --> 00:30:52,330
在语音识别时遇到问题
who has trouble with Chinese speech recognition,

701
00:30:52,470 --> 00:30:56,210
我觉得可能是你故意这样说的
my answer is you'd probably talk deliberately.

702
00:30:56,340 --> 00:30:58,480
语音识别系统的是
The way the speech recognition system works,

703
00:30:58,500 --> 00:31:00,650
针对自然语言的培训
is that they are trained on natural speech,

704
00:31:00,670 --> 00:31:02,200
所以你应该这么说
so you should talk like this.

705
00:31:02,470 --> 00:31:03,900
相反地 你知道
If instead, you know,

706
00:31:03,920 --> 00:31:05,580
如果当你和一个小宝宝说话的时候
when you talk to a little baby, right,

707
00:31:05,600 --> 00:31:07,430
你说喝牛奶
you say drink your milk,

708
00:31:07,450 --> 00:31:08,320
他会说什么？
he will say what?

709
00:31:08,340 --> 00:31:10,400
喝！你！牛奶！
Drink, Your, Milk!

710
00:31:10,770 --> 00:31:13,040
如果你这样做的话 语音识别就会扰乱
If you do that, the speech recognition will get confused,

711
00:31:13,060 --> 00:31:16,470
声音太大 就会造成麻烦
you are too loud, you cause trouble.

712
00:31:16,490 --> 00:31:18,450
所以不要故意这样说话
So don't talk deliberately.

713
00:31:18,470 --> 00:31:22,490
也不要抠字眼
Don't try to talk like, try to emphasize words.

714
00:31:22,510 --> 00:31:24,860
语速就保持你跟其他人
Just talk like you talk to another person

715
00:31:24,880 --> 00:31:26,540
说话那样
at the same pace and speed.

716
00:31:26,560 --> 00:31:29,290
可能这就是原因吧
That's probably the likely reason.

717
00:31:30,350 --> 00:31:34,490
而且 当你切换输入法（IME）
And also, when try to dictate to a IME,

718
00:31:34,510 --> 00:31:36,070
或敲打键盘时
or the keyboard,

719
00:31:36,510 --> 00:31:38,050
它一开始也不是英文的
it doesn't do English

720
00:31:38,070 --> 00:31:40,490
而且不可能一下子就出现你要输入的词语
and it doesn't do proper names very well.

721
00:31:40,630 --> 00:31:42,070
所以你要非常小心
So you got to be careful.

722
00:31:42,090 --> 00:31:45,010
你懂得  "我想要写一封信"
You know. "I'd like a letter to",

723
00:31:45,030 --> 00:31:48,170
并且输入"李开复" 是这样吗？
and stop and type in "Kai-fu Lee". Right?

724
00:31:48,190 --> 00:31:50,610
因为它的字典中没有李开复
Because it doesn't have Kai-fu Lee in its dictionary.

725
00:31:50,630 --> 00:31:55,170
所以 当你敲打的词语是不常见的或英语时
So when you do proper names that are unusual or English,

726
00:31:55,190 --> 00:31:56,150
为什么不说话呢？
don't you speech,

727
00:31:56,170 --> 00:31:57,600
你可以停下来输入语音
you pause and type it in,

728
00:31:57,830 --> 00:32:00,410
或者你将语音添加到它的词汇组里
or you teach it to add it to its vocabulary.

729
00:32:00,630 --> 00:32:04,080
如果你和Ted一样是个外国人
If Ted, you are foreigner,

730
00:32:04,100 --> 00:32:06,660
那么 你正好多了个中文老师
well, get a Chinese teacher

731
00:32:06,680 --> 00:32:08,390
来帮助你提高中文水平
and improve your Chinese.

732
00:32:09,430 --> 00:32:12,630
Sally是优达学城的一名学生 她来自美国
Sally is a Undacity student from the United States.

733
00:32:12,650 --> 00:32:13,860
她问了一个非常有趣的问题
She asked a very interesting question,

734
00:32:13,880 --> 00:32:16,840
我认为你是世界上唯一能够给出答案的人
I think you are the single in the world to answer,

735
00:32:17,110 --> 00:32:19,920
那就是根据你在硅谷多年的经历
which is, you have been in Silicon Valley a lot,

736
00:32:20,210 --> 00:32:22,300
你觉得硅谷的AI技术发展
what's in your opinion the difference between

737
00:32:22,320 --> 00:32:25,670
与中国的AI技术发展
AI technology development in Silicon Valley

738
00:32:25,690 --> 00:32:27,130
有什么区别呢？
and here in China?

739
00:32:27,630 --> 00:32:29,620
好的 这是一个很好的问题
ok, it's a good question.

740
00:32:29,960 --> 00:32:36,080
在我看来 在美国的这样一个大环境下
I think AI technology in Silicon Valley tends to be,

741
00:32:36,230 --> 00:32:40,170
硅谷的AI技术更趋向于提出新算法
invent new algorithm, find new applications,

742
00:32:40,190 --> 00:32:43,750
开拓新的应用领域
build within the American environment.

743
00:32:43,770 --> 00:32:46,730
人们往往对企业有很多的想法
And people tend to think about enterprise a lot.

744
00:32:46,750 --> 00:32:48,690
因为AI技术基本上
Because AI, fundamentally,

745
00:32:48,710 --> 00:32:50,910
是服务于企业的应用程序
is an enterprise application,

746
00:32:50,930 --> 00:32:52,620
而并非为消费者服务
not really a consumer app.

747
00:32:52,750 --> 00:32:55,680
你不也在开发一个能促进银行、公司
You are selling a solution to make a bank, or a company,

748
00:32:55,700 --> 00:32:58,290
或医院更好发展的解决方案吗？
or a hospital do something better.

749
00:32:58,310 --> 00:33:02,390
因此我觉得美国企业家和AI企业家
So I think the American entrepreneurial AI entrepreneurs

750
00:33:02,410 --> 00:33:04,060
更倾向于研究商业应用程序
tend to look at business applications

751
00:33:04,080 --> 00:33:05,660
就像IBM的超级电脑"沃森"？
like IBM Watson

752
00:33:05,680 --> 00:33:08,770
就像沃森努力发掘癌症或肿瘤的方法一样
like Watson style for trying to find cancer or tumors.

753
00:33:08,790 --> 00:33:11,560
这可以说这既是个大问题又是个小问题
So they could be big problems or small ones,

754
00:33:11,580 --> 00:33:13,730
但这正好符合企业数据仓库化
but the kind of fit within the data warehousing

755
00:33:13,750 --> 00:33:15,080
建设的目标
enterprise direction.

756
00:33:16,350 --> 00:33:20,470
在中国 这种问题到处都是
In China, they are all over the place.

757
00:33:20,490 --> 00:33:25,150
反而我觉得在中国这种数据更容易获取
I think in China, the data is more accessible

758
00:33:25,600 --> 00:33:30,290
导致中国的很多的需求
and the Chinese society has a lot of

759
00:33:30,480 --> 00:33:31,910
得不到满足,
needs that are not fulfilled

760
00:33:31,930 --> 00:33:35,020
因为过去200多年来逐美国社会
because the American society and economy which developed

761
00:33:35,040 --> 00:33:39,250
和经济发展缓慢
gradually and slowly over the last 200 years or so.

762
00:33:39,360 --> 00:33:44,230
好在过去35年里中国迅速发展
But the China society rapidly grew up in the last 35 years.

763
00:33:44,250 --> 00:33:49,040
在这个过程中 还有很多差距尚未填补
In that process, there are many gaps that are unfilled,

764
00:33:49,170 --> 00:33:50,850
因此我觉得中国企业家
so I think the Chinese entrepreneurs

765
00:33:50,870 --> 00:33:52,620
更倾向于寻找这些差距
tend to look for those gaps

766
00:33:52,640 --> 00:33:54,820
然后越过差距去解决问题
and jump in and try to solve the problems.

767
00:33:55,060 --> 00:33:57,970
例如对智慧金融的投资
So one example is our investment in smart finance.

768
00:33:57,990 --> 00:34:00,900
这家公司成立于在18个月前
That is company that was founded 18 months ago

769
00:34:00,920 --> 00:34:03,680
这一年他们都在做小额贷款
and this year they are doing small loans.

770
00:34:03,700 --> 00:34:04,690
只要下载一个应用程序
You have an app,

771
00:34:04,710 --> 00:34:06,500
将你的数据上传至这个应用
you upload your data,

772
00:34:06,520 --> 00:34:11,100
那么在八秒内就可以把钱转到手机上
and then you get your money to your phone in eight seconds.

773
00:34:11,270 --> 00:34:13,410
而在美国你根本不需要这些东西
So that's something in the US you don't need

774
00:34:13,430 --> 00:34:15,440
因为大家都有信用卡
because all of you have a credit card.

775
00:34:15,460 --> 00:34:16,660
实际上是
actually it is because of a legal

776
00:34:16,680 --> 00:34:17,760
美国的
(inaudible) in the United States,

777
00:34:17,780 --> 00:34:18,940
银行业务亏损
who is a banking loss

778
00:34:19,590 --> 00:34:21,120
各种simitations
various simitations,

779
00:34:21,140 --> 00:34:24,850
自从2007年的金融危机以来
since 2007's financial crisis,

780
00:34:24,980 --> 00:34:27,130
很难给你提供在线贷款
make it hard to give you an online loan.

781
00:34:27,150 --> 00:34:29,000
的确是这样
is that right, ok, well.

782
00:34:29,020 --> 00:34:30,970
其实中国是唯一
So, the Chinese opportunities

783
00:34:30,990 --> 00:34:33,160
有这种待遇的国家
then in fact very uniquely Chinese,

784
00:34:33,460 --> 00:34:37,500
所以这个公司在上个月放款150万元
so this company made 1.5 million loans in the last month.

785
00:34:37,520 --> 00:34:38,300
太不可思议了
that's incredible.

786
00:34:38,320 --> 00:34:39,360
你可以看到
so you can see that,

787
00:34:39,380 --> 00:34:41,710
一旦在这种连续性的
when you have these gaps that are created

788
00:34:41,730 --> 00:34:45,830
指数增长中途出现差距
by this continuity in the middle of exponential growth,

789
00:34:45,850 --> 00:34:47,420
所有的中国企业家
all the Chinese entrepreneurs are there

790
00:34:47,440 --> 00:34:49,190
都会抓住这样的机会
smelling for such opportunities.

791
00:34:49,460 --> 00:34:52,150
我刚说什么来着？
what you just said blows my mind.

792
00:34:52,170 --> 00:34:56,120
一个月一百五十万的贷款 简直太疯狂了
Look at the number of 1.5 million loans in a month is crazy.

793
00:34:56,590 --> 00:34:59,360
中国的恐慌（？）
The thing of scare (???) of China,

794
00:34:59,380 --> 00:35:02,050
这个数据的确
and yes the availability of data,

795
00:35:02,300 --> 00:35:04,920
也许是由于中国的发展过程中
maybe it's regulatory opportunities

796
00:35:04,940 --> 00:35:06,550
存在诸多不确定因素
in the course of uncertainties

797
00:35:06,570 --> 00:35:07,930
监管单位已经学会抓住这些机会
that characterize China.

798
00:35:07,950 --> 00:35:10,260
这使得万事皆有可能
That makes things possible.

799
00:35:10,280 --> 00:35:11,450
我得想想
I have to think about it.

800
00:35:11,470 --> 00:35:14,260
我想知道有没有哪条法律
I wonder if it's right to have a law that

801
00:35:14,280 --> 00:35:18,750
规定不能在线借钱 有这回事吗？
doesn't permit borrowing money online, is that really …

802
00:35:19,470 --> 00:35:20,920
在线借钱是可以的
borrowing money online is ok,

803
00:35:20,940 --> 00:35:24,020
但是在美国 这样一个收取大额回报
but a bank putting you pressure and then

804
00:35:24,220 --> 00:35:28,050
并使你感到压力山大的银行是不可能的
charging large returns is impossible in the United States.

805
00:35:28,160 --> 00:35:31,060
信用额度有一定的限制
There is a regulation on the credit rates you can charge.

806
00:35:31,080 --> 00:35:33,290
如果你遵守监管单位的信用额度
If you go to the regulatory credit rates,

807
00:35:33,310 --> 00:35:35,080
企业可能不会
a business may not be,

808
00:35:35,100 --> 00:35:36,170
因为企业每年可能会
because a business might charge

809
00:35:36,190 --> 00:35:38,020
收取30％的费用
30% a year.

810
00:35:38,040 --> 00:35:40,920
这可是一大笔收入
A large amount of returns.

811
00:35:40,940 --> 00:35:44,970
智慧融资的独特之处就是AI技术
well, the unique thing about smart finance is the core AI

812
00:35:44,990 --> 00:35:47,810
拥有较低的贷款不良率业
that does the loan has a very low bad loan rate.

813
00:35:47,830 --> 00:35:51,000
实际上他们的利率也可以非常灵活的
So they actually can have flexible interest rates,

814
00:35:51,020 --> 00:35:52,160
即使有上限
even there is ceiling.

815
00:35:52,180 --> 00:35:53,050
不错呀
that's great.

816
00:35:53,580 --> 00:35:57,780
John问了一个问题 与你创建的
John asked a question about your venture,

817
00:35:57,800 --> 00:35:59,260
创新工场（Sinovation Ventures）有关
Sinovation Ventures.

818
00:35:59,610 --> 00:36:04,050
他想知道在AI行业的所有领域中
He wants to know among all segments of AI industry,

819
00:36:04,250 --> 00:36:05,620
你和Sinovation Ventures
which areas are you

820
00:36:05,640 --> 00:36:08,280
最看好的是哪一个？
and Sinovation Ventures most interested in?

821
00:36:08,300 --> 00:36:12,560
当你给AI创业者做投资时
What characters do you value,

822
00:36:12,580 --> 00:36:14,960
你比较珍惜哪种人才？
when you invest in an AI entrepreneur?

823
00:36:15,320 --> 00:36:21,140
哪些方面你比较关注？
What do you care about?

824
00:36:21,160 --> 00:36:21,850
没错
Right, right.

825
00:36:21,870 --> 00:36:25,230
我们比较看好金融领域
So, our interest area is in the financial area.

826
00:36:25,250 --> 00:36:29,680
不仅包括贷款 还包括投资
That includes not only loans but also investments,

827
00:36:29,700 --> 00:36:32,070
保险 银行等等
insurance, banking and so on.

828
00:36:32,090 --> 00:36:36,100
所有有关金融的这些方面
All of them, all these financial aspects

829
00:36:36,120 --> 00:36:38,790
都是人们发明的游戏 纯数字游戏
are games invented by people, pure numbers.

830
00:36:38,810 --> 00:36:40,940
所以 正好适合AI
So, perfect for AI.

831
00:36:40,960 --> 00:36:45,360
不需要本钱 也不需要动手 非常方便
No rose to rise, no hands to move, any of that.

832
00:36:45,380 --> 00:36:48,080
只需要操作这些数字
So, they are purely frictionless numbers to put through.

833
00:36:48,100 --> 00:36:49,340
这就是为什么我们对其感兴趣的原因
That's why we like that.

834
00:36:49,360 --> 00:36:51,150
我们也做投资
We do investment as well,

835
00:36:51,170 --> 00:36:56,100
包括两个无人驾驶汽车
but we also have two autonomous vehicle investments,

836
00:36:56,120 --> 00:36:58,590
机器人
we have some robotic investments,

837
00:36:58,610 --> 00:37:00,640
以及人脸识别投资项目
we have investment in face recognition,

838
00:37:00,660 --> 00:37:02,090
我们的确投资了很多的其他项目
so we do invest in many other things,

839
00:37:02,110 --> 00:37:04,310
但金融是我们最喜欢的
but financial is our favorite.

840
00:37:04,330 --> 00:37:09,030
现在第二个问题是我们在寻找什么
Now the second part of the question is what do we look for.

841
00:37:09,730 --> 00:37:13,700
我们绝对不会寻找更加智能的算法
We absolutely do not look for smarter algorithms,

842
00:37:13,720 --> 00:37:19,700
因为今天的AI技术是所有已知的技术
because today AI is such that, all the known technologies,

843
00:37:19,720 --> 00:37:22,420
（如深度学习）中做的比较好的
such as deep learning, are good enough

844
00:37:22,440 --> 00:37:27,740
但是在应用领域仍然没有得到充分利用
and still not fully exploited in the application areas,

845
00:37:27,760 --> 00:37:30,220
就像企业家 风投
as entrepreneurs, VCs,

846
00:37:30,420 --> 00:37:32,380
明明现有的AI技术已经完全
it's irresponsible to have

847
00:37:32,400 --> 00:37:33,580
能够解决问题了
invented new algorithms

848
00:37:33,600 --> 00:37:36,650
但是他们还是不负责任地发明新的算法
to solve problems when existing ones are good enough.

849
00:37:36,670 --> 00:37:39,620
我们鼓励大学的研究实验室能够做到这一点
We encourage university's research labs to do that.

850
00:37:39,640 --> 00:37:42,790
因此 我们寻求的是那些能够对这种持续性
So we look for those entrepreneurs who have sharp eye

851
00:37:42,810 --> 00:37:45,390
或机会拥有敏锐眼光的企业家
on this continuity or opportunity

852
00:37:45,410 --> 00:37:48,250
以创造一个快速创造价值的公司
to create a company that rapidly creates value.

853
00:37:48,270 --> 00:37:49,080
所以 这就是生意
so, business.

854
00:37:49,100 --> 00:37:50,480
是生意 一种商业理念
business, business sense.

855
00:37:50,500 --> 00:37:52,010
AI技术的出现是理所当然
take AI for granted,

856
00:37:52,030 --> 00:37:52,790
要关心的是在生意中
and focus on business,

857
00:37:52,810 --> 00:37:54,740
如何赚钱 赚谁的钱
how to make money, who gonna pay,

858
00:37:54,760 --> 00:37:56,990
谁做决定 要赚多少钱...
who makes the decision, how much they gonna pay…

859
00:37:57,010 --> 00:37:57,740
确实如此
exactly.

860
00:37:59,310 --> 00:38:01,370
我们希望技术人员是
And then we want the technologist

861
00:38:01,390 --> 00:38:03,710
一名非常务实的实践人员
to be a very practical practitioner

862
00:38:03,730 --> 00:38:06,380
能够选择正确的算法然后再用于解决问题
that picks a right algorithm and puts it to work.

863
00:38:06,400 --> 00:38:09,220
估计你怎么也不会想到我...
you will never find me…

864
00:38:09,430 --> 00:38:11,150
Sebastian 我们可一直在关注着你呢！
we will always find you Sebastian.

865
00:38:11,170 --> 00:38:12,660
我想要金融民主化
I want the democratization,

866
00:38:12,680 --> 00:38:14,010
那怎么赚钱呢？
so how do you make money?

867
00:38:14,030 --> 00:38:15,640
呵呵  好吧
Hehe. Ok.

868
00:38:15,660 --> 00:38:18,550
Timmy和Carol问了一个综合性的问题
So, Timmy and Carol asked a combined question.

869
00:38:18,570 --> 00:38:22,340
你曾经说过大约90％的重复性工作
Timmy is a person who mentioned that you once talked about

870
00:38:22,510 --> 00:38:26,250
将被AI技术替代
some 90% of repetitive jobs will be taken over by AI.

871
00:38:26,270 --> 00:38:27,370
你有这样说过？
You said that.

872
00:38:27,510 --> 00:38:29,520
我曾经是说过
I said specifically once.

873
00:38:30,340 --> 00:38:32,410
Timmy 想知道现在最有可能
they know want to know, Timmy wants to know which are

874
00:38:32,430 --> 00:38:35,240
被取代的是哪一类工作
the most likely to be taken over now.

875
00:38:35,380 --> 00:38:38,060
而 Carol 想知道对于长远来说
And carol wants to know which is the safest job

876
00:38:38,080 --> 00:38:39,690
哪一类工作最安全
in the long term.

877
00:38:39,950 --> 00:38:41,500
同样的问题
Kind of the same question,

878
00:38:42,190 --> 00:38:44,430
作为一名本科生
which should I study as an undergraduate

879
00:38:44,560 --> 00:38:47,320
我应该先提问哪一个才能不被你打乱
to have a chance not to be disrupted by Kai-fu.

880
00:38:48,550 --> 00:38:50,490
好的 我们可以举个例子
well, we can give examples.

881
00:38:50,510 --> 00:38:51,160
大家知道吗？
You know.

882
00:38:51,580 --> 00:38:53,890
商人正在被替换
Traders are being replaced right now.

883
00:38:53,910 --> 00:38:56,070
在华尔街 几乎没有生意可做了
In Wall Street there are hardly trades left,

884
00:38:56,090 --> 00:38:57,270
全都是自动化的
that's all automated.

885
00:38:57,290 --> 00:38:58,930
其次 我们重申一遍
Again, we reaffirm the point that

886
00:38:58,950 --> 00:39:00,920
金融是最好的 AI 技术应用程序
finances are the best AI app.

887
00:39:01,120 --> 00:39:03,500
而且你也知道 某些工作 尤其是
But also you know, certain jobs,

888
00:39:03,520 --> 00:39:05,370
有特殊要求的工作 工人是危险的
particular character degree jobs,

889
00:39:05,520 --> 00:39:09,240
这是因为工厂机器人的出现
because of factory robotics.

890
00:39:09,260 --> 00:39:13,980
司机将面临危险 可能不会很快
Drivers will be in danger, probably not soon,

891
00:39:14,150 --> 00:39:16,570
但是会有很大一部分人面临危险
but there are a large percentage of people.

892
00:39:17,050 --> 00:39:19,350
而对于保安人员来说
And security guards,

893
00:39:19,370 --> 00:39:22,030
用相机也可以达到同样的效果
because watching them with cameras would be almost as good

894
00:39:22,050 --> 00:39:25,750
不要认为这是一对一的替换
And don't think this as a replacing one for one.

895
00:39:25,770 --> 00:39:28,080
例如 如果你需要十名保安人员
For example if you have ten security guards,

896
00:39:28,100 --> 00:39:29,620
守卫一个大工厂
guarding a big factory,

897
00:39:29,640 --> 00:39:31,190
或许你还需要另外一个
maybe you still have one

898
00:39:31,210 --> 00:39:33,590
那将是机器人相机
and the other nigh will be robotic cameras.

899
00:39:33,740 --> 00:39:36,730
不仅仅是这类蓝领工作 .
And also don't think of this blue collar job only,

900
00:39:36,750 --> 00:39:39,490
我觉得很多医生也会被替换
because I think many doctor jobs will get be replaced.

901
00:39:39,620 --> 00:39:44,370
例如 我们不想成为放射科医生
For example, we wouldn't want to be a radiologist,

902
00:39:44,830 --> 00:39:48,940
因为你要查看所有有关这些肿瘤
because you will read all these pictures for tumors and

903
00:39:48,960 --> 00:39:50,450
或类似东西的放射片
things like that.

904
00:39:50,470 --> 00:39:52,360
但是 机器操作起来就好多了
But this is much better done by machine.

905
00:39:52,380 --> 00:39:54,510
还没有对它们输入足够的数据和进行培训
They just haven't got enough data and training yet.

906
00:39:54,530 --> 00:39:56,250
但总有一天 它们会做到的
But someday, they will.

907
00:39:56,270 --> 00:40:03,230
所以我觉得很多这些工作 一项项概括..
So I think a lot of these jobs, one generalization…

908
00:40:03,250 --> 00:40:04,800
哪一类工作最安全了？
what's the safest job.

909
00:40:05,840 --> 00:40:08,910
喜剧演员
safest job would be a comedian,

910
00:40:08,930 --> 00:40:13,520
精神科医生 他们是最安全的
psychiatrist, that is pretty safe.

911
00:40:13,540 --> 00:40:14,690
不 未必
no, no, no.

912
00:40:16,230 --> 00:40:19,560
这可能是由于数据还没有达到一定的程度
it's maybe there are not enough data.

913
00:40:19,580 --> 00:40:20,380
额 好吧
Ok.

914
00:40:26,170 --> 00:40:28,790
任何能够夺人眼球
anything that that requires personal attention,

915
00:40:28,810 --> 00:40:31,240
且对创造力有一定要求的东西
anything that requires creativity,

916
00:40:31,260 --> 00:40:33,550
才是真正富有艺术创造力
true artistic creativity.

917
00:40:34,910 --> 00:40:37,710
经验法则告诉你哪些事情
One rule of thumb is the job you do

918
00:40:37,960 --> 00:40:39,730
可以做
can be done with something.

919
00:40:44,180 --> 00:40:46,270
但不总是真的 只是大致如此
Not always true, but roughly.

920
00:40:46,860 --> 00:40:49,380
问题是你提到全球AI技术方面
the question is you mentioned shortage of

921
00:40:49,400 --> 00:40:52,240
人才欠缺
AI related talents globally.

922
00:40:52,650 --> 00:40:55,580
为什么会有这样的问题以及如何解决呢？
Why there is such a shortage and how to solve it?

923
00:40:55,790 --> 00:40:57,900
你有什么可以解决这个问题的办法吗？
Do you see any solution to this challenge?

924
00:40:58,300 --> 00:41:01,490
好的 这可以为优达学城
ok. This gonna be an advertisement for

925
00:41:01,510 --> 00:41:04,320
深度学习课程做一次广告
Udacity courses of deep learning.

926
00:41:04,920 --> 00:41:07,530
我认为问题在于...
I think the shortage is…

927
00:41:07,550 --> 00:41:13,700
学习AI技术需要扎实的
it does require good fundamentals

928
00:41:13,720 --> 00:41:16,820
计算机科学和数学基础
in computer science and mathematics to learn AI

929
00:41:16,990 --> 00:41:18,780
并不是每个人都可以做到这一点
and not every body has that.

930
00:41:18,950 --> 00:41:21,630
它不只是从教科书中学习
And it is not learning only from the textbook.

931
00:41:21,650 --> 00:41:25,660
还需要一个好老师
Doing, requires a good teacher,

932
00:41:25,680 --> 00:41:27,610
能够一对一
who is on one-on-one.

933
00:41:27,750 --> 00:41:29,490
所以 我认为这是非常好的
So, I think it is very good,

934
00:41:29,850 --> 00:41:32,000
并不是每个大学
and I think not every university

935
00:41:32,020 --> 00:41:33,770
都要进行这样的教学
should be in place to teach that.

936
00:41:33,790 --> 00:41:37,780
在线教学是让你进入状态并且操作自如的
So online teaching as the first step to get you in,

937
00:41:37,800 --> 00:41:38,840
关键一步
and feel comfortable,

938
00:41:38,860 --> 00:41:41,930
如果你想取得进步 那么你可以尝试下一步
if you want to make progress then you can try to the next,

939
00:41:41,950 --> 00:41:44,740
找一个导师 找一份工作 学习...
getting a mentor, getting a job, learning…

940
00:41:47,170 --> 00:41:48,130
这是我的团队
This is my team,

941
00:41:48,150 --> 00:41:50,610
这里我要做一些说明 此处应该加上括号
put here my notes and say, in brackets,

942
00:41:50,760 --> 00:41:51,940
"Sebastian
"Sebastian,

943
00:41:51,960 --> 00:41:55,140
你可以介绍一下 Udacity 是做什么的"
you could introduce what is Udacity doing here",

944
00:41:56,850 --> 00:41:58,690
我要以一个很短的商业广告
and I should start a short commercial

945
00:41:58,710 --> 00:42:00,630
作为开始

946
00:42:00,650 --> 00:42:03,370
预计该广告今天就能推出
the commercial is expected to be launched today,

947
00:42:03,520 --> 00:42:06,090
这是我们深度学习课程的中文版
a Chinese version of our deep learning curriculum,

948
00:42:06,110 --> 00:42:08,660
也是最受欢迎的课程
the most popular curriculum.

949
00:42:08,680 --> 00:42:10,820
这是世界上唯一的深度学习课程
It's the only deep learning curriculum in the world.

950
00:42:10,840 --> 00:42:13,580
目前还没有中文版本
There are no versions of Chinese right now.

951
00:42:13,600 --> 00:42:15,740
它主要由Google完成
and it's done by Google mostly

952
00:42:16,210 --> 00:42:22,460
然后进行出版
and published a most popular deep learning.

953
00:42:22,480 --> 00:42:25,830
深刻学习课程非常受欢迎
Deep learning is here with a crazy demand.

954
00:42:25,850 --> 00:42:28,250
如果你是一名滴滴司机
So you are a DD driver

955
00:42:28,440 --> 00:42:29,920
但是你不喜欢你的工作
and you don't like your job.

956
00:42:30,640 --> 00:42:33,330
（当然我喜欢滴滴 ）
I love DD.

957
00:42:33,350 --> 00:42:35,710
你想要增加薪水
And you want to double your salary,

958
00:42:36,250 --> 00:42:38,860
深度学习就可以帮你实现这一点
deep learning is exactly the magic that the people do

959
00:42:38,880 --> 00:42:40,300
而你所谈论的大部分有关AI技术
and most of the AI exactly

960
00:42:40,320 --> 00:42:42,650
其实就是深度学习
you talk about is about deep learning.

961
00:42:42,670 --> 00:42:46,450
所以有一个中文版的Udacity.com
So there is a Chinese version of Udacity.com.

962
00:42:46,740 --> 00:42:50,210
如果您在接下来的两天内注册
In the next two days we will take 300

963
00:42:50,230 --> 00:42:53,020
我们将收取您300的学费
in your tuition if you enroll right now.

964
00:42:53,290 --> 00:42:55,360
希望你们会喜欢我所讲的内容
Hope guys you will like me for saying this.

965
00:42:56,390 --> 00:42:57,250
成交
Deal.

966
00:42:57,270 --> 00:42:57,700
顺便说一下
By the way,

967
00:42:57,720 --> 00:42:59,660
在移动设备上工作时
works on the mobile device,

968
00:42:59,680 --> 00:43:01,730
滴滴司机在遇到交通堵塞时
DD driver when they are stuck in traffic

969
00:43:01,750 --> 00:43:02,880
可以去那边和...
can go over there and …

970
00:43:02,900 --> 00:43:05,220
不要在开车的同时
don't drive and (inaudible) at the same time.

971
00:43:09,830 --> 00:43:12,560
就我认为的有关自驾车这个关键问题
Give us a layout of the crucial question

972
00:43:12,580 --> 00:43:15,200
请给我们一个规划
that's in my heart about the self-driving car,

973
00:43:15,220 --> 00:43:18,110
特别是中国在未来扮演的角色
specifically China's role in the future.

974
00:43:18,590 --> 00:43:21,660
好的 在参观了美国之后
Ok. I think China will have a big role

975
00:43:21,680 --> 00:43:25,520
我觉得中国将在自动驾驶上发挥巨大的潜力
in autonomous vehicles when I visited US,

976
00:43:25,540 --> 00:43:27,100
不仅体现在技术上
not necessarily technology,

977
00:43:27,120 --> 00:43:29,240
我发现中国在自动驾驶方面
China is significantly behind,

978
00:43:29,260 --> 00:43:30,840
已经严重落后于美国
in autonomous vehicle technology,

979
00:43:30,860 --> 00:43:32,930
至少要三到五年才能赶上
at least three to five years behind.

980
00:43:32,950 --> 00:43:34,770
我们一定会赶上美国的
We will catch up.

981
00:43:34,790 --> 00:43:37,690
而我认为一个有趣的问题是
And I think the big interesting issue is

982
00:43:37,710 --> 00:43:41,410
如何协调监管 民族 道德
how will the regulatory, ethnical, moral,

983
00:43:41,430 --> 00:43:44,520
环境与自动驾驶之间的关系
environment cause this to take off.

984
00:43:44,540 --> 00:43:46,290
当我去美国的时候
When I go to America,

985
00:43:46,500 --> 00:43:48,680
我的朋友们（不是电脑专业）
my friends, not computer friends

986
00:43:48,700 --> 00:43:50,960
只谈谈两件事情
only want to talk about two things,

987
00:43:50,980 --> 00:43:52,770
一个是有关手摇车的问题
one is the trolley problem,

988
00:43:52,790 --> 00:43:58,980
另一个是自动驾驶在实际操作前
and the second is how good an autonomous vehicle

989
00:43:59,000 --> 00:44:01,390
是怎么的好
has to be before it is allowed to be launched.

990
00:44:01,410 --> 00:44:02,450
这是两个相关的问题
They are related problems,

991
00:44:02,470 --> 00:44:04,310
第一个是从伦理方面来说
the first one is an ethical problem,

992
00:44:04,330 --> 00:44:06,890
比如说你现在独自推着手推车
you now, trolley goes alone, you are driving the trolley

993
00:44:06,910 --> 00:44:10,270
正好前面有一个人
and there is one person ahead of you,

994
00:44:10,860 --> 00:44:12,640
哦 不对 是五个人
sorry, the five people ahead of you,

995
00:44:12,660 --> 00:44:16,750
你可以选择继续前进杀死这五个人
if you don't do anything you kill the five people

996
00:44:16,770 --> 00:44:19,120
或者你可以选择转向
or you could turn and there is one person,

997
00:44:19,140 --> 00:44:20,510
杀死后面的一个人
there you kill one person.

998
00:44:20,530 --> 00:44:25,730
那么你是故意选择主动杀死一个人
So do you purposefully and actively kill one person

999
00:44:25,750 --> 00:44:28,310
还是装作不知道地杀死五个人
or close your eyes and kill five people.

1000
00:44:28,790 --> 00:44:32,820
对我来说 答案是不重要的
To me, I thing the answer is unimportant.

1001
00:44:32,840 --> 00:44:33,830
我有我的答案
I have my answer,

1002
00:44:33,850 --> 00:44:34,990
但我觉得不重要
but I think it is unimportant.

1003
00:44:35,010 --> 00:44:36,270
我认为对于这样一个事实
I think it's a fact

1004
00:44:36,290 --> 00:44:41,640
美国人似乎在无休止地在辩论
that Americans seem to endlessly want to debate this topic

1005
00:44:41,660 --> 00:44:45,050
将技术问题上升到道德上
and turn a technology into a moral problem

1006
00:44:45,070 --> 00:44:46,460
这样会阻碍一个国家的发展
that would slow the country down.

1007
00:44:46,480 --> 00:44:47,800
我觉得这就像教授们
I think this is like

1008
00:44:47,820 --> 00:44:50,170
所研究的哲学问题一样
professors' philosophy problems.

1009
00:44:51,390 --> 00:44:52,800
我不喜欢这个问题
I hate the problem.

1010
00:44:52,820 --> 00:44:54,530
我会选择杀死一个人
I would choose to kill the one person.

1011
00:44:55,940 --> 00:44:56,740
如果你每年
who cares,

1012
00:44:56,760 --> 00:44:58,500
能拯救50万人的话 但是谁会在乎呢？
if you save half a million people every year

1013
00:44:58,520 --> 00:44:59,090
我知道
I know.

1014
00:44:59,110 --> 00:45:02,280
但这种无休止的辩论非常可怕
But this kind of endless debate is terrible.

1015
00:45:02,300 --> 00:45:05,060
另一件事是自动驾驶的系统要达到什么程度
The other thing is how good the system has to be.

1016
00:45:05,080 --> 00:45:07,110
再次有人强调系统
And again there are people who feel like

1017
00:45:07,130 --> 00:45:08,890
一定要贴近完美
it has to be almost perfect,

1018
00:45:08,910 --> 00:45:10,610
有些人觉得一定要比
and then people think it has to be

1019
00:45:10,630 --> 00:45:13,030
人类操作好得多
absolutely a lot better than human,

1020
00:45:13,050 --> 00:45:15,900
有些人又觉得有一点进步就可以了
and then the people think just a little bit better,

1021
00:45:16,050 --> 00:45:17,240
我觉得
and I think

1022
00:45:17,650 --> 00:45:20,360
在中国可能会有更加务实的讨论
China would probably take the more pragmatic rout.

1023
00:45:20,380 --> 00:45:23,740
所以 当科技与人类的同步
so, you think China is going to be breaking ground

1024
00:45:23,760 --> 00:45:25,000
而不是略占优势的时候
when the technology gets

1025
00:45:25,020 --> 00:45:27,330
你觉得中国会打破常规吗？
as good as the human performance but not better.

1026
00:45:28,660 --> 00:45:30,250
我不知道中国每天会发生
I don't know how many accidents kill

1027
00:45:30,270 --> 00:45:31,260
多少起死亡事故
people in China everyday,

1028
00:45:31,280 --> 00:45:34,820
至少有500？
so at least 500 at least?

1029
00:45:34,840 --> 00:45:35,480
也许是1000？
Maybe 1000?

1030
00:45:35,500 --> 00:45:36,400
我不知道
I don't know.

1031
00:45:36,420 --> 00:45:40,550
在美国 每年有4万人死亡
In the US, there are 40,000 deaths a year,

1032
00:45:40,780 --> 00:45:41,990
每天有100人死亡
so 100 people per day.

1033
00:45:42,660 --> 00:45:44,060
假设中国的数字是1000
Let's say the number is 1000 in China.

1034
00:45:44,080 --> 00:45:47,080
那么使用自驾车就如同每年杀800人
So using self-driving car is like

1035
00:45:47,100 --> 00:45:50,420
或一天杀500人一样
killing 800 people's a day or 500 a day.

1036
00:45:50,440 --> 00:45:54,020
你说中国更务实 说的很好
You say China is more pragmatic and say it's fine

1037
00:45:54,040 --> 00:45:55,990
在中国你将不会遇到太多的交通问题
because you will have less traffic

1038
00:45:56,010 --> 00:45:59,970
并且会有更多安静的时间
you have more quiet time than in US

1039
00:45:59,990 --> 00:46:01,410
在美国你每天可能会杀死一个人
where you may kill 1 person a day

1040
00:46:01,430 --> 00:46:02,690
可能你不会这么做
might not do it.

1041
00:46:02,970 --> 00:46:05,310
我不知道中国人会怎样回答这个问题
well, I don't know the answer for China

1042
00:46:05,330 --> 00:46:07,170
中国人口稠密
and China has a lot of people and

1043
00:46:07,190 --> 00:46:08,930
政府官员众多
many different government officials.

1044
00:46:08,950 --> 00:46:11,060
但是我觉得对完美的要求
But I'm saying there will be less obsession

1045
00:46:11,080 --> 00:46:12,340
不会这么高
in demanding perfection.

1046
00:46:12,710 --> 00:46:15,080
所以这一点
So if it's a bit better than people

1047
00:46:15,100 --> 00:46:16,610
不错
maybe it's good enough.

1048
00:46:16,630 --> 00:46:20,960
但在美国有这么多的辩论
But in the US there are so much debate.

1049
00:46:21,090 --> 00:46:24,000
所有这些辩论都会阻碍美国的发展
US will slow this down with all the debates.

1050
00:46:24,020 --> 00:46:27,150
美国的自驾车公司要到中国来吗？
Should self-driving car US company come to China?

1051
00:46:28,090 --> 00:46:32,320
我试过了 这非常难！
It's very difficult to come to China. I've tried but.

1052
00:46:32,340 --> 00:46:33,750
我在中国有公司
well my company is in China,

1053
00:46:33,770 --> 00:46:35,460
是一家自驾汽车公司
we are a self-driving car company now.

1054
00:46:35,480 --> 00:46:37,090
我们也要来中国
so should we come to China.

1055
00:46:38,000 --> 00:46:39,680
好吧 优达学城来中国
well, Udacity should come to China,

1056
00:46:39,700 --> 00:46:42,950
这是一个非常普通的事情
because it's a very universal thing.

1057
00:46:43,100 --> 00:46:44,810
对于自驾汽车公司
The self-driving car company

1058
00:46:44,830 --> 00:46:46,970
我想你需要一个中国合作伙伴
I think you need a Chinese partner to come in.

1059
00:46:46,990 --> 00:46:48,620
所以请跟我谈谈
So please talk to us about

1060
00:46:48,640 --> 00:46:50,090
我可能会投资你的公司
maybe investing in your company.

1061
00:46:50,110 --> 00:46:52,020
凡事参与美国自驾
the audience involved in

1062
00:46:52,040 --> 00:46:54,730
汽车公司的成员
the US self-driving car companies.

1063
00:46:54,750 --> 00:46:58,070
如新加坡等国家
There are countries like Singapore

1064
00:46:58,090 --> 00:47:00,800
都在极力支持这项技术
which actively encourage this technology.

1065
00:47:00,820 --> 00:47:01,370
那不错
that's good.

1066
00:47:01,390 --> 00:47:02,750
你觉得他们会这么做吗？
do you think they will leg up?

1067
00:47:04,640 --> 00:47:06,100
新加坡确实会这样做
I think Singapore does,

1068
00:47:06,120 --> 00:47:09,330
因为这是一项技术
because it's kind of technology

1069
00:47:09,350 --> 00:47:12,040
得益于一个控制力良好的
that benefits from a well-controlled

1070
00:47:12,060 --> 00:47:13,930
管理环境
and managed environment.

1071
00:47:13,950 --> 00:47:15,820
新加坡和中国都是自上而下
Both Singapore and China are relatively

1072
00:47:15,840 --> 00:47:18,110
相对制约的管理模式
managed from top down,

1073
00:47:18,130 --> 00:47:21,200
新加坡有额外的优势 就是它很小
and Singapore has the additional advantage of being small.

1074
00:47:21,220 --> 00:47:22,760
正因为如此才能够控制住
So it's controllable.

1075
00:47:22,780 --> 00:47:26,050
所以我觉得新加坡政府鼓励
So I think the Singaporean government actually

1076
00:47:26,070 --> 00:47:29,470
创新的方式其实是非常明智的
has been very smart in the way they encourage innovation,

1077
00:47:29,490 --> 00:47:31,440
他们通过各种各样的方法
they have various ways to fund

1078
00:47:31,460 --> 00:47:34,050
来为创业公司提供资金援助
start up companies with incentives

1079
00:47:34,070 --> 00:47:35,940
同时 他们也在开发无人驾驶汽车
and also doing the autonomous vehicle.

1080
00:47:35,960 --> 00:47:37,340
他们的治理方式给我留下了深刻的印象
I'm very impressed by their government.

1081
00:47:37,980 --> 00:47:41,330
因为你是最成功、最了不起
since you are one of the most amazing entrepreneurs,

1082
00:47:41,350 --> 00:47:44,100
最具有远见的企业家、科学家和投资商
amazing scientist, amazing investor,

1083
00:47:44,240 --> 00:47:46,470
连我都觉得你是一个传奇
I also think you are an amazing visionary.

1084
00:47:48,080 --> 00:47:52,040
可以给我们说说30年后
Tell us something about how technologies

1085
00:47:52,060 --> 00:47:55,460
会是什么样的呢？
could be 30 years from now?

1086
00:47:56,090 --> 00:47:57,750
你指的是技术还是这个社会？
technology or the world?

1087
00:47:57,900 --> 00:47:58,690
都有
both.

1088
00:47:58,850 --> 00:48:04,430
对于还在投资期间的一些技术而言
Some technologies, maybe on the investment horizon

1089
00:48:04,450 --> 00:48:06,490
这可能是我们的孩子要担心的
but our kids will worry about

1090
00:48:06,950 --> 00:48:08,530
他们可能会有更疯狂的举动
and something crazy to do.

1091
00:48:11,010 --> 00:48:15,470
我还没有怎么想自己会做些什么
I havn't think too much about what I would be doing.

1092
00:48:15,490 --> 00:48:16,340
当你60岁呢？
You will be 60 then.

1093
00:48:17,360 --> 00:48:19,760
好吧 我想我还活着
Well, I think I would be alive,

1094
00:48:19,780 --> 00:48:22,690
寿名的延长是 AI 技术
because human longevity is one of the great

1095
00:48:22,710 --> 00:48:25,410
最大的成就之一
beneficiary outcomes of AI,

1096
00:48:25,430 --> 00:48:26,380
这样的话我们会活得更久
we will live longer.

1097
00:48:26,400 --> 00:48:28,930
大部分癌症将会消失
Cancer will be largely eradicated.

1098
00:48:28,950 --> 00:48:30,410
所以我应该还活着
So I would be around.

1099
00:48:30,430 --> 00:48:31,120
这很重要
That's important.

1100
00:48:31,140 --> 00:48:32,530
是我们的目标之一
That's for one.

1101
00:48:33,080 --> 00:48:34,820
其实 在接下来的30年里
I think the world actually faces

1102
00:48:34,840 --> 00:48:37,560
世界将面临着非常严峻的挑战
very difficult challenging in the next 30 years,

1103
00:48:37,720 --> 00:48:40,500
因为 AI 技术正在取代所有的工作
because AI is taking over all these jobs.

1104
00:48:40,520 --> 00:48:43,140
我想可能会有一些负面的影响
I think there is a possible negative outcome

1105
00:48:43,160 --> 00:48:47,970
人们可能会失去努力工作的
that people could lose their incentive to work hard

1106
00:48:47,990 --> 00:48:50,070
激情和动力
and lose their motivation.

1107
00:48:50,090 --> 00:48:53,150
而且 VR 技术的发展也很好
And also with the VR working so well,

1108
00:48:53,170 --> 00:48:54,730
人们只需坐在家里
people could just sit in home

1109
00:48:54,750 --> 00:48:56,950
整天玩游戏
and let their brain stop developing

1110
00:48:56,970 --> 00:48:58,220
让大脑放松
by playing games all day.

1111
00:48:58,460 --> 00:49:00,750
这个结果可能很糟糕
That's possibly one negative outcome.

1112
00:49:00,770 --> 00:49:03,070
但我还是比较乐观的
But I think I'm more optimistic

1113
00:49:03,090 --> 00:49:05,700
也许还有一个比较好的结果
that maybe a more positive outcome would be

1114
00:49:05,720 --> 00:49:08,960
那就是人类再也不需要
that I think human race was never

1115
00:49:08,980 --> 00:49:12,610
去做一些重复的工作
put into place to do just repetitive jobs.

1116
00:49:12,740 --> 00:49:15,630
为了追逐金钱和名望
I think we continue to fall into traps

1117
00:49:15,650 --> 00:49:17,990
可能还有他人的尊重
because we chase money and fame,

1118
00:49:19,640 --> 00:49:21,450
人们可能会继续选择这种生活
Or respect, I should say.

1119
00:49:21,470 --> 00:49:24,750
我们的父母告诉我们去当医生 当律师
When our parents tell us, be a doctor, lawyer,

1120
00:49:24,760 --> 00:49:29,680
去商学院 做工程师
go to businees school, be an engineer

1121
00:49:29,830 --> 00:49:33,210
他们实际上是在和我们说追逐声望和金钱
They are telling us to chase after respect and money.

1122
00:49:33,340 --> 00:49:35,940
但是这类工作 很多都会消失
But many of these jobs will be gone.

1123
00:49:35,960 --> 00:49:39,780
就好像是造物主在说
So this may be our creator's way to tell us that,

1124
00:49:39,800 --> 00:49:42,960
你看 既然你没办法找到自己的人生方向
look, you can't seem to find your own path,

1125
00:49:42,980 --> 00:49:46,590
那我就创造一个 AI
So I'm gonna create an AI 

1126
00:49:46,600 --> 00:49:49,380
让你根本没有选择可选
to remove those possiblities from your consideration.

1127
00:49:49,400 --> 00:49:52,680
你们人类得找到自己的命运和归宿
So you guys, human kinds, need to find your own destiny.

1128
00:49:52,700 --> 00:49:56,210
所以我想加入这次大探险
So I'd love to be a part of that exploration,

1129
00:49:56,230 --> 00:49:59,550
看看这次冒险里 是科学与创造性更加重要
to see whether that's something scientific and creative

1130
00:49:59,570 --> 00:50:03,490
还是信仰更加重要
or something that's spiritual and religious,

1131
00:50:03,710 --> 00:50:10,710
我想 这就是继无聊的工作之后 人类的真实命运
So I think that's mankind's true destiny after the boring jobs are gone,

1132
00:50:10,730 --> 00:50:11,720
还是有一些事情值得我们去做
there's something worth our work.

1133
00:50:11,740 --> 00:50:13,920
我喜欢这个 因为对我来说
I love this because to me

1134
00:50:13,940 --> 00:50:16,300
最值得尊重的人
the people who get the most respect

1135
00:50:16,570 --> 00:50:19,410
是那些不听从父母安排、自立自强的人
are the ones who don't follow their parent's advice.

1136
00:50:19,660 --> 00:50:20,100
是的
yes.

1137
00:50:20,120 --> 00:50:21,940
那些一路疯狂成长的人
the ones who grow something crazy,

1138
00:50:21,960 --> 00:50:25,530
比如我 父母不会告诉你如何
like, I don't think your parents have told you

1139
00:50:25,550 --> 00:50:28,650
才能成为世界最强的奥赛罗球员
to build the world strongest Othello player,

1140
00:50:28,860 --> 00:50:31,890
如何建立世界最强的语音识别系统
build the world strongest speech recognition system

1141
00:50:31,910 --> 00:50:33,250
包括你的导师也不会告诉你
and your advisor told you

1142
00:50:33,270 --> 00:50:34,960
如何使用专家系统...
to use Expert System…

1143
00:50:34,980 --> 00:50:36,810
是的 但我不同意这一点
yes but I didn't.

1144
00:50:39,460 --> 00:50:42,440
我的父母出生在20世纪初
But I'm deeply grateful for my parents

1145
00:50:42,460 --> 00:50:45,260
我非常感激他们
who were born in the early 1900s,

1146
00:50:45,280 --> 00:50:47,590
是他们教我追求梦想
that they let me pursue my dream

1147
00:50:47,610 --> 00:50:49,690
选择自己的学校、工作
and let me pick the schools and jobs

1148
00:50:49,710 --> 00:50:51,890
事业以及专业
and career and the major.

1149
00:50:51,910 --> 00:50:52,920
我真心地感谢他们
I'm deeply grateful for that.

1150
00:50:53,070 --> 00:50:57,300
这里有很多你的粉丝 全是年轻人
you have a great audience here, really young people.

1151
00:50:57,320 --> 00:51:02,010
如果让你回到年轻时
But if you talked your young self,

1152
00:51:02,030 --> 00:51:04,040
比如30岁 25岁
you are 30, 25 years old,

1153
00:51:04,290 --> 00:51:06,510
你又会给出什么建议？
what's your advice?

1154
00:51:07,490 --> 00:51:10,830
我的建议是跟随你的内心
I would advice follow your heart,

1155
00:51:10,980 --> 00:51:14,700
因为这样你才能认清自己
because this is the way how you differentiate yourself.

1156
00:51:15,020 --> 00:51:17,530
做和其他人一样的事情
Working on things that everybody else is doing,

1157
00:51:17,550 --> 00:51:18,940
你的优势是什么？
what is your edge?

1158
00:51:19,140 --> 00:51:21,690
是与其他人及AI技术对着干？
Against other people as well the AI.

1159
00:51:21,810 --> 00:51:24,780
还有一件事让我感触很深
The other thing I would say is go very deep,

1160
00:51:25,000 --> 00:51:28,520
多台机器同时以五秒的时间
because at the time where five second decisions

1161
00:51:28,540 --> 00:51:31,300
重复做功时
are replicated are done by machines,

1162
00:51:31,650 --> 00:51:33,600
你必须非常努力地去工作
you have to work hard

1163
00:51:33,620 --> 00:51:35,590
才能发现规律
and find the (inaudible) rule

1164
00:51:35,610 --> 00:51:41,100
然后为了生存而成为该方面的专家
and really becoming an expert in order to just survive.

1165
00:51:41,790 --> 00:51:44,090
开复 很高兴能邀请到你
Kai-fu, I've been, I believe, an honor

1166
00:51:44,110 --> 00:51:49,420
并和你畅谈
and pleasure to be with you and ask you questions.

1167
00:51:49,440 --> 00:51:49,780
谢谢
Thanks.

1168
00:51:49,800 --> 00:51:51,970
和你交谈
Listen to your answer,

1169
00:51:51,990 --> 00:51:55,060
感觉我们就像好兄弟一样
it sounds like a brother from a different mother,

1170
00:51:55,080 --> 00:51:59,340
老实说 我非常赞同你的所有观点
because I completely agree with whatever you say, honestly.

1171
00:52:00,580 --> 00:52:02,510
谢谢你 Sebastian 和你交流也很开心
Thank you Sebastian, always pleasure talking to you,

1172
00:52:02,530 --> 00:52:04,410
让我们继续做好哥们
please will continue to call me brother.

1173
00:52:04,430 --> 00:52:05,100
当然没问题
Yes.

1174
00:52:05,680 --> 00:52:07,260
让我们来宣布最后一条消息
We will make one last announcement.

1175
00:52:07,280 --> 00:52:08,970
这里是 Udacity Talk
This is Udacity Talk,

1176
00:52:08,990 --> 00:52:09,930
你可以在线观看我们的节目
you can see us online

1177
00:52:09,950 --> 00:52:11,420
之前我们也采访过 Tony Fodana
and we have people like Tony Fodana

1178
00:52:11,440 --> 00:52:13,000
等人
and interviewed in the past,

1179
00:52:13,130 --> 00:52:14,760
我们会采访更多了不起的人物
and we will interview more fascinating people.

1180
00:52:14,780 --> 00:52:19,100
这是我们在中国做的第一期节目
This is our first edition outside the US, in China.

1181
00:52:19,260 --> 00:52:21,420
每次来中国我都非常高兴
I'm delighted every time I come to China.

1182
00:52:21,440 --> 00:52:24,270
因为这个国家取得了很多的成就
I found this country more accomplishments

1183
00:52:24,290 --> 00:52:26,890
到处都是企业家 能量
I think you have many entrepreneurs, energy,

1184
00:52:26,910 --> 00:52:29,800
创造力 不断推动着你们发展
creativity that blows in your way,

1185
00:52:29,820 --> 00:52:32,110
在许多方面你们都创建了一个新的硅谷
I think you are the new Silicon Valley in many ways.

1186
00:52:32,130 --> 00:52:35,310
非常荣幸能与开复博士
This's great pleasure to be with Kai-fu,

1187
00:52:35,330 --> 00:52:40,250
创新工厂、滴滴等许多公司合作
Sinovation Ventures, DD with many other companies

1188
00:52:40,500 --> 00:52:43,600
并向您学习如何建立一个卓越的企业
and learning from you how to build a company.

1189
00:52:44,270 --> 00:52:45,690
最后一次
One last time,

1190
00:52:45,710 --> 00:52:50,350
如果你喜欢 Udacity 的深度学习课程
if you like this Udacity courses on deep learning,

1191
00:52:51,040 --> 00:52:55,770
我们有中文的在线课程 cn.udacity.com
we have courses on line in Chinese, cn.udacity.com,

1192
00:52:56,090 --> 00:52:59,140
最近两天报名 会有折扣
for two days if you sign up you get a rebate.

1193
00:52:59,160 --> 00:53:00,830
提醒一下 数学上
We recommended you to know

1194
00:53:00,850 --> 00:53:02,520
有个自由的模式
there is a liberal pattern in math.

1195
00:53:02,540 --> 00:53:06,610
深度学习的特点之一就
One thing about deep learning is

1196
00:53:07,120 --> 00:53:08,930
是软件工程师们非常努力
software engineers work really hard,

1197
00:53:08,950 --> 00:53:12,680
你必须考虑每一个可能的规则
you have to think every possible rule.

1198
00:53:13,000 --> 00:53:15,510
深度学习是一种使之变得容易的方式
Deep learning is a way to make it easy.

1199
00:53:15,530 --> 00:53:17,590
只是举个例子 由你来制定规则
You just put example and you make rules.

1200
00:53:17,610 --> 00:53:19,810
在计算机程序领域
I think it's an area of computer programing

1201
00:53:19,830 --> 00:53:21,470
软件工程师已经过时了
where software engineers are obsolete

1202
00:53:21,490 --> 00:53:24,410
拥有非常简单技能的人们
and people with very simple skills can do

1203
00:53:24,430 --> 00:53:27,370
可以通过最近在皮肤癌检测
amazing stuff by the recent

1204
00:53:27,390 --> 00:53:30,790
的进展中取得惊人的成就
progress on skin cancer detection.

1205
00:53:30,810 --> 00:53:32,400
所以 去看看我们的网站
So, go to our website.

1206
00:53:32,420 --> 00:53:36,210
我想特别感谢一下李开复博士
I want to thank, specifically Kai-fu Lee of course,

1207
00:53:36,230 --> 00:53:40,260
感谢创新工厂、斗鱼直播
his company Sinovation Ventures, Douyu TV,

1208
00:53:40,280 --> 00:53:44,140
品玩、机器之心和果壳网MOOC学院
Ping West, Synced and Guokr MOOC

1209
00:53:44,710 --> 00:53:47,630
今晚为我们带来的伟大贡献
who was holding us tonight for you contributions.

1210
00:53:47,650 --> 00:53:50,310
再次感谢你参与我们的在线访谈
Thank you once more online great questions.

1211
00:53:50,330 --> 00:53:53,470
感谢创新工厂的观众
Thank youaudience here in Sinovation Ventures

1212
00:53:53,490 --> 00:53:56,900
希望下一次的 Udacity Talks 能继续见到您！
and see you for the next Udacity Talks!

1213
00:56:05,250 --> 00:56:07,170
再见！
bye bye

