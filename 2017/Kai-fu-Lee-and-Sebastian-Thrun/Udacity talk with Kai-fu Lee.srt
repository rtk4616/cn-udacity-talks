1
00:00:00,020 --> 00:00:03,610
优达学城 李开复专访
Udacity Talks with Kai-fu Lee

2
00:01:08,860 --> 00:01:09,880
你好
Nihao.

3
00:01:14,390 --> 00:01:20,480
真让人难以置信 我竟然能在北京的创新工厂
It is a unbelievable pleasure to be here in Beijing in Sinovation

4
00:01:20,480 --> 00:01:24,220
碰到我一直以来的好友
with my good friend and long time friend

5
00:01:24,600 --> 00:01:26,060
李开复博士
Dr. Kai-fu Lee.

6
00:01:26,970 --> 00:01:29,760
我一直都很喜欢中国
I always love to be in China,

7
00:01:29,940 --> 00:01:32,340
你也知道 中国估计是
because you know China is

8
00:01:32,360 --> 00:01:35,320
当今最有创造力的国家
perhaps the most innovative country today.

9
00:01:36,060 --> 00:01:39,510
全球的大科技公司
If you look at big Tech companies on the planet,

10
00:01:39,840 --> 00:01:41,790
十个中有四个是中国人创办的
four out of ten are Chinese,

11
00:01:42,400 --> 00:01:44,250
没有欧洲公司
there is no European company,

12
00:01:44,270 --> 00:01:46,410
没有南美公司
there is no southern American company,

13
00:01:46,690 --> 00:01:49,070
却有出色的中国公司
but there are amazing Chinese companies.

14
00:01:49,090 --> 00:01:50,890
感谢开复
Thanks to Kai-fu,

15
00:01:51,220 --> 00:01:54,380
开复是中国最具实力
whom I consider the most important

16
00:01:54,400 --> 00:01:58,120
最有才华的投资者
and most talented investor in all China.

17
00:01:58,340 --> 00:02:01,190
这永远是不平凡的一年的开始
This is always a fantastic start of a year;

18
00:02:01,210 --> 00:02:04,150
就算是参观这里的新兴企业也能令人振奋
it is always great to visit start-up companies here.

19
00:02:04,170 --> 00:02:07,210
我认为正是你们卓越的创新力和开拓力
I think you rival the Silicon Valley

20
00:02:07,330 --> 00:02:11,630
使得你们能与硅谷匹敌
in your ability to innovate and build an amazing business.

21
00:02:12,640 --> 00:02:14,420
我是这场对话的主持人
I'm here the moderator.

22
00:02:14,970 --> 00:02:18,270
1991年我遇到了开复
I've met Kai-fu in 1991,

23
00:02:18,430 --> 00:02:20,910
当时他在宾夕法尼亚州匹兹堡的
when he was in the faculty of a college in Pittsburgh

24
00:02:20,930 --> 00:02:24,200
卡内基梅隆大学任教
of Pennsylvania called Carnegie Mellon University.

25
00:02:24,660 --> 00:02:27,950
就在 5307 号
He was in 5307,

26
00:02:28,850 --> 00:02:30,180
一个有窗户的办公室
a window office,

27
00:02:30,420 --> 00:02:32,990
正好在我的无窗实验室旁边
right next to my windowless lab,

28
00:02:33,010 --> 00:02:35,630
我当时在那里当旁听生
where I was acting as a visiting student.

29
00:02:36,210 --> 00:02:39,620
开复是卡内基梅隆大学语音识别
Kai-fu was the preeminent researcher

30
00:02:39,790 --> 00:02:44,100
和游戏方面的杰出研究专家
on speech recognition and gaming playing at Carnegie Mellon.

31
00:02:44,120 --> 00:02:46,380
他既是恶魔又是上帝
He was a demon and god.

32
00:02:46,800 --> 00:02:49,740
我有幸和他谈了几次
I got a chance to talk to him a few times,

33
00:02:49,760 --> 00:02:53,300
当我把他的系统应用于卡内基梅隆大学的
when I adopted his system to one of the very first

34
00:02:53,320 --> 00:02:55,540
第一个语音可控设备之后
speech controllable device in Carnegie Mellon.

35
00:02:55,690 --> 00:02:56,560
最重要的是
And most of all,

36
00:02:56,580 --> 00:02:57,560
我见识到了李开复博士
over the years I have learnt

37
00:02:57,580 --> 00:03:00,550
这么多年来卓越的洞察力
Dr. Kai-fu Lee has an insight.

38
00:03:00,690 --> 00:03:02,440
他的内心
He is, in his heart,

39
00:03:02,680 --> 00:03:05,640
像一个16岁的孩子一样充满热情
as yound as a 16-year old, and as enthusiasm,

40
00:03:05,750 --> 00:03:08,090
又像一位500岁的老人一样睿智
but as wise as a 500-year old.

41
00:03:08,250 --> 00:03:09,500
欢迎开复
Welcome Kai-fu.

42
00:03:09,760 --> 00:03:11,120
谢谢 谢谢塞巴斯蒂安
Thank you. Thank you Sebastian.

43
00:03:11,140 --> 00:03:12,560
你太客气了
You are too kind.

44
00:03:12,580 --> 00:03:14,660
我可是塞巴斯蒂安的忠实粉丝
I'm a huge fan of Sebastian,

45
00:03:14,830 --> 00:03:20,370
因为他参与开发了谷歌、谷歌地图
for the work he has done at Google or for the maps

46
00:03:20,390 --> 00:03:25,550
谷歌自驾车、谷歌 X实验室和优达学城
as well as for the self-driving car and Google X and Udacity

47
00:03:25,570 --> 00:03:28,090
以及人们口耳相传的一些新事物
and some new things people rumor about.

48
00:03:28,470 --> 00:03:29,410
嘘…..
shhhhhhhh.

49
00:03:29,430 --> 00:03:31,450
我对他做的每件事情都有所关注
I follow up every thing he does.

50
00:03:31,770 --> 00:03:32,310
别说啦
don't talk of that.

51
00:03:32,330 --> 00:03:34,260
好的 秘密 秘密
OK. Secret, secret.

52
00:03:35,250 --> 00:03:37,030
我是这里的主持人
I am here the moderator.

53
00:03:37,140 --> 00:03:38,560
今天的主角是李开复
Today is all about Kai-fu Lee.

54
00:03:38,940 --> 00:03:40,880
我们每个月都会开展一期
This is a series of Udacity Talks

55
00:03:40,900 --> 00:03:42,880
优达学城专访
which we do every month or so,

56
00:03:43,040 --> 00:03:46,140
我们会邀请如李开复等知名人士
where we bring luminaries like Kai-fu Lee to everybody,

57
00:03:46,160 --> 00:03:47,790
来与大家（大部分是我们的学生）交流
most our students and among our students

58
00:03:47,810 --> 00:03:49,370
我选取了我们学生提出的一些问题
I picked up some questions

59
00:03:49,680 --> 00:03:51,520
与李开复互动
to interact with Kai-fu Lee.

60
00:03:51,540 --> 00:03:53,440
但在此之前 我想问您几个问题
But before that I want to ask you a few questions.

61
00:03:53,460 --> 00:03:55,750
我想回归本源
So I want to go back to the basics,

62
00:03:55,770 --> 00:03:59,820
因为在我看来 人们通常将您视为
because I think people will view as an amazing investor

63
00:03:59,840 --> 00:04:01,860
一名出色的投资者和商业领袖
and an amazing business leader in China.

64
00:04:01,880 --> 00:04:04,120
但是他们并不太了解您是怎么起家的
But they don't really know what you start out with.

65
00:04:04,290 --> 00:04:06,020
您曾经是一名黑客对吗?
You were a hacker right?

66
00:04:06,300 --> 00:04:07,320
对 是的
yes, I was.

67
00:04:07,340 --> 00:04:10,070
其实我曾经研究过你的代码
actually I worked on your code.

68
00:04:10,090 --> 00:04:10,570
哦？
oho!

69
00:04:10,590 --> 00:04:12,010
那个程序叫做“比尔”
and the program was called Bill

70
00:04:12,980 --> 00:04:14,500
它是游戏奥赛罗
it was Othello game.

71
00:04:14,770 --> 00:04:20,560
1984年
In 1984,

72
00:04:20,580 --> 00:04:24,180
我是卡内基梅隆大学的二年级研究生
I was a second-year graduate student at Carnegie Mellon.

73
00:04:24,550 --> 00:04:28,720
我教一群高中生编程
I taught a bunch of high school students how to program.

74
00:04:28,740 --> 00:04:30,750
其中一个学生真的很聪明
One of the students was really smart.

75
00:04:30,770 --> 00:04:32,720
他叫 Sanjoy Mahajan
His name is Sanjoy Mahajan.

76
00:04:32,850 --> 00:04:34,480
后来 我和他一起开发了
And then I worked with him to

77
00:04:34,500 --> 00:04:36,200
一个奥赛罗游戏程序
build an Othellogame program.

78
00:04:36,220 --> 00:04:38,380
然后我们说 我们可以把它
And then we said well we could make it

79
00:04:38,400 --> 00:04:39,810
变得像世界冠军一样棒
as good as world champion.

80
00:04:40,000 --> 00:04:42,620
所以我们接着一起研究
So we went ahead and he and I worked together.

81
00:04:42,640 --> 00:04:45,340
在卡内基梅隆大学 我们没有资金
At Carnegie Mellon we had no funding

82
00:04:45,360 --> 00:04:47,950
只是为了好玩
just for fun developed this program

83
00:04:47,970 --> 00:04:49,920
这个程序很快就被开发出来了
that was very fast

84
00:04:49,940 --> 00:04:52,610
成了世界冠军比尔
and did the world champion called Bill.

85
00:04:52,630 --> 00:04:54,390
为什么叫比尔呢？
why it was called Bill?

86
00:04:54,410 --> 00:04:57,570
因为《奥赛罗》是一个
I called it Bill because Othello is a play

87
00:04:57,590 --> 00:04:59,160
莎士比亚戏剧
written by Shakespeare

88
00:04:59,180 --> 00:05:01,490
莎士比亚的姓是威廉
and Shakespeare's first name is William

89
00:05:01,510 --> 00:05:04,330
而比尔是威廉的简称
and Bill is the short for William.

90
00:05:04,880 --> 00:05:08,640
这段不可思议的历史值得为世人所知
this is an untold history but the world should know.

91
00:05:08,660 --> 00:05:11,640
我们谈过谷歌阿尔法围棋
We talked about Google Alpha Go

92
00:05:12,720 --> 00:05:17,040
它去年打败了世界围棋冠军
beating the world champion in Go last year.

93
00:05:17,060 --> 00:05:19,930
大约在20年前
In 1997, about 20 years ago,

94
00:05:19,950 --> 00:05:22,890
卡内基梅隆大学的后代"深蓝"
Deep Blue, an offspring of Carnegie Mellon,

95
00:05:22,910 --> 00:05:24,400
战胜了 Gary Kasparov
beat Gary Kasparov

96
00:05:24,420 --> 00:05:26,700
当时的国际象棋世界冠军
who was then considered the world champion in chess,

97
00:05:26,720 --> 00:05:28,200
尽管存在一些争议
though there were debates about it.

98
00:05:28,220 --> 00:05:33,400
但在此之前
But before that, Samuel the checkers game,

99
00:05:34,330 --> 00:05:37,130
塞缪尔的西洋跳棋程序击败了一名
there was a great success in Carnegie Mellon that was

100
00:05:37,150 --> 00:05:39,930
真正的跳棋大师
a strong authentic player was beaten by a virtual program.

101
00:05:39,950 --> 00:05:40,780
那是您的杰作吗？
Is that yours?

102
00:05:40,800 --> 00:05:41,930
那是一个微型程序
that was a micro program.

103
00:05:41,950 --> 00:05:43,520
所以在 AI 游戏的历史上
so you were a reigning champion

104
00:05:43,540 --> 00:05:46,010
您一度是个卫冕冠军
in the history of AI games

105
00:05:46,030 --> 00:05:50,090
这是另一个非常受欢迎的游戏
well it was another very popular game.

106
00:05:50,280 --> 00:05:52,000
我的确因为它在人工智能方面
I did get a publication

107
00:05:52,020 --> 00:05:53,640
获得了一些知名度
in Artificial Intelligence.

108
00:05:53,660 --> 00:05:54,180
太棒了
that was great.

109
00:05:54,200 --> 00:05:55,490
看你的代码
I looked at your code

110
00:05:55,510 --> 00:06:00,120
就能领略你精彩的编程方式
and I can tell the way you encoded was just brilliant.

111
00:06:00,140 --> 00:06:02,570
这是一个生成你自己的代码的程序
It was a program to generate your own code.

112
00:06:02,590 --> 00:06:04,490
一段能生成代码的代码
It was a code generating code.

113
00:06:04,680 --> 00:06:06,280
这是一个预编程
it's a pre-programing.

114
00:06:06,300 --> 00:06:08,120
基本上在计算机科学方面
Basically in computer science,

115
00:06:08,820 --> 00:06:11,390
人们希望最大限度地减少繁琐的计算量
you want to minimize a massive amount of computing

116
00:06:11,410 --> 00:06:14,200
因而创建了可以查找的表格
so you create tables that you could look up

117
00:06:14,220 --> 00:06:16,940
并快速处理事务
and rapidly do things fast.

118
00:06:16,960 --> 00:06:18,410
据我了解
As I understand it,

119
00:06:20,130 --> 00:06:22,690
CMU 开发了一个新的德州扑克智能系统
CMU has a new Texas Hold'em poker player,

120
00:06:22,710 --> 00:06:25,700
我认为这也有着巨大的潜力
I think they also generate a large space.

121
00:06:25,720 --> 00:06:27,780
我觉得你30年前的开发
I think there are going to be footsteps

122
00:06:27,800 --> 00:06:29,500
给了他们一些启发
that you started 30 years earlier.

123
00:06:29,520 --> 00:06:30,300
他们学习了你的经验
That kind of learning.

124
00:06:30,320 --> 00:06:31,060
是的
Yes.

125
00:06:31,610 --> 00:06:35,510
然后你转到了一个叫 SPHINX 的程序
Then you moved on to something called SPHINX,

126
00:06:35,670 --> 00:06:38,610
这可是世界上第一个真人发音
which was the world very first speaker voice

127
00:06:38,630 --> 00:06:40,060
和语音识别系统
and speech recognition system.

128
00:06:40,080 --> 00:06:41,030
你是怎么做到的？
How did that happen?

129
00:06:41,780 --> 00:06:43,600
我去了卡内基梅隆大学
well I went to Carnegie Mellon

130
00:06:43,620 --> 00:06:51,780
遇到了我们的系主任
and I met with our department chair,

131
00:06:58,030 --> 00:07:02,850
尼克尔·哈博曼
Nichole Harborman.

132
00:07:02,870 --> 00:07:05,850
尼克尔说十分欢迎开复
Nicole said Kai-fu welcome

133
00:07:05,870 --> 00:07:07,950
我说您对我有什么期望吗？
and I said what do you expect from me?

134
00:07:08,210 --> 00:07:11,900
他说我希望你在你所研究的领域创作一篇
He said I want you to write the best thesis

135
00:07:11,920 --> 00:07:12,780
最棒的论文
in your area

136
00:07:12,800 --> 00:07:14,650
我希望你无论做什么研究
and I want you to be the best in the world

137
00:07:14,670 --> 00:07:16,140
都是世界上最棒的
in whatever thesis you do.

138
00:07:16,490 --> 00:07:18,100
我说这真的很难
I said that is really hard

139
00:07:18,120 --> 00:07:19,290
我不大可能是最棒的
and I cannot be the best.

140
00:07:19,310 --> 00:07:21,330
他说你可以选择一个较窄的领域
He said you can pick a narrower area

141
00:07:21,350 --> 00:07:22,360
你就能做到
and you will be the best.

142
00:07:22,380 --> 00:07:24,980
语言识别这种狭窄的区域？
it doesn't matter a narrow area like speech recognition?

143
00:07:25,000 --> 00:07:26,010
谁在乎呢?
who care

144
00:07:26,030 --> 00:07:26,940
真是个糟糕的选择 呵呵
what a bad choice. hehehe

145
00:07:26,960 --> 00:07:28,540
他说 "要在你的领域做出最好的研究成果
he just said, "write the best thesis in your area,

146
00:07:28,560 --> 00:07:31,770
否则你就白来卡内基梅隆了"
otherwise this is not what Carnegie Mellon is about".

147
00:07:31,910 --> 00:07:34,290
之后 我去和拉吉·瑞迪
Then I went to work with Raj Reddy on

148
00:07:34,910 --> 00:07:36,380
一起研究语音识别
speech recognition.

149
00:07:36,540 --> 00:07:40,890
拉吉建议我使用
Raj was suggesting that I should use Expert System

150
00:07:40,910 --> 00:07:41,870
专家系统
for speech recognition.

151
00:07:45,040 --> 00:07:47,090
嗯 我非常尊重拉吉
well, I respect Raj greatly.

152
00:07:47,240 --> 00:07:52,580
那时候这个技术既流行
At that time, it was a very popular technology

153
00:07:52,600 --> 00:07:54,010
又容易上手
and it is plausible.

154
00:07:54,030 --> 00:07:57,440
一个叫 Victor Zhu 的人编写了一些新颖的程序
A guy named Victor Zhu writes special programs.

155
00:07:57,460 --> 00:08:00,430
所以拉吉说 哎 我们来效仿 Victor Zhu 吧
So Raj said well let's just emulate the Victor Zhu.

156
00:08:00,550 --> 00:08:02,940
所以我们干了一年
So I did that for one year

157
00:08:02,960 --> 00:08:05,190
的确发表了一些成果
and we really published what we did

158
00:08:05,210 --> 00:08:07,090
我发现我们走到了死胡同
and I saw it was an deadend

159
00:08:07,110 --> 00:08:08,310
再走下去是没用的
and it wasn't going to work.

160
00:08:08,470 --> 00:08:10,340
所以我不得不面对一个问题
So I had to face the issue,

161
00:08:10,360 --> 00:08:13,360
我是否真的挑战了我的博士生导师
do I actually challenge my Ph.D advisor

162
00:08:13,380 --> 00:08:14,990
尝试了不同的东西
and try something different

163
00:08:15,170 --> 00:08:16,750
或者按照他所说的
or do what he says

164
00:08:16,770 --> 00:08:21,460
研究了我的系主任说的不要做的事情
and graduate what my department chair said not to do.

165
00:08:21,480 --> 00:08:22,940
所以我挣扎了一下 说
So I struggled a bit and said

166
00:08:22,960 --> 00:08:25,710
"额 我真的想在这个领域里
"well, I really wanted to be the best thesis

167
00:08:25,730 --> 00:08:27,730
有所成就
in this sub-category

168
00:08:27,940 --> 00:08:30,700
但我不知道怎么改进"
but I didn't know how to make it better",

169
00:08:30,720 --> 00:08:33,900
所以幸运的是 我遇到了彼得·布朗
so it was lucky that I met Peter Brown,

170
00:08:34,090 --> 00:08:39,150
另一个在 IBM 学习的 CMU 学生
who was another CMU student studying at IBM,

171
00:08:39,170 --> 00:08:42,210
他回来告诉了我隐马尔可夫模型
so he came back and told me the hidden Markov models

172
00:08:42,380 --> 00:08:44,480
隐马尔可夫模型在当时
hidden Markov models at that time

173
00:08:44,500 --> 00:08:46,340
可是一个神秘的新事物
had been a cryptic new thing.

174
00:08:46,500 --> 00:08:47,870
是的 没人知道它
it was. No one knew about it.

175
00:08:47,890 --> 00:08:49,590
它不是专家系统
It wasn't Expert System.

176
00:08:49,610 --> 00:08:50,760
没有用于机器学习的代码规则
It has no rules of code in it for machine learning.

177
00:08:50,780 --> 00:08:51,610
对
right.

178
00:08:51,630 --> 00:08:55,020
令人惊奇的是 你有一台机器
It was fascinating that you had a machine

179
00:08:55,040 --> 00:08:58,640
向它丢进一些数据 它会学习一些东西
that you could throw data and it learns what A and B and C.

180
00:08:58,660 --> 00:09:02,100
它是现在深度学习的简洁版
It is kind of a simple version of deep learning today.

181
00:09:02,120 --> 00:09:04,340
所以用了一个周末以后
So I implemented it over a weekend

182
00:09:04,360 --> 00:09:06,370
我发现它太神奇了
and I saw that it was amazing.

183
00:09:06,390 --> 00:09:07,710
我试过 Toy 数据
I tried to Toy Data.

184
00:09:07,730 --> 00:09:09,340
那应该有用
I saw that should work.

185
00:09:09,590 --> 00:09:15,940
我基本上会喝很多咖啡
I basically drank a lot of coffee

186
00:09:15,960 --> 00:09:18,810
去找导师
and went to my advisor and said

187
00:09:18,830 --> 00:09:21,540
说：“拉吉 我喜欢语音识别
"Raj, I love speech recognition

188
00:09:21,560 --> 00:09:23,700
但我不会去用专家系统”
but I'm not gonna use Exper System"

189
00:09:24,140 --> 00:09:25,760
他说 你想做什么
and he said what do you want to do.

190
00:09:25,780 --> 00:09:27,770
我说我想用隐马尔可夫模型
I said I gonna use hidden Markov models

191
00:09:27,920 --> 00:09:30,310
虽然那不一定有用
I am not sure that would work

192
00:09:30,330 --> 00:09:32,100
我们争论了一会
and we debated for a while.

193
00:09:32,120 --> 00:09:34,490
最后 他认识到我很固执
In the end, he saw that I was stubborn.

194
00:09:34,510 --> 00:09:37,170
所以他说了一些话 这些话让我铭记终生
So he said something I remember my whole life.

195
00:09:37,190 --> 00:09:39,860
他说 “开复 我不同意你的观点
He said, "Kaifu, Idon't agree with you,

196
00:09:39,880 --> 00:09:40,870
但我支持你”
but I support you".

197
00:09:41,580 --> 00:09:45,240
我认为这不仅是教授做过的
That I think was not the only most generous thing

198
00:09:45,260 --> 00:09:46,690
最宽厚的事
a professor could do,

199
00:09:46,710 --> 00:09:49,940
而且是一种令人赞叹的领导力
but also an amazing style of leadership.

200
00:09:50,080 --> 00:09:52,030
如果你想领导聪明的人
If you want to lead smart people,

201
00:09:52,050 --> 00:09:53,730
不要告诉他们要做什么
you cannot tell them what to do,

202
00:09:53,750 --> 00:09:55,150
而要引导他们发挥自己的热情
you have to lead them to use their passion.

203
00:09:55,330 --> 00:09:55,700
谢谢你
Thank you.

204
00:09:55,720 --> 00:09:57,970
老实说 拉吉 如果你在看专访
Honestly, Raj if you were watching,

205
00:09:57,990 --> 00:09:58,980
记得我们爱你
we love you.

206
00:09:59,390 --> 00:10:00,720
你对卡内基梅隆的贡献
You work more for Carnegie Mellon

207
00:10:00,740 --> 00:10:01,380
比任何人都多
than anybody else.

208
00:10:01,400 --> 00:10:02,860
当我来到卡内基梅隆
I had been in the same theme

209
00:10:02,880 --> 00:10:04,660
我一直研究同一个课题
when I came to the Carnegie Mellon

210
00:10:04,680 --> 00:10:05,740
从来没有和你直接合作过
I had never worked with you directly,

211
00:10:05,760 --> 00:10:07,120
和其他人合作
I worked with somebody else.

212
00:10:07,360 --> 00:10:09,390
但我们俩的办公室是紧挨着的
But I was literally next door to your office.

213
00:10:10,000 --> 00:10:14,840
彼得·布朗是一个有信誉影响力的人
Peter Brown is a person who had credit impact.

214
00:10:15,590 --> 00:10:17,930
彼得很低调
Peter is very low profile.

215
00:10:18,060 --> 00:10:19,300
不过你要是去谷歌搜他
But if you google him

216
00:10:19,320 --> 00:10:23,050
你会发现他在 IBM 语音组工作
you will see that he worked in the IBM speech group.

217
00:10:23,070 --> 00:10:24,930
他和鲍勃·默瑟做了第一个
He and Bob Mercer did the first

218
00:10:24,950 --> 00:10:27,910
统计机器翻译项目
statistical machine translation.

219
00:10:28,090 --> 00:10:30,350
神奇的是 那时候 每个人翻译的时候
It was fascinating at that time everybody

220
00:10:30,370 --> 00:10:32,320
都死抠语法
translated by syntax,

221
00:10:32,340 --> 00:10:35,930
导致翻译的版本差强人意
translated never quite what you want.

222
00:10:35,950 --> 00:10:39,330
彼得和鲍勃说 我们用包模型
And Peter and Bob said is let's use the Bag Model,

223
00:10:39,350 --> 00:10:41,550
让我们把单词全部整合到一起
let's take every word and do a mapping

224
00:10:41,570 --> 00:10:43,280
来做两种语言里的单词的一一映射吧
of the word into another language.

225
00:10:43,420 --> 00:10:45,150
我们再用另一种语言模型
Let's take another language model

226
00:10:45,170 --> 00:10:48,910
把新的包放到一句话里
to put the new bags into one sentence.

227
00:10:49,060 --> 00:10:52,690
语言学的东西是很玄乎的
The linguist thing is heretical;

228
00:10:52,710 --> 00:10:53,800
你怎么可能做到这些呢？
how did you possibly do that?

229
00:10:53,820 --> 00:10:54,967
这种做法把某物
This regards

230
00:10:54,987 --> 00:10:56,150
当成了一种语言
Something like a language.

231
00:10:56,170 --> 00:10:57,400
它们更有用
They work better.

232
00:10:57,420 --> 00:10:58,510
所以他们用这个
So they used this.

233
00:10:58,530 --> 00:11:01,740
我记得加拿大的国会辩论
I remember the Canadianparliamentary debates,

234
00:11:01,760 --> 00:11:03,190
由于辩论内容直接从英文
because they were literally translated

235
00:11:03,210 --> 00:11:04,430
翻译成了法文
literally from English to French.

236
00:11:04,450 --> 00:11:06,360
需要一个巨大的语料库 对吧？
This is huge corpus of data, right?

237
00:11:06,380 --> 00:11:10,550
是的 因为当时没有很多双语资料
Yes. Becauseat that time there was not much bilingual data.

238
00:11:10,570 --> 00:11:14,030
加拿大国会一直都有能力
Canada was a country where the parliament

239
00:11:14,050 --> 00:11:16,510
直接产出高质量的译文
has always a direct translation of very high quality one.

240
00:11:16,530 --> 00:11:17,760
所以他们做到了这些
So they did that.

241
00:11:17,780 --> 00:11:19,680
您是世界上第一位
you are one of the first machine learning people

242
00:11:19,700 --> 00:11:20,440
机器学习者
in the world.

243
00:11:20,460 --> 00:11:20,800
对
Yes.

244
00:11:20,820 --> 00:11:23,050
他们就像你在卡内基梅隆研究语音识别一样
as you were at Carnegie Mellon for speech recognition

245
00:11:23,070 --> 00:11:24,760
只是做了不同的语言翻译
but they did different language translation.

246
00:11:24,780 --> 00:11:27,390
这是世界上第一台应用这个原理的机器
The first machine in the world to put the principle

247
00:11:27,520 --> 00:11:30,480
接着它推动了谷歌和其他人打造了一流的
that then drove Google and others to build their amazing

248
00:11:30,640 --> 00:11:31,660
语言翻译引擎
language translation engines.

249
00:11:31,680 --> 00:11:34,150
没错 IBM 有很多天才
that's right. IBM has amazing people.

250
00:11:34,170 --> 00:11:35,290
而作为一个旁观者
And, as a side note,

251
00:11:35,310 --> 00:11:36,680
鲍勃·默瑟和彼得·布朗
Bob Mercer and Peter Brown

252
00:11:36,700 --> 00:11:39,330
加入了 Resonance Technology
went off to join Resonance Technology,

253
00:11:39,450 --> 00:11:42,240
它的对冲基金可能拥有
which was probably the highest return

254
00:11:42,490 --> 00:11:44,300
世界上最高的回报定量
quantitative hedge fund in the world.

255
00:11:44,320 --> 00:11:47,660
每年都有30-50％的回报
It's like 30-50% return every year.

256
00:11:47,680 --> 00:11:49,240
是的 他们有两个基金
Yes. They have two funds.

257
00:11:49,260 --> 00:11:51,270
他们自己的钱的基金的回报是 71%
For their own money they made 71%

258
00:11:52,580 --> 00:11:55,060
全世界其他人的钱的基金回报是 30-50％
for the rest of the world they made 30-50%.

259
00:11:55,680 --> 00:11:56,940
他们做得很好
They did very very well.

260
00:11:56,960 --> 00:12:00,600
哈哈 我自己的投资只有5％的收益
I only make 5% in my daily trading activities.

261
00:12:01,100 --> 00:12:05,440
然后你去了微软
Then you went to Microsoft

262
00:12:05,460 --> 00:12:08,340
当我问你的时候 你提到的第一件事
and when I asked you about the very first thing

263
00:12:08,360 --> 00:12:10,960
是你解雇了70名语言学家
you mention is you fired 70 linguists.

264
00:12:11,820 --> 00:12:15,660
你声称你的名誉将毁于一旦
You claim you fame to fire.

265
00:12:15,890 --> 00:12:17,510
关键不是我的名誉
it is not my fame.

266
00:12:17,530 --> 00:12:19,380
其实那是个非常困难的时期
Actually it was a very difficult period.

267
00:12:19,400 --> 00:12:22,020
因为我最初去微软
Because I went to Microsoft initially to

268
00:12:22,040 --> 00:12:23,990
是建立微软中国研究院
found Microsoft Research China,

269
00:12:24,010 --> 00:12:25,460
他们有大量的资金
which had huge amount of funds

270
00:12:25,480 --> 00:12:28,220
雇了很多人去做有趣的事情
and hired a lot of people to do fun things.

271
00:12:28,240 --> 00:12:30,360
总是件有趣的事 雇人
It is always fun to hire people

272
00:12:30,380 --> 00:12:32,510
召集像您这样的人才
and bring people who are like you

273
00:12:32,530 --> 00:12:34,620
赋予他们自由并与他们一起工作
and give them freedom and work with them.

274
00:12:34,640 --> 00:12:36,870
那就是我们当时在微软中国研究院做的事
That was we did in Microsoft Research China.

275
00:12:36,890 --> 00:12:37,687
这也是我们今天在创新工厂
That is what we do today

276
00:12:37,707 --> 00:12:39,390
合资企业做的事
in Sinovation Ventures.

277
00:12:39,410 --> 00:12:43,270
但是不幸的是 大概是因为我做得太好了
But unfortunately, I guess I did good enough jobs,

278
00:12:43,290 --> 00:12:45,450
比尔·盖茨说 “开复很不错
said Bill Gates, "well Kai-fu is pretty good,

279
00:12:45,470 --> 00:12:47,170
我们把他拉回来
let's pull him back to

280
00:12:47,190 --> 00:12:50,460
给他一些有问题的团队
and let's give him some problematic teams

281
00:12:50,480 --> 00:12:51,670
看看他会怎么做”
and see what he does."

282
00:12:51,690 --> 00:12:54,050
给我的其中一支团队
And one of the teams he asked me to lead

283
00:12:54,070 --> 00:12:55,630
是自然语言小组
was the natural language group,

284
00:12:55,790 --> 00:13:01,290
叫 NLG 这个团队一共大概有 110 人
known as NLG. It was a team for about 110 people.

285
00:13:01,310 --> 00:13:02,530
我猜都是博士 对吧？
PhD I guess, right?

286
00:13:02,550 --> 00:13:05,830
110 个人基本上全是博士
110, mostly PhD.

287
00:13:07,270 --> 00:13:09,340
其中70％是语言学家
70% of them are linguists,

288
00:13:10,300 --> 00:13:12,630
但不一定是计算语言学家
not necessarily computational linguists,

289
00:13:12,650 --> 00:13:14,000
也不一定懂计算
some are computational, some are not,

290
00:13:14,020 --> 00:13:16,440
基本上他们没有写过任何代码
but basically they didn't write any code

291
00:13:16,460 --> 00:13:18,170
也不懂算法
they didn't understand algorithms.

292
00:13:18,190 --> 00:13:21,100
但是他们确实
But they did work very hard to

293
00:13:21,120 --> 00:13:24,500
非常努力地完善每个英文句子
make every English sentence parcel as well as possible

294
00:13:24,520 --> 00:13:27,160
还写了一些检测语法错误的规则
and they wrote rules to detect grammar errors.

295
00:13:27,180 --> 00:13:28,560
所以出来的产品不算差
So the product isn't bad.

296
00:13:28,640 --> 00:13:30,310
如果你用 Microsoft Word
If you use Microsoft Words,

297
00:13:30,470 --> 00:13:32,410
语法检查功能也还行
the grammar checker isn't bad.

298
00:13:32,430 --> 00:13:34,540
他们修复了相当多的错误
They fix a fair amount of errors.

299
00:13:34,740 --> 00:13:38,210
但比尔说“开复 带着这110个人
But Bill says "Kai-fu, take these 110 people

300
00:13:38,230 --> 00:13:43,080
去研究自然语言对话技术吧”
and turn them into a natural language dialog technology".

301
00:13:43,360 --> 00:13:44,630
我跟团队谈了谈
I talked to the team

302
00:13:44,650 --> 00:13:45,870
了解了这个技术
and I looked to the technology

303
00:13:45,890 --> 00:13:47,510
然后说我没办法做这个
and I said there was no way

304
00:13:47,530 --> 00:13:51,300
因为更多的语言学家不能解决问题
because the future cannot possibly be more linguistics

305
00:13:51,320 --> 00:13:53,200
需要更多的统计学家
and there should be more statistics.

306
00:13:53,340 --> 00:13:55,020
更准确地说
Just to put it correctly.

307
00:13:55,040 --> 00:13:57,800
你曾经带领过70位世界级的语言学家
You took 70 world class linguists

308
00:13:57,820 --> 00:14:01,900
而他们供职于最受推崇的微软公司
who were hired by the most revered company - Microsoft.

309
00:14:01,920 --> 00:14:02,410
是的
Yes.

310
00:14:05,320 --> 00:14:09,040
你觉得在这个小统计公式里
And you felt the little statistic formula,

311
00:14:09,060 --> 00:14:11,760
其中有抽象的模式和数据
there was abstruct patterns and data

312
00:14:11,780 --> 00:14:14,390
源于70名顶尖的专家 是吗？
that would be the 70 super smart experts. Yes?

313
00:14:14,410 --> 00:14:16,200
是的
Yes, I did.

314
00:14:16,220 --> 00:14:21,730
他们没有重新研究语法检查
They didn't re-implement the grammar checker

315
00:14:21,750 --> 00:14:23,850
而是投入到了其他任何任务上
but on any other tasks yes they did.

316
00:14:23,990 --> 00:14:26,160
所以回到数据上来说
so machine learning, back to the data,

317
00:14:26,180 --> 00:14:28,860
你第一个捕捉到了机器学习
you were one of the very first striking eyes to witness

318
00:14:28,880 --> 00:14:31,280
能击败人类专家的地方
where she beats human experts.

319
00:14:31,510 --> 00:14:32,750
是的 不过当然
Yes, but of course

320
00:14:32,770 --> 00:14:35,270
微软有很多人非常擅长机器学习
Microsoft has a lot of people who are very good

321
00:14:35,290 --> 00:14:37,730
比如
in machine learning like.

322
00:14:37,750 --> 00:14:39,320
我不是唯一的那个
I wasn't alone.

323
00:14:39,340 --> 00:14:41,050
但不幸的是
But the group I inherited

324
00:14:41,070 --> 00:14:43,400
我接手的那个团队第一步走错了
unfortunately had a wrong first step.

325
00:14:43,420 --> 00:14:46,500
要想解雇70个人是很难的
It was very difficult to fire 70 people

326
00:14:46,520 --> 00:14:48,420
这会对他们的家人产生极大的影响
and that had an impact to their family

327
00:14:48,440 --> 00:14:50,810
他们不理解我的决定
and they didn't understand my decision

328
00:14:50,990 --> 00:14:52,500
我们争论了很多次
and we had a lot of fighting

329
00:14:52,520 --> 00:14:53,920
他们还向比尔抱怨
and they complained to Bill.

330
00:14:53,940 --> 00:14:55,780
还好我们终于完成了项目构建
But we ended up the building,

331
00:14:55,900 --> 00:14:58,430
如果你用 Windows Support
if you use the Windows Support today,

332
00:14:58,450 --> 00:15:01,400
你可以手动输入你的问题
you type a question to say you have a problem

333
00:15:01,420 --> 00:15:04,500
而如何修复这个问题
and how to fix something that was based

334
00:15:04,520 --> 00:15:06,260
最终是基于我构建的系统
eventually on the system I built.

335
00:15:06,280 --> 00:15:08,110
它的确很有用也很稳健
And it works. It is robust.

336
00:15:08,300 --> 00:15:10,340
这是个智能系统
It is a very smart system.

337
00:15:10,360 --> 00:15:12,700
不可能在语言系统的
It couldn't have been possible

338
00:15:12,720 --> 00:15:14,720
框架下构建起来
to have been built under linguist system.

339
00:15:14,740 --> 00:15:15,600
的确令人佩服
it's quite amazing,

340
00:15:15,620 --> 00:15:18,900
因为你是我所在领域的杰出科学家之一
because you are one of the eminent scientists in my field.

341
00:15:18,920 --> 00:15:23,080
人们专程来卡内基梅隆只为了和你握手
People come to Carnegie Mellon to shake your hand.

342
00:15:23,100 --> 00:15:23,790
不 没那回事
No, not at all.

343
00:15:23,810 --> 00:15:26,030
之后 您当了经理
and then you became a manager

344
00:15:26,050 --> 00:15:28,690
做统计相关业务
and you did statistic business,

345
00:15:28,710 --> 00:15:30,750
这个转变还比较大
which is a quite shift of career.

346
00:15:30,970 --> 00:15:34,210
您后来去了一个搜索引擎公司
And then you moved to a search engine company,

347
00:15:34,350 --> 00:15:35,290
不过名字我忘了
whose name I forgot.

348
00:15:35,310 --> 00:15:35,860
哈哈哈
Hahaha.

349
00:15:35,880 --> 00:15:37,220
能再告诉我们叫什么名字吗？
what's the name again

350
00:15:37,870 --> 00:15:38,590
谷歌
Google.

351
00:15:38,610 --> 00:15:41,410
呵呵 我应该听说过他们
Hehe. I should know them.

352
00:15:41,430 --> 00:15:43,600
额 在中国它还不太普及
Well, it's not that known in China.

353
00:15:49,100 --> 00:15:51,100
我猜你后来开始为谷歌在中国的发展
then you started your role in Google

354
00:15:51,120 --> 00:15:52,270
做贡献 对吧？
in China I guess, right?

355
00:15:52,290 --> 00:15:55,620
对 在2005年 我创立了谷歌中国
yes, I started Google China. 2005.

356
00:15:56,220 --> 00:15:58,860
他们怎么看待
what have they said about between

357
00:15:58,880 --> 00:16:01,200
谷歌中国和中国政府之间的关系？
Google China and China's government?

358
00:16:01,220 --> 00:16:02,930
好像并不总是...
It wasn't always as…

359
00:16:03,550 --> 00:16:05,750
嗯 谷歌总是很难
well, it was always difficult for Google

360
00:16:05,770 --> 00:16:07,950
深入了解中国文化
to understand the Chinese culture.

361
00:16:07,970 --> 00:16:10,190
这需要大量的实践
And this requires practice.

362
00:16:10,210 --> 00:16:11,420
有什么区别？
what are the differences.

363
00:16:12,120 --> 00:16:12,850
额
Well,

364
00:16:12,870 --> 00:16:14,190
我会注意的
I will be carefully here.

365
00:16:14,210 --> 00:16:17,340
嗯 有什么区别
Well, what are the differences.

366
00:16:17,840 --> 00:16:18,650
我爱中国
I love China.

367
00:16:18,670 --> 00:16:19,920
好的 我可以回答
Ok I can answer that.

368
00:16:19,940 --> 00:16:22,200
你在谷歌工作过
You worked at Google.

369
00:16:22,220 --> 00:16:25,270
我们都知道 谷歌的根本任务
We all know Google's fundamental mission

370
00:16:25,290 --> 00:16:27,390
是整合世界各地的信息
is to organize the world's information

371
00:16:27,410 --> 00:16:30,960
并随时提供给大家
and make it available to everybody at anytime.

372
00:16:31,150 --> 00:16:33,920
所以我认为他们不能做到
So I think they take a special exception

373
00:16:34,080 --> 00:16:36,470
这一点的情况是很少的
to situations where they cannot do that.

374
00:16:36,490 --> 00:16:39,910
是的 关于中国法律和的辩论
Yes. Debates about Chinese laws and or on.

375
00:16:39,930 --> 00:16:41,420
我赞同你
I agree with you.

376
00:16:42,500 --> 00:16:44,080
那么继续.
Then press forward now,

377
00:16:44,100 --> 00:16:46,910
你自己有一些资金
you have your own fund,

378
00:16:48,070 --> 00:16:52,180
一组公司
a mount of money, you have a portfolio of companies,

379
00:16:52,330 --> 00:16:54,050
个人孵化中心
your incubation center

380
00:16:54,070 --> 00:16:55,330
是你令高效的人工智能
and you make efficient artificial intelligence

381
00:16:55,350 --> 00:16:56,440
成为迄今为止最轰动的事
the biggest thing ever,

382
00:16:56,580 --> 00:16:59,420
但你同时也会投资 我知道
but you also fund, I know,

383
00:16:59,440 --> 00:17:01,450
我们已经展示了
we already showed girls

384
00:17:01,470 --> 00:17:05,090
一些事业有成的女孩
who have aspiring career.

385
00:17:05,110 --> 00:17:06,130
发生了什么？
What's happening?

386
00:17:06,662 --> 00:17:07,744
嗯
well,

387
00:17:07,764 --> 00:17:11,360
我在2009年创立了创新工厂合资公司
I founded Sinovation Ventures in 2009.

388
00:17:11,380 --> 00:17:13,860
这不是"罪恶的欢呼" 而是"标志的欢呼"
it is not "sin ovation" but "sign ovation"

389
00:17:13,880 --> 00:17:15,170
嗯 我称之为"标志的欢呼"
well I call it "sign ovation",

390
00:17:15,190 --> 00:17:16,260
因为我们没犯罪
because we don't sin.

391
00:17:16,280 --> 00:17:17,410
呵呵
hehe

392
00:17:17,430 --> 00:17:20,680
我们没什么罪 我们尽量不这样
Well, we don't sin very much. We try not to.

393
00:17:21,050 --> 00:17:23,430
我以为这是"罪恶的欢呼"呢
I thought it was "sin ovation".

394
00:17:23,610 --> 00:17:25,450
也许是因为发音很像？
easy to pronounce, perhaps?

395
00:17:25,470 --> 00:17:27,440
但 Sino 是中国的意思
But Sino is like China.

396
00:17:27,460 --> 00:17:29,230
对 我知道
It is good. I know.

397
00:17:29,740 --> 00:17:32,550
当我们创办创新工厂合资公司时
when we started the Sinovation Ventures,

398
00:17:32,570 --> 00:17:35,310
我们想做所有的技术投资
we wanted to do all tech investing.

399
00:17:35,550 --> 00:17:39,670
但当时大部分中国技术是模仿国外的
But at that time, much of tech in China were still copycats.

400
00:17:40,280 --> 00:17:44,380
在这个阶段 人们想投资
It wasn't at a stage where you could really find to fund

401
00:17:44,400 --> 00:17:47,580
一个AI公司、科技公司、数据库公司
an AI company or a tech company or a database company

402
00:17:47,600 --> 00:17:48,420
或其他公司是很难的
or something.

403
00:17:49,340 --> 00:17:51,640
因为市场规模大 
Because the market is large

404
00:17:51,790 --> 00:17:55,070
产品需求量大
and the need for product is large

405
00:17:55,090 --> 00:17:57,080
但创造力
but the degree of creativity

406
00:17:57,650 --> 00:18:00,200
和知识深度不够
and the depth of knowledge wasn't there.

407
00:18:00,370 --> 00:18:01,870
所以我们不得不说 好吧
So we had to say, ok,

408
00:18:01,890 --> 00:18:04,970
我们拿了投资者的钱就得赚钱
we took investors money we got to make money

409
00:18:04,990 --> 00:18:07,920
所以我们要投资任何能赚钱的地方
so we gonna invest whatever makes money.

410
00:18:08,660 --> 00:18:10,590
我们擅长
What we are good at is

411
00:18:10,780 --> 00:18:13,530
技术方面
things that are propelled by technology.

412
00:18:13,550 --> 00:18:16,600
所以我们把钱用在了
So we would invest in anything that fits

413
00:18:16,620 --> 00:18:21,180
手机、AI和任何其他热点上
the exponential wave of mobile, AI, any other wave.

414
00:18:21,200 --> 00:18:24,560
所以我们投资了一些不寻常的公司
So we invested in some very unusual companies

415
00:18:24,580 --> 00:18:27,030
比如 SNH48
like the SNH48.

416
00:18:27,050 --> 00:18:30,820
所以你用美金还是人民币投资？
so you take American money or take Chinese money?

417
00:18:30,840 --> 00:18:31,860
我们两个都用
we take both.

418
00:18:32,090 --> 00:18:34,860
SNH48 不算一个真正意义上的技术公司吧
SNH48 is not an exact tech company.

419
00:18:35,760 --> 00:18:37,930
你知道他们有一些技术
There is some tech, you know

420
00:18:38,590 --> 00:18:42,810
这是个众包的大数据公司
It's a crowd sourcing, big data company.

421
00:18:42,830 --> 00:18:43,990
别不好意思 这公司很棒
Don't be ashamed, it is great.

422
00:18:44,310 --> 00:18:47,740
是的 我真的很惊讶
Yes. I was really surprised

423
00:18:47,760 --> 00:18:49,330
塞巴斯蒂安竟然知道他们
Sebastian knew about them.

424
00:18:49,350 --> 00:18:52,860
我不知道你们当中谁知道 SNH48
I don't know few of your guys know SNH48.

425
00:18:52,880 --> 00:18:53,890
这已经是一种投资了
That is already an investment.

426
00:18:53,910 --> 00:18:55,340
我们是第一批投资者
We are the first investors.

427
00:18:55,360 --> 00:19:00,100
因为我们看到 观看这些电视节目
Because we saw that watching these shows on TV

428
00:19:00,120 --> 00:19:02,530
只会产生大量的收入
was only going to generate so much revenue,

429
00:19:02,550 --> 00:19:06,300
如果你能让人们参与投票和花钱
if you could have people participate and vote and pay.

430
00:19:06,320 --> 00:19:08,320
这是个更大的机遇
That is much bigger opportunity.

431
00:19:08,340 --> 00:19:10,630
那就是我们的理念
That was the concept we have.

432
00:19:10,650 --> 00:19:12,930
我们都看电视
we all watch TV and

433
00:19:12,950 --> 00:19:13,950
和游戏节目
their game shows,

434
00:19:13,970 --> 00:19:17,480
美国的人才都聚集在了一起
American talents, come together in one world.

435
00:19:17,500 --> 00:19:20,750
我有个问题
Here is a question I wondered about.

436
00:19:20,770 --> 00:19:21,650
当我还是孩子的时候
When I was a kid.

437
00:19:21,670 --> 00:19:27,230
我隐约感觉日本会统治世界
I was kind of known that Japan would rule the world,

438
00:19:27,250 --> 00:19:31,840
日本会成为动态随机存取记忆体
like, Japan became the epicenter for DRAM

439
00:19:31,860 --> 00:19:36,430
半导体行业和超强性能 CPU 的技术中心
and for most semi-conductor and very exceptional CPUs.

440
00:19:36,450 --> 00:19:40,090
日本的投资不可磨灭
And Japan made an investment which cannot disappear.

441
00:19:40,790 --> 00:19:42,360
而过去十年
And the last ten years,

442
00:19:42,380 --> 00:19:44,360
我们知道中国引领了世界
we have known the China has taken off the world.

443
00:19:44,380 --> 00:19:46,970
而且和日本有区别
And there is a difference.

444
00:19:47,560 --> 00:19:48,440
日本与中国的
What's the difference in the

445
00:19:48,460 --> 00:19:50,070
成功秘诀有什么区别？
recipe between Japan and China?

446
00:19:51,000 --> 00:19:52,880
呵呵 我不太了解日本
Well I'm not an expert in Japan.

447
00:19:52,900 --> 00:19:55,490
但是我的一个朋友最近
But one of my friends recently

448
00:19:55,510 --> 00:19:57,230
接手了一家日本公司 
took over a Japanese company

449
00:19:57,380 --> 00:20:01,100
他描述了他看到的一些日本人的优缺点
and he described the good and bad things he saw.

450
00:20:01,260 --> 00:20:04,210
优点是注意细节
The good things are attention to detail.

451
00:20:04,370 --> 00:20:09,960
他们注重极小的技术问题
Extreme value of tiny technical issues

452
00:20:09,980 --> 00:20:14,210
努力确保事情完美无缺
and making sure things are done flawlessly and beautifully.

453
00:20:14,760 --> 00:20:21,440
缺点在于日本文化不是比较饥饿的文化
The problem is that it is not a very hungry culture.

454
00:20:21,610 --> 00:20:24,280
人们不对抗 只是努力工作
People don't fight and work extremely hard.

455
00:20:24,300 --> 00:20:26,750
他们的努力程度不及中国人
They work hard but not as hard as in China.

456
00:20:26,910 --> 00:20:28,710
而且 他们比较注重阶级
And also, it is very hierarchical.

457
00:20:28,960 --> 00:20:31,000
我朋友称 你知道董事会
So he described in a board meeting,

458
00:20:31,020 --> 00:20:33,280
有四个级别
you know there are four layers of tables,

459
00:20:33,300 --> 00:20:36,220
当有问题要讨论的时候
and when issues came up for discussion,

460
00:20:36,240 --> 00:20:38,970
高级副总裁会转向副总裁
the senior VP would turn around to their VPs

461
00:20:38,990 --> 00:20:40,470
问他们答案
and say what is the answer to that.

462
00:20:40,490 --> 00:20:42,240
副总裁转向董事
The VP would turn around to the directors,

463
00:20:42,260 --> 00:20:43,450
董事转向经理
and director to the managers,

464
00:20:43,470 --> 00:20:46,140
经理转向普通员工
manager would turn around to the individual contributor

465
00:20:46,160 --> 00:20:49,410
然后他们会叫某人去做事和传播信息
then they would call somebody and information propagates up.

466
00:20:49,530 --> 00:20:50,640
这就像一个我听过的游戏
it is like a hear game

467
00:20:50,660 --> 00:20:51,830
你们一直重复这个词
where you repeat the word

468
00:20:51,850 --> 00:20:54,770
直到最后你会问这是原来那个词吗？
and you gonna say this is the same word?

469
00:20:54,790 --> 00:20:57,430
是的 我认为中国的大公司
yes. I think large companies in China

470
00:20:57,450 --> 00:21:00,360
建立了等级文化
build a hierarchical culture

471
00:21:00,380 --> 00:21:02,590
管理层并没有创造自己的价值
where management didn't add their value.

472
00:21:02,610 --> 00:21:04,430
等等 你们中国有很多大公司
but, hold out, you have large companies,

473
00:21:04,450 --> 00:21:08,000
有阿里巴巴、腾讯、百度、京东
you have Alibaba, Tencent, Baidu, JD.

474
00:21:08,020 --> 00:21:09,660
这些公司怎么避免这种情况？
How do these companies avoid it?

475
00:21:10,000 --> 00:21:12,380
以阿里巴巴为例
I will take Alibaba as an example.

476
00:21:12,400 --> 00:21:14,680
我认为马云的聪明之处
I think Jack Ma is a brilliant,

477
00:21:14,700 --> 00:21:17,520
在于他重塑公司的方式
in the way he reinvents the company.

478
00:21:17,790 --> 00:21:21,500
任何不断壮大的公司都会遇到一个问题
Any company that gets big would have a problem of

479
00:21:21,520 --> 00:21:23,720
聪明人感觉自己的能力达到了上限
smart people feeling like reach their ceiling,

480
00:21:23,740 --> 00:21:25,880
好像没有进步空间了
like cannot go up anymore.

481
00:21:25,900 --> 00:21:29,080
所以马云把他的公司分成……
So Jack organizes his company in,

482
00:21:29,100 --> 00:21:33,060
我不太记得具体数字….. 25个团体
I don't how many, 25 groups,

483
00:21:33,080 --> 00:21:35,980
每个团体都是一个独立的公司
each of which is an independent company

484
00:21:36,000 --> 00:21:38,850
每个公司都有一个顶峰
with a pinnacle that is a truly

485
00:21:38,870 --> 00:21:41,240
是其所在区域真正的十亿美元的公司
billion-dollar company in its zone

486
00:21:41,260 --> 00:21:45,260
有负责管理经理的CEO
with CEO taking responsibility accountable for the managers

487
00:21:45,280 --> 00:21:46,570
马云让经理轮岗
and he rotates them

488
00:21:46,590 --> 00:21:49,620
每个人都觉得他自己是CEO
but each person feels like they are a CEO.

489
00:21:49,640 --> 00:21:52,590
他们觉得 就好像 如果你是财务总监
They feel like, it is like, if you are a financial CEO,

490
00:21:52,610 --> 00:21:54,860
你不会想离开去另一家公司
you don't want to leave and do to another company,

491
00:21:54,880 --> 00:21:57,800
因为你本来就管理着一个大公司
because you are running as big a company as you can imagine.

492
00:21:57,960 --> 00:22:02,680
然而 所有25家公司都有一致的文化
Yet, all the 25 companies have a consistent culture.

493
00:22:02,790 --> 00:22:06,000
所以他也能引领和
So he is also able to lead

494
00:22:06,020 --> 00:22:08,630
复制一点阿里巴巴的发展策略
and replicate a little bit Alibabas.

495
00:22:08,650 --> 00:22:11,660
这使他们相对灵活
That keeps them relatively nimble,

496
00:22:11,680 --> 00:22:14,050
专注 遵循一贯的文化
focused yet consistent culture.

497
00:22:14,280 --> 00:22:15,940
我认为也许
That kind of,

498
00:22:16,160 --> 00:22:18,680
Alpabet 是这种模式下的一个尝试
I think maybe Alpabet is an attempt to this.

499
00:22:18,700 --> 00:22:23,950
Alpabet和伯克希尔·哈撒韦公司
Alfabet and Berkshire Hathaway

500
00:22:23,970 --> 00:22:25,760
有相同之处
have a same flavor of it.

501
00:22:25,780 --> 00:22:28,810
是的 所以我认为我们需要创新企业模式
yes. So I think we need to innovate in corporate model,

502
00:22:28,830 --> 00:22:30,310
阿里巴巴、Alpabet
Alibaba, Alpabet,

503
00:22:30,330 --> 00:22:32,460
伯克希尔·哈撒韦就是这样做的
Berkshire Hathaway are ones that have.

504
00:22:32,480 --> 00:22:34,040
我想也许日本大公司
I think maybe the Japanese companies

505
00:22:34,060 --> 00:22:35,110
还做不到这个
when are large cannot do that.

506
00:22:35,130 --> 00:22:39,510
人工智能真是太有趣了
interesting interesting. Artificial intelligence.

507
00:22:39,530 --> 00:22:39,980
当然
Yes.

508
00:22:40,000 --> 00:22:44,290
你曾经在卡内基梅隆讲的一个话题
a topic that you started at Carnegie Mellon.

509
00:22:44,310 --> 00:22:47,510
正好也是我当时谈论的话题
I was also being around and in the same topic.

510
00:22:48,480 --> 00:22:51,250
你当时正全身心地投入工作
You have dedicated whole of your energy to it.

511
00:22:51,270 --> 00:22:54,370
工作于该地区的一家内部创业公司
You worked in a in-house start-up company in the area.

512
00:22:54,390 --> 00:22:56,190
能说说它为什么对你这么重要么
Tell about it. Why is important.

513
00:22:56,940 --> 00:22:58,850
嗯 我觉得AI很重要
well, I think AI is important.

514
00:22:58,870 --> 00:23:00,880
因为它能改变一切
Because it will change everything.

515
00:23:00,900 --> 00:23:03,010
它比手机要重要得多
It is much more important than mobile.

516
00:23:03,190 --> 00:23:04,610
手机是一个新设备
Mobile is a new devise.

517
00:23:04,630 --> 00:23:05,350
也的确很重要
It's very important.

518
00:23:05,370 --> 00:23:06,600
这是一种能将我们
It's a new device

519
00:23:06,620 --> 00:23:08,240
大多数人联系在一起的新设备
that connects most of us.

520
00:23:08,260 --> 00:23:12,190
但AI不仅仅关乎人类 还影响着商业
But AI is not just to people, but to business.

521
00:23:12,210 --> 00:23:15,820
它将重塑商业 令它从传统转向
It is going to reinvent businesses from traditional

522
00:23:15,840 --> 00:23:18,500
娱乐和互联网
to entertainment to internet.

523
00:23:18,520 --> 00:23:21,810
每个公司 每一件事都会因此受到影响
Every company, every thing, is impacted.

524
00:23:21,940 --> 00:23:23,540
塞巴斯蒂安比任何人
Sebastian, more than any body,

525
00:23:23,560 --> 00:23:25,190
都了解自动车辆
knows about autonomous vehicles.

526
00:23:25,210 --> 00:23:27,320
它将会改变交通
That is going to change the future of

527
00:23:27,340 --> 00:23:29,090
运输的未来
transportation and delivery.

528
00:23:29,350 --> 00:23:32,430
想想财务、一切与金融相关的
You think about finance, everything financial,

529
00:23:32,450 --> 00:23:37,940
银行、保险、交易、证券、投资
banking, insurance, trading, security, investment.

530
00:23:37,960 --> 00:23:39,490
他们都有硬伤
They are all built wrong.

531
00:23:39,710 --> 00:23:42,830
做这些工作的人并不擅长这些
The people doing these jobs are not good at it,

532
00:23:42,850 --> 00:23:44,810
因为总有一些磕磕绊绊
because there are a number of crunching jobs.

533
00:23:44,830 --> 00:23:46,570
人永远不可能和机器一样
People can never be machines.

534
00:23:46,590 --> 00:23:49,430
所以大多数这些人会被机器所取代 
So most of these people would be replaced by machines,

535
00:23:49,450 --> 00:23:52,800
机器不仅更聪明 更准确
who are not only smarter, more accurate,

536
00:23:52,820 --> 00:23:55,610
也不会累 不会情绪化
but also they don't get tired, they are not emotional.

537
00:23:55,630 --> 00:23:59,720
机器将在全世界大大提升效率
This will create a huge amount of efficiency in the world.

538
00:23:59,740 --> 00:24:01,000
这就是我们要研究它的原因
That's why we work on it

539
00:24:01,020 --> 00:24:03,190
因为它具有巨大的经济价值
because it has so much economic value,

540
00:24:03,210 --> 00:24:06,770
而且我还可以解释其AI
but also because another role I can play

541
00:24:06,790 --> 00:24:09,630
对中国的潜在影响
is to explain its potential impact of AI in China

542
00:24:09,650 --> 00:24:13,110
因为它会冲击所有领域
because this will disrupt all the areas.

543
00:24:13,130 --> 00:24:13,590
你知道的
You know.

544
00:24:13,610 --> 00:24:15,500
我们已经在教育系统
The education system we have it wrong.

545
00:24:15,520 --> 00:24:17,301
银行系统上犯了错
The banking system is wrong.

546
00:24:17,321 --> 00:24:20,582
考虑到AI的冲击
And all these things, because of the AI disruption,

547
00:24:20,602 --> 00:24:24,048
我们需要为下一代做好准备
we need to prepare our next generations to be ready,

548
00:24:24,068 --> 00:24:26,954
因为如果他们接受的教育
because if they are being educated

549
00:24:26,974 --> 00:24:30,880
使得他们做重复性的工作
to become skilled in some repetitive work,

550
00:24:30,900 --> 00:24:32,880
就会被AI取而代之
it would be replaced by AI.

551
00:24:32,900 --> 00:24:35,564
他们需要考虑如何
They need to look at how to

552
00:24:35,584 --> 00:24:38,220
规划自己的职业和教育
plan their careers and education before that.

553
00:24:38,240 --> 00:24:41,560
另一个问题 我和你的角度一样
another question, which I have the same position as yours.

554
00:24:41,580 --> 00:24:43,536
但是我想听听你的回答
But I want to hear your answer.

555
00:24:43,723 --> 00:24:46,641
我们中间有75％的人在办公室做
75% of us work in office jobs,

556
00:24:46,958 --> 00:24:49,993
基本上是重复的工作
in basically repetitive jobs.

557
00:24:50,013 --> 00:24:51,267
所以你刚才告诉我
So you just told me

558
00:24:51,287 --> 00:24:53,513
每个人都会被电脑所取代
that each of them will be replaced by computer.

559
00:24:53,533 --> 00:24:54,342
当然
of course.

560
00:24:54,362 --> 00:24:55,799
这些人会怎么样？
what gonna happen to these people?

561
00:24:56,385 --> 00:24:58,967
好的 有几种可能的猜测
well, there are several possible speculations.

562
00:24:59,690 --> 00:25:01,182
我猜优达学城没有
I guess it comes out that Udacity hits

563
00:25:01,202 --> 00:25:01,905
培养这类人（稍微）
none of these (sort of).

564
00:25:02,608 --> 00:25:04,577
那是 如果你第一次这样做
that yes. If you first do that.

565
00:25:04,597 --> 00:25:07,014
再教育 的确是这样
Reeducation, yes.

566
00:25:07,483 --> 00:25:10,369
首先 不要太恐慌
Well, first of all. Not to panic too much.

567
00:25:10,389 --> 00:25:12,361
因为这些强大的AI机器
Because there will be taxes generated

568
00:25:12,381 --> 00:25:14,705
会产生税收
by these amazing AI machines

569
00:25:14,725 --> 00:25:17,025
税收会给人们带来收益
and taxed will feed the people.

570
00:25:17,045 --> 00:25:19,896
所以民主是社会主义的
so democracy would be socialist.

571
00:25:20,061 --> 00:25:22,874
我的意思是企业所得税可能是70％
I mean corporate gains tax might be like 70%,

572
00:25:22,894 --> 00:25:23,858
而不是30％
not 30%.

573
00:25:23,878 --> 00:25:27,151
你我都必须缴纳很多税
you and I have to pay a lot of taxes.

574
00:25:27,171 --> 00:25:28,768
但没有人会饿
But no one would go hungry.

575
00:25:28,788 --> 00:25:30,183
这就解决了一个大问题
So that solves the big problem.

576
00:25:30,206 --> 00:25:31,718
但那些被替代的人做什么呢
But what do they do.

577
00:25:31,835 --> 00:25:38,069
我认为他们应该想想一些
I think one is they think about

578
00:25:38,089 --> 00:25:40,453
需要深刻创意才能的工作
do they have deep creative talent.

579
00:25:40,473 --> 00:25:43,090
显然 有的人得到了一个机器人程序后
Obviously, someone got a program to robots

580
00:25:43,110 --> 00:25:44,868
成为了下一个毕加索
and becomes the next Picasso.

581
00:25:45,442 --> 00:25:51,548
第二 他们能否做AI不能做的事情
Secondly, can they take on something that AI cannot do.

582
00:25:51,712 --> 00:25:53,637
还有很多事情 AI做不了
There are still a lot of things that AI cannot do.

583
00:25:53,657 --> 00:25:58,219
你明白的 艺术、电影、幽默
You know. Art, movies, humor,

584
00:25:59,192 --> 00:26:03,188
手工艺、园艺
crafts, gardening.

585
00:26:03,587 --> 00:26:04,747
所有这些事情
All those things.

586
00:26:04,767 --> 00:26:07,313
都需要大量劳力
There are plenty of jobs that remain there.

587
00:26:07,794 --> 00:26:11,239
服务业的劳力需求最大
The largest quantity will be in services,

588
00:26:11,391 --> 00:26:14,379
例如 打扫、做饭
such as, you know cleaning, kitchen,

589
00:26:14,399 --> 00:26:17,286
照顾孩子和老人
taking care of the kids, taking care of elderly.

590
00:26:17,496 --> 00:26:22,010
而我认为今天的服务工作在社会上
And I think service jobs today don't get enough

591
00:26:22,266 --> 00:26:24,933
没有得到足够的重视和尊重
attention and respect in the society

592
00:26:24,953 --> 00:26:26,484
我们必须做出改变
and I think we have to change that.

593
00:26:26,613 --> 00:26:28,932
我认为日本其实是一个非常好的例子
I think Japan actually is a very positive example of that.

594
00:26:28,952 --> 00:26:30,256
如果你去日本
If you go to Japan,

595
00:26:30,276 --> 00:26:35,799
会看到那些努力做饭或切寿司的人
people who work so hard to make a bowl or to cut sushi,

596
00:26:35,819 --> 00:26:38,592
受到了神一样的待遇
they are treated like gods.

597
00:26:38,815 --> 00:26:40,670
但现在有些公司基本上
but there are now companies that basically

598
00:26:40,690 --> 00:26:42,085
都有做食物的机器人
have robots that make your food,

599
00:26:42,105 --> 00:26:43,795
叫做加利福尼亚的
that is called in California

600
00:26:43,815 --> 00:26:45,225
你可能见过
which you might know that

601
00:26:45,245 --> 00:26:46,538
在手机上订购食物
you order your food in your phone

602
00:26:46,558 --> 00:26:48,398
进入商店时食物已经准备好了
and when you enter the store, that is already ready

603
00:26:48,418 --> 00:26:50,378
准备食物的可能是机器人
and robots can prepare food for you.

604
00:26:50,519 --> 00:26:51,515
但是我们必须相信
but we have to believe.

605
00:26:51,535 --> 00:26:52,558
我是个美食家
I'm a foodie,

606
00:26:52,578 --> 00:26:56,238
我坚信人类会做出更好的食物
so. I firmly believe that humans will make better food

607
00:26:56,258 --> 00:26:57,831
如果你用心了
and if you put in your love,

608
00:26:57,851 --> 00:27:00,663
所有的日本寿司厨师用心了
that all Japanese sushi chefs put in,

609
00:27:00,683 --> 00:27:02,116
我觉得食物会变得更好吃
I think the food would taste better

610
00:27:02,136 --> 00:27:03,909
因为人们有更多的技能...
because there are more skills…

611
00:27:03,929 --> 00:27:06,382
来吧 像你说的
come on, there is a data-crunching job,

612
00:27:06,402 --> 00:27:07,644
这里有一个数据压缩的工作
in your own words.

613
00:27:08,206 --> 00:27:11,312
有台机器可以制作一千块寿司
Like, a machine can make a thousand pieces of Sushi.

614
00:27:11,332 --> 00:27:12,331
这不仅仅是切块 对吧？
well it is not just about cutting, right?

615
00:27:12,351 --> 00:27:14,517
它包括准备、选材
It includes preparing, choosing.

616
00:27:14,537 --> 00:27:16,849
我想浪漫一点
I'd like to be romantic a little bit

617
00:27:16,869 --> 00:27:18,994
认为还应该有服务行业
and think there are service jobs.

618
00:27:19,014 --> 00:27:21,955
你才是对的 我错了
And I even you are right and I'm wrong.

619
00:27:21,975 --> 00:27:22,811
呵呵
hehe

620
00:27:23,795 --> 00:27:28,307
虽然服务行业一直不受人们尊重
but even if service jobs cannot be revered,

621
00:27:28,327 --> 00:27:29,315
但是我们仍要努力
we have to try,

622
00:27:29,335 --> 00:27:32,256
毕竟大多数人将来从事的还是服务业
because most of the population will be service jobs.

623
00:27:32,276 --> 00:27:34,928
如果我们能够尊重这些人的话
If we treat these people with respect,

624
00:27:34,948 --> 00:27:37,823
还会觉得这些工作是不合需要？
if we feel these jobs are undesirable,

625
00:27:37,952 --> 00:27:42,654
还会把服务人员视为二等公民吗？
if we treat service people as second class citizens,

626
00:27:42,674 --> 00:27:44,061
不会
it won't.

627
00:27:44,081 --> 00:27:44,658
当然
I agree.

628
00:27:44,678 --> 00:27:45,912
不管怎么说
whenever we can,

629
00:27:45,932 --> 00:27:47,764
为了使服务行业得到更多人的尊重
to make service jobs more respectable,

630
00:27:47,784 --> 00:27:49,639
是时候发明一些新的东西了
maybe we have to invent some.

631
00:27:49,659 --> 00:27:52,190
比尔?盖茨在他最近的文章中
Bill gates, in his recent article,

632
00:27:52,210 --> 00:27:55,026
谈到了同情心  是这样吗？
talked about compassion. Right?

633
00:27:55,046 --> 00:27:58,175
也许机器人可以替代人类来照顾
Maybe the people displaced by robots can take care of

634
00:27:58,195 --> 00:28:01,890
流离失所的老人、残疾人
the elderly, take care of the handicapped,

635
00:28:02,710 --> 00:28:05,644
托儿所的孩子
one-on-one nursery homes.

636
00:28:05,664 --> 00:28:08,956
也许这些工作不能快速产生经济价值？
And these are not jobs generating immediate economic value?

637
00:28:08,976 --> 00:28:11,249
但是 他们酝酿出的是爱
But they generate love and they

638
00:28:11,269 --> 00:28:12,785
并帮助创建人与人之间的联系
create human to human connection.

639
00:28:12,805 --> 00:28:14,296
这是一个伟大的愿景
that is a great great vision.

640
00:28:14,316 --> 00:28:17,425
开复 我很喜欢跟你聊天
So, Kai-fu, I love talking to you.

641
00:28:17,445 --> 00:28:18,921
天哪！ 我真的学到了很多
My god. I learned so much.

642
00:28:20,445 --> 00:28:23,211
我知道的就是大概有
One of the things I will do is on behave of

643
00:28:23,231 --> 00:28:24,922
七十万学生
probably seven hundred thousand students

644
00:28:24,942 --> 00:28:26,480
正在收看直播
watching on-line right now,

645
00:28:26,597 --> 00:28:28,024
谁来给我们提问
who sent us questions,

646
00:28:28,044 --> 00:28:30,545
在节目开始之前
I guess I have piece of paper

647
00:28:30,565 --> 00:28:32,335
我准备了一张纸
that I got just before the show

648
00:28:32,355 --> 00:28:34,593
我想要把学生的问题带给你
and I love ask the students' questions to you,

649
00:28:34,613 --> 00:28:36,679
因为对优达学城的学生来说
because you have such a great situation

650
00:28:36,699 --> 00:28:38,660
这是一个非常重要的时刻
to Udacity's students at this point.

651
00:28:38,800 --> 00:28:40,874
有一个叫Josie的学生
There is a person who called Josie

652
00:28:40,894 --> 00:28:42,445
她的问题是关于人工智能（AI）的
and she is asking about AI,

653
00:28:42,465 --> 00:28:45,480
她想要问你在当今社会
and she asks in your opinion, what is the most mature

654
00:28:45,500 --> 00:28:49,930
AI技术中最成熟的应用是什么？
application of AI technology in the industry today?

655
00:28:50,070 --> 00:28:51,008
今天？
today?

656
00:28:52,906 --> 00:28:55,859
最成熟的要数搜索引擎了
Well the most mature that would have to be search engines.

657
00:28:55,879 --> 00:28:58,243
因为我们每天都在用它
Because we use it everyday.

658
00:28:58,263 --> 00:29:00,118
在搜索引擎后面
Behind the search engine,

659
00:29:00,364 --> 00:29:03,188
不仅有匹配字段来帮助获取词语
not only there is a matching words to get words,

660
00:29:03,208 --> 00:29:06,150
在点击后就会出现你想要了解的东西
but there is a learning what things people click on.

661
00:29:06,291 --> 00:29:08,681
它有一定的知识层级
It has a hierarchy of knowledge,

662
00:29:08,798 --> 00:29:14,136
就像当你去谷歌 去百度时
like when you go to Google, go to Baidu,

663
00:29:14,156 --> 00:29:15,694
我要用你的名字作为例子
and I will use your name as an example,

664
00:29:15,714 --> 00:29:18,472
如果你去谷歌搜索谁是 巴斯蒂安?特伦
if you go to Google to search who is Sebastian Thrun,

665
00:29:18,492 --> 00:29:20,241
就会出来有关你的介绍
your biography comes out

666
00:29:20,261 --> 00:29:22,452
因为它有一个和你的信息
because it has a knowledge representation,

667
00:29:22,570 --> 00:29:24,433
相匹配的知识表示
it has a matching,

668
00:29:24,453 --> 00:29:26,976
当你点击该结果时
and when you click on that result,

669
00:29:26,996 --> 00:29:29,986
就会加强搜索并得到更多的正确答案
it will get reinforced and get more answers correctly.

670
00:29:30,186 --> 00:29:32,295
在我看来 搜索引擎已经存在了
So I think search engine

671
00:29:32,315 --> 00:29:35,354
很长时间 并且经证实
has been around for a long time and proven,

672
00:29:35,374 --> 00:29:38,393
我觉得这是最成熟的例子了
I think that's certainly the most mature example.

673
00:29:39,061 --> 00:29:43,285
正如你所言
as you are visionary,

674
00:29:43,695 --> 00:29:46,730
实际上在这样一个亚马逊和新设备及移动设施
how will search engines look ten years from now

675
00:29:46,750 --> 00:29:49,930
引领潮流的时代 搜索引擎将如何应对
in the age of Amazon Echo and new devices

676
00:29:50,688 --> 00:29:52,434
接下来的这十年？
and mobile, actually.

677
00:29:53,899 --> 00:29:56,500
实际上搜索引擎算不上最成熟的技术 
well, search engines actually are not very smart,

678
00:29:56,520 --> 00:29:57,426
你有没有想过？
do you think about it?

679
00:29:57,446 --> 00:29:58,481
你问一个问题
You ask one question;

680
00:29:58,501 --> 00:30:00,798
它会给出十种答案
it gives you you know ten mission answers.

681
00:30:00,938 --> 00:30:02,755
通常你会看到一个页面有十条搜索结果
Usually you look at ten in one page,

682
00:30:02,775 --> 00:30:04,606
即使你忽略第一页
even you ignore the first page,

683
00:30:04,626 --> 00:30:06,059
还是会给你十种答案
give you ten answers,

684
00:30:06,079 --> 00:30:07,734
这是一个非常棘手的问题
it's a very tricky interface.

685
00:30:07,754 --> 00:30:13,183
因为我们不知道正确答案是在哪个页面上
Because we, when the right answer is on that page

686
00:30:13,203 --> 00:30:14,535
而对于这些你本不了解的东西
and something you don't know

687
00:30:14,555 --> 00:30:15,421
你是否该会感到开心呢？
if you are happy,

688
00:30:15,441 --> 00:30:17,343
即使是弹出答案了 也许只有50-60％的
even through the pop-up answers only right

689
00:30:17,363 --> 00:30:19,203
可能性是你想要的
maybe 50-60% at the time.

690
00:30:19,589 --> 00:30:22,179
所以我想十年后
So I think ten years from now,

691
00:30:22,199 --> 00:30:25,179
我想要搜索引擎能够理解你的问题
I like the search engine to understand what you say

692
00:30:25,199 --> 00:30:25,969
并给出正确答案
and give you the answer,

693
00:30:25,989 --> 00:30:28,020
而这个答案正好是你要找的
one answer that you are looking for.

694
00:30:28,184 --> 00:30:29,731
所以你正在建立一个"聊天插件"
so you are building a "chat bar" right now,

695
00:30:29,751 --> 00:30:31,137
你想要在新的搜索引擎上
is that you want to be detective

696
00:30:31,157 --> 00:30:32,520
进行探测吗？
in terms of new search engine?

697
00:30:32,954 --> 00:30:33,891
你指的是哪个系统？
what system?

698
00:30:33,911 --> 00:30:36,606
你正在Sinovations建立
so you are building a "chat bar" right now here,

699
00:30:36,626 --> 00:30:38,188
一个"聊天插件"
in Sinovations,

700
00:30:38,622 --> 00:30:41,587
因此你是想...
that you want to be…

701
00:30:41,751 --> 00:30:42,641
呵呵 聊天插件？
hehe, Chat Bar.

702
00:30:42,661 --> 00:30:44,985
起来像是一种搜索引擎 还是...
is it like a search engine or…

703
00:30:45,005 --> 00:30:47,622
我们说过谈话不会涉及到绝密内容
we said we won't talk about your secret project,

704
00:30:47,642 --> 00:30:49,556
所以还是来谈谈其他吧
so we should talk about my secret project either.

705
00:30:49,576 --> 00:30:51,478
抱歉 我晓得了
sorry.I got it.

706
00:30:51,498 --> 00:30:53,353
下一个问题来自Ted
The next question is from Ted.

707
00:30:55,146 --> 00:30:57,970
我们都觉得AI技术是非常强大的
We all agree that AI is very powerful already.

708
00:30:57,990 --> 00:31:01,670
但Ted抱怨说
But Ted complains, he says at present,

709
00:31:01,951 --> 00:31:04,910
语音识别软件不能完全准确地
I cannot fully depend on voice recognition software to

710
00:31:04,930 --> 00:31:09,446
检测到他所说的话 尤其是中文
accurately detect what I'm saying, especially, in Chinese,

711
00:31:09,466 --> 00:31:12,536
最好是普通话  这是为什么？
it should be mandarin. Why is that?

712
00:31:14,564 --> 00:31:17,552
是这样的 语音识别系统
well, the speech recognition system

713
00:31:17,572 --> 00:31:19,404
最近已经有所改善
has been improved a lot lately.

714
00:31:19,580 --> 00:31:22,556
如果你使用的是kedaxunfei的
So if you use the newest version from

715
00:31:23,271 --> 00:31:26,927
最新版本  ifly科技或百度
kedaxunfei, ifly tech, or baidu,

716
00:31:26,947 --> 00:31:28,744
它的准确性应该是相当高的
the accuracy should be quite high.

717
00:31:29,787 --> 00:31:32,001
一个原因可能是由于你的口音
One possible reason is your accent.

718
00:31:32,021 --> 00:31:35,236
但我觉得当今大多数中国人的口音
But I kind of doubt it because most Chinese people's accent

719
00:31:35,256 --> 00:31:37,283
还是可以的
is pretty moderate today.

720
00:31:38,748 --> 00:31:39,545
这个叫Ted的
the name is Ted.

721
00:31:39,565 --> 00:31:41,678
可能是一个正在学习中文的美国人
He might be an American who is learning Chinese.

722
00:31:41,698 --> 00:31:45,911
这样啊 那么请不要讲外语
well, then. Don't speak foreign language.

723
00:31:46,649 --> 00:31:49,708
可能的话 我会给你们两个解释
It could be. I'll answer twice.

724
00:31:49,728 --> 00:31:51,416
如果作为一个中国人
If you are Chinese,

725
00:31:51,436 --> 00:31:53,736
在语音识别时遇到问题
who has trouble with Chinese speech recognition,

726
00:31:53,876 --> 00:31:57,615
我觉得可能是你故意这样说的
my answer is you'd probably talk deliberately.

727
00:31:57,744 --> 00:31:59,888
语音识别系统的是
The way the speech recognition system works,

728
00:31:59,908 --> 00:32:02,050
针对自然语言的培训
is that they are trained on natural speech,

729
00:32:02,070 --> 00:32:03,608
所以你应该这么说
so you should talk like this.

730
00:32:03,878 --> 00:32:05,307
相反地 你知道
If instead, you know,

731
00:32:05,327 --> 00:32:06,983
如果当你和一个小宝宝说话的时候
when you talk to a little baby, right,

732
00:32:07,003 --> 00:32:08,835
你说喝牛奶
you say drink your milk,

733
00:32:08,855 --> 00:32:09,722
他会说什么？
he will say what?

734
00:32:09,742 --> 00:32:11,808
喝！你！牛奶！
Drink, Your, Milk!

735
00:32:12,171 --> 00:32:14,445
如果你这样做的话 语音识别就会扰乱
If you do that, the speech recognition will get confused,

736
00:32:14,465 --> 00:32:17,878
声音太大 就会造成麻烦
you are too loud, you cause trouble.

737
00:32:17,898 --> 00:32:19,851
所以不要故意这样说话
So don't talk deliberately.

738
00:32:19,871 --> 00:32:23,894
也不要抠字眼
Don't try to talk like, try to emphasize words.

739
00:32:23,914 --> 00:32:26,262
语速就保持你跟其他人
Just talk like you talk to another person

740
00:32:26,282 --> 00:32:27,945
说话那样
at the same pace and speed.

741
00:32:27,965 --> 00:32:30,699
可能这就是原因吧
That's probably the likely reason.

742
00:32:31,754 --> 00:32:35,895
而且 当你切换输入法（IME）
And also, when try to dictate to a IME,

743
00:32:35,915 --> 00:32:37,477
或敲打键盘时
or the keyboard,

744
00:32:37,910 --> 00:32:39,457
它一开始也不是英文的
it doesn't do English

745
00:32:39,477 --> 00:32:41,895
而且不可能一下子就出现你要输入的词语
and it doesn't do proper names very well.

746
00:32:42,032 --> 00:32:43,473
所以你要非常小心
So you got to be careful.

747
00:32:43,493 --> 00:32:46,415
你懂得  "我想要写一封信"
You know. "I'd like a letter to",

748
00:32:46,435 --> 00:32:49,577
并且输入"李开复" 是这样吗？
and stop and type in "Kai-fu Lee". Right?

749
00:32:49,597 --> 00:32:52,012
因为它的字典中没有李开复
Because it doesn't have Kai-fu Lee in its dictionary.

750
00:32:52,032 --> 00:32:56,570
所以 当你敲打的词语是不常见的或英语时
So when you do proper names that are unusual or English,

751
00:32:56,590 --> 00:32:57,550
为什么不说话呢？
don't you speech,

752
00:32:57,570 --> 00:32:59,003
你可以停下来输入语音
you pause and type it in,

753
00:32:59,237 --> 00:33:01,815
或者你将语音添加到它的词汇组里
or you teach it to add it to its vocabulary.

754
00:33:02,038 --> 00:33:05,483
如果你和Ted一样是个外国人
If Ted, you are foreigner,

755
00:33:05,503 --> 00:33:08,061
那么 你正好多了个中文老师
well, get a Chinese teacher

756
00:33:08,081 --> 00:33:09,796
来帮助你提高中文水平
and improve your Chinese.

757
00:33:10,839 --> 00:33:14,038
Sally是优达学城的一名学生 她来自美国
Sally is a Undacity student from the United States.

758
00:33:14,058 --> 00:33:15,269
她问了一个非常有趣的问题
She asked a very interesting question,

759
00:33:15,280 --> 00:33:18,245
我认为你是世界上唯一能够给出答案的人
I think you are the single in the world to answer,

760
00:33:18,519 --> 00:33:21,329
那就是根据你在硅谷多年的经历
which is, you have been in Silicon Valley a lot,

761
00:33:21,610 --> 00:33:23,708
你觉得硅谷的AI技术发展
what's in your opinion the difference between

762
00:33:23,728 --> 00:33:27,071
与中国的AI技术发展
AI technology development in Silicon Valley

763
00:33:27,091 --> 00:33:28,536
有什么区别呢？
and here in China?

764
00:33:29,032 --> 00:33:31,024
好的 这是一个很好的问题
ok, it's a good question.

765
00:33:31,364 --> 00:33:37,482
在我看来 在美国的这样一个大环境下
I think AI technology in Silicon Valley tends to be,

766
00:33:37,634 --> 00:33:41,572
硅谷的AI技术更趋向于提出新算法
invent new algorithm, find new applications,

767
00:33:41,592 --> 00:33:45,157
开拓新的应用领域
build within the American environment.

768
00:33:45,177 --> 00:33:48,134
人们往往对企业有很多的想法
And people tend to think about enterprise a lot.

769
00:33:48,154 --> 00:33:50,095
因为AI技术基本上
Because AI, fundamentally,

770
00:33:50,115 --> 00:33:52,318
是服务于企业的应用程序
is an enterprise application,

771
00:33:52,338 --> 00:33:54,029
而并非为消费者服务
not really a consumer app.

772
00:33:54,150 --> 00:33:57,084
你不也在开发一个能促进银行、公司
You are selling a solution to make a bank, or a company,

773
00:33:57,104 --> 00:33:59,694
或医院更好发展的解决方案吗？
or a hospital do something better.

774
00:33:59,714 --> 00:34:03,795
因此我觉得美国企业家和AI企业家
So I think the American entrepreneurial AI entrepreneurs

775
00:34:03,815 --> 00:34:05,468
更倾向于研究商业应用程序
tend to look at business applications

776
00:34:05,488 --> 00:34:07,065
就像IBM的超级电脑"沃森"？
like IBM Watson

777
00:34:07,085 --> 00:34:10,179
就像沃森努力发掘癌症或肿瘤的方法一样
like Watson style for trying to find cancer or tumors.

778
00:34:10,199 --> 00:34:12,968
这可以说这既是个大问题又是个小问题
So they could be big problems or small ones,

779
00:34:12,988 --> 00:34:15,133
但这正好符合企业数据仓库化
but the kind of fit within the data warehousing

780
00:34:15,153 --> 00:34:16,480
建设的目标
enterprise direction.

781
00:34:17,758 --> 00:34:21,871
在中国 这种问题到处都是
In China, they are all over the place.

782
00:34:21,891 --> 00:34:26,550
反而我觉得在中国这种数据更容易获取
I think in China, the data is more accessible

783
00:34:27,007 --> 00:34:31,694
导致中国的很多的需求
and the Chinese society has a lot of

784
00:34:31,882 --> 00:34:33,312
得不到满足,
needs that are not fulfilled

785
00:34:33,332 --> 00:34:36,429
因为过去200多年来逐美国社会
because the American society and economy which developed

786
00:34:36,449 --> 00:34:40,650
和经济发展缓慢
gradually and slowly over the last 200 years or so.

787
00:34:40,767 --> 00:34:45,631
好在过去35年里中国迅速发展
But the China society rapidly grew up in the last 35 years.

788
00:34:45,651 --> 00:34:50,443
在这个过程中 还有很多差距尚未填补
In that process, there are many gaps that are unfilled,

789
00:34:50,572 --> 00:34:52,259
因此我觉得中国企业家
so I think the Chinese entrepreneurs

790
00:34:52,279 --> 00:34:54,029
更倾向于寻找这些差距
tend to look for those gaps

791
00:34:54,049 --> 00:34:56,220
然后越过差距去解决问题
and jump in and try to solve the problems.

792
00:34:56,466 --> 00:34:59,378
例如对智慧金融的投资
So one example is our investment in smart finance.

793
00:34:59,398 --> 00:35:02,308
这家公司成立于在18个月前
That is company that was founded 18 months ago

794
00:35:02,328 --> 00:35:05,085
这一年他们都在做小额贷款
and this year they are doing small loans.

795
00:35:05,105 --> 00:35:06,099
只要下载一个应用程序
You have an app,

796
00:35:06,119 --> 00:35:07,907
将你的数据上传至这个应用
you upload your data,

797
00:35:07,927 --> 00:35:12,509
那么在八秒内就可以把钱转到手机上
and then you get your money to your phone in eight seconds.

798
00:35:12,673 --> 00:35:14,818
而在美国你根本不需要这些东西
So that's something in the US you don't need

799
00:35:14,838 --> 00:35:16,845
因为大家都有信用卡
because all of you have a credit card.

800
00:35:16,865 --> 00:35:18,064
实际上是
actually it is because of a legal

801
00:35:18,084 --> 00:35:19,162
美国的
(inaudible) in the United States,

802
00:35:19,182 --> 00:35:20,346
银行业务亏损
who is a banking loss 

803
00:35:20,990 --> 00:35:22,525
各种simitations
various simitations,

804
00:35:22,545 --> 00:35:26,252
自从2007年的金融危机以来
since 2007's financial crisis,

805
00:35:26,389 --> 00:35:28,533
很难给你提供在线贷款
make it hard to give you an online loan.

806
00:35:28,553 --> 00:35:30,408
的确是这样
is that right, ok, well.

807
00:35:30,428 --> 00:35:32,373
其实中国是唯一
So, the Chinese opportunities

808
00:35:32,393 --> 00:35:34,565
有这种待遇的国家
then in fact very uniquely Chinese,

809
00:35:34,862 --> 00:35:38,905
所以这个公司在上个月放款150万元
so this company made 1.5 million loans in the last month.

810
00:35:38,925 --> 00:35:39,707
太不可思议了
that's incredible.

811
00:35:39,727 --> 00:35:40,762
你可以看到
so you can see that,

812
00:35:40,782 --> 00:35:43,117
一旦在这种连续性的
when you have these gaps that are created

813
00:35:43,137 --> 00:35:47,231
指数增长中途出现差距
by this continuity in the middle of exponential growth,

814
00:35:47,251 --> 00:35:48,825
所有的中国企业家
all the Chinese entrepreneurs are there

815
00:35:48,845 --> 00:35:50,595
都会抓住这样的机会
smelling for such opportunities.

816
00:35:50,864 --> 00:35:53,559
我刚说什么来着？
what you just said blows my mind.

817
00:35:53,579 --> 00:35:57,520
一个月一百五十万的贷款 简直太疯狂了
Look at the number of 1.5 million loans in a month is crazy.

818
00:35:57,996 --> 00:36:00,762
中国的恐慌（？）
The thing of scare (???) of China,

819
00:36:00,782 --> 00:36:03,457
这个数据的确
and yes the availability of data,

820
00:36:03,703 --> 00:36:06,328
也许是由于中国的发展过程中
maybe it's regulatory opportunities

821
00:36:06,348 --> 00:36:07,957
存在诸多不确定因素
in the course of uncertainties

822
00:36:07,977 --> 00:36:09,332
监管单位已经学会抓住这些机会
that characterize China.

823
00:36:09,352 --> 00:36:11,664
这使得万事皆有可能
That makes things possible.

824
00:36:11,684 --> 00:36:12,859
我得想想
I have to think about it.

825
00:36:12,879 --> 00:36:15,660
我想知道有没有哪条法律
I wonder if it's right to have a law that

826
00:36:15,680 --> 00:36:20,156
规定不能在线借钱 有这回事吗？
doesn't permit borrowing money online, is that really …

827
00:36:20,871 --> 00:36:22,327
在线借钱是可以的
borrowing money online is ok,

828
00:36:22,347 --> 00:36:25,421
但是在美国 这样一个收取大额回报
but a bank putting you pressure and then

829
00:36:25,620 --> 00:36:29,452
并使你感到压力山大的银行是不可能的
charging large returns is impossible in the United States.

830
00:36:29,569 --> 00:36:32,464
信用额度有一定的限制
There is a regulation on the credit rates you can charge.

831
00:36:32,484 --> 00:36:34,694
如果你遵守监管单位的信用额度
If you go to the regulatory credit rates,

832
00:36:34,714 --> 00:36:36,487
企业可能不会
a business may not be,

833
00:36:36,507 --> 00:36:37,571
因为企业每年可能会
because a business might charge

834
00:36:37,591 --> 00:36:39,420
收取30％的费用
30% a year.

835
00:36:39,440 --> 00:36:42,323
这可是一大笔收入
A large amount of returns.

836
00:36:42,343 --> 00:36:46,371
智慧融资的独特之处就是AI技术
well, the unique thing about smart finance is the core AI

837
00:36:46,391 --> 00:36:49,218
拥有较低的贷款不良率业
that does the loan has a very low bad loan rate.

838
00:36:49,238 --> 00:36:52,406
实际上他们的利率也可以非常灵活的
So they actually can have flexible interest rates,

839
00:36:52,426 --> 00:36:53,563
即使有上限
even there is ceiling.

840
00:36:53,583 --> 00:36:54,453
不错呀
that's great.

841
00:36:54,981 --> 00:36:59,188
John问了一个问题 与你创建的
John asked a question about your venture,

842
00:36:59,208 --> 00:37:00,661
创新工场（Sinovation Ventures）有关
Sinovation Ventures.

843
00:37:01,013 --> 00:37:05,454
他想知道在AI行业的所有领域中
He wants to know among all segments of AI industry,

844
00:37:05,653 --> 00:37:07,024
你和Sinovation Ventures
which areas are you

845
00:37:07,044 --> 00:37:09,684
最看好的是哪一个？
and Sinovation Ventures most interested in?

846
00:37:09,704 --> 00:37:13,962
当你给AI创业者做投资时
What characters do you value,

847
00:37:13,982 --> 00:37:16,360
你比较珍惜哪种人才？
when you invest in an AI entrepreneur?

848
00:37:16,724 --> 00:37:22,540
哪些方面你比较关注？
What do you care about?

849
00:37:22,560 --> 00:37:23,255
没错
Right, right.

850
00:37:23,275 --> 00:37:26,638
我们比较看好金融领域
So, our interest area is in the financial area.

851
00:37:26,658 --> 00:37:31,080
不仅包括贷款 还包括投资
That includes not only loans but also investments,

852
00:37:31,100 --> 00:37:33,478
保险 银行等等
insurance, banking and so on.

853
00:37:33,498 --> 00:37:37,506
所有有关金融的这些方面
All of them, all these financial aspects

854
00:37:37,526 --> 00:37:40,195
都是人们发明的游戏 纯数字游戏
are games invented by people, pure numbers.

855
00:37:40,215 --> 00:37:42,340
所以 正好适合AI
So, perfect for AI.

856
00:37:42,360 --> 00:37:46,763
不需要本钱 也不需要动手 非常方便
No rose to rise, no hands to move, any of that.

857
00:37:46,783 --> 00:37:49,482
只需要操作这些数字
So, they are purely frictionless numbers to put through.

858
00:37:49,502 --> 00:37:50,748
这就是为什么我们对其感兴趣的原因
That's why we like that.

859
00:37:50,768 --> 00:37:52,552
我们也做投资
We do investment as well,

860
00:37:52,572 --> 00:37:57,506
包括两个无人驾驶汽车
but we also have two autonomous vehicle investments,

861
00:37:57,526 --> 00:37:59,991
机器人
we have some robotic investments,

862
00:38:00,011 --> 00:38:02,043
以及人脸识别投资项目
we have investment in face recognition,

863
00:38:02,063 --> 00:38:03,496
我们的确投资了很多的其他项目
so we do invest in many other things,

864
00:38:03,516 --> 00:38:05,711
但金融是我们最喜欢的
but financial is our favorite.

865
00:38:05,731 --> 00:38:10,430
现在第二个问题是我们在寻找什么
Now the second part of the question is what do we look for.

866
00:38:11,133 --> 00:38:15,106
我们绝对不会寻找更加智能的算法
We absolutely do not look for smarter algorithms,

867
00:38:15,126 --> 00:38:21,108
因为今天的AI技术是所有已知的技术
because today AI is such that, all the known technologies,

868
00:38:21,128 --> 00:38:23,827
（如深度学习）中做的比较好的
such as deep learning, are good enough

869
00:38:23,847 --> 00:38:29,148
但是在应用领域仍然没有得到充分利用
and still not fully exploited in the application areas,

870
00:38:29,168 --> 00:38:31,621
就像企业家 风投
as entrepreneurs, VCs,

871
00:38:31,820 --> 00:38:33,789
明明现有的AI技术已经完全
it's irresponsible to have

872
00:38:33,809 --> 00:38:34,984
能够解决问题了
invented new algorithms

873
00:38:35,004 --> 00:38:38,051
但是他们还是不负责任地发明新的算法
to solve problems when existing ones are good enough.

874
00:38:38,071 --> 00:38:41,022
我们鼓励大学的研究实验室能够做到这一点
We encourage university's research labs to do that.

875
00:38:41,042 --> 00:38:44,198
因此 我们寻求的是那些能够对这种持续性
So we look for those entrepreneurs who have sharp eye

876
00:38:44,218 --> 00:38:46,796
或机会拥有敏锐眼光的企业家
on this continuity or opportunity

877
00:38:46,816 --> 00:38:49,656
以创造一个快速创造价值的公司
to create a company that rapidly creates value.

878
00:38:49,676 --> 00:38:50,488
所以 这就是生意
so, business.

879
00:38:50,508 --> 00:38:51,882
是生意 一种商业理念
business, business sense.

880
00:38:51,902 --> 00:38:53,411
AI技术的出现是理所当然
take AI for granted,

881
00:38:53,431 --> 00:38:54,199
要关心的是在生意中
and focus on business,

882
00:38:54,219 --> 00:38:56,145
如何赚钱 赚谁的钱
how to make money, who gonna pay,

883
00:38:56,165 --> 00:38:58,395
谁做决定 要赚多少钱...
who makes the decision, how much they gonna pay…

884
00:38:58,415 --> 00:38:59,142
确实如此
exactly.

885
00:39:00,712 --> 00:39:02,774
我们希望技术人员是
And then we want the technologist

886
00:39:02,794 --> 00:39:05,118
一名非常务实的实践人员
to be a very practical practitioner

887
00:39:05,138 --> 00:39:07,786
能够选择正确的算法然后再用于解决问题
that picks a right algorithm and puts it to work.

888
00:39:07,806 --> 00:39:10,622
估计你怎么也不会想到我...
you will never find me…

889
00:39:10,833 --> 00:39:12,556
Sebastian 我们可一直在关注着你呢！
we will always find you Sebastian.

890
00:39:12,576 --> 00:39:14,068
我想要金融民主化
I want the democratization,

891
00:39:14,088 --> 00:39:15,412
那怎么赚钱呢？
so how do you make money?

892
00:39:15,432 --> 00:39:17,041
呵呵  好吧 
Hehe. Ok.

893
00:39:17,061 --> 00:39:19,959
Timmy和Carol问了一个综合性的问题
So, Timmy and Carol asked a combined question.

894
00:39:19,979 --> 00:39:23,749
你曾经说过大约90％的重复性工作
Timmy is a person who mentioned that you once talked about

895
00:39:23,913 --> 00:39:27,651
将被AI技术替代
some 90% of repetitive jobs will be taken over by AI.

896
00:39:27,671 --> 00:39:28,776
你有这样说过？
You said that.

897
00:39:28,917 --> 00:39:30,921
我曾经是说过
I said specifically once.

898
00:39:31,741 --> 00:39:33,815
Timmy 想知道现在最有可能
they know want to know, Timmy wants to know which are

899
00:39:33,835 --> 00:39:36,647
被取代的是哪一类工作
the most likely to be taken over now.

900
00:39:36,788 --> 00:39:39,460
而 Carol 想知道对于长远来说
And carol wants to know which is the safest job

901
00:39:39,480 --> 00:39:41,097
哪一类工作最安全
in the long term.

902
00:39:41,355 --> 00:39:42,902
同样的问题
Kind of the same question,

903
00:39:43,593 --> 00:39:45,832
作为一名本科生
which should I study as an undergraduate

904
00:39:45,960 --> 00:39:48,726
我应该先提问哪一个才能不被你打乱
to have a chance not to be disrupted by Kai-fu.

905
00:39:49,952 --> 00:39:51,897
好的 我们可以举个例子
well, we can give examples.

906
00:39:51,917 --> 00:39:52,565
大家知道吗？
You know.

907
00:39:52,987 --> 00:39:55,296
商人正在被替换
Traders are being replaced right now.

908
00:39:55,316 --> 00:39:57,475
在华尔街 几乎没有生意可做了
In Wall Street there are hardly trades left,

909
00:39:57,495 --> 00:39:58,671
全都是自动化的
that's all automated.

910
00:39:58,691 --> 00:40:00,332
其次 我们重申一遍
Again, we reaffirm the point that

911
00:40:00,352 --> 00:40:02,324
金融是最好的 AI 技术应用程序
finances are the best AI app.

912
00:40:02,523 --> 00:40:04,902
而且你也知道 某些工作 尤其是
But also you know, certain jobs,

913
00:40:04,922 --> 00:40:06,774
有特殊要求的工作 工人是危险的
particular character degree jobs,

914
00:40:06,926 --> 00:40:10,641
这是因为工厂机器人的出现
because of factory robotics.

915
00:40:10,661 --> 00:40:15,387
司机将面临危险 可能不会很快
Drivers will be in danger, probably not soon,

916
00:40:15,559 --> 00:40:17,974
但是会有很大一部分人面临危险
but there are a large percentage of people.

917
00:40:18,453 --> 00:40:20,751
而对于保安人员来说
And security guards,

918
00:40:20,771 --> 00:40:23,434
用相机也可以达到同样的效果
because watching them with cameras would be almost as good

919
00:40:23,454 --> 00:40:27,157
不要认为这是一对一的替换
And don't think this as a replacing one for one.

920
00:40:27,177 --> 00:40:29,489
例如 如果你需要十名保安人员
For example if you have ten security guards,

921
00:40:29,509 --> 00:40:31,024
守卫一个大工厂
guarding a big factory,

922
00:40:31,044 --> 00:40:32,591
或许你还需要另外一个
maybe you still have one

923
00:40:32,611 --> 00:40:34,993
那将是机器人相机
and the other nigh will be robotic cameras.

924
00:40:35,146 --> 00:40:38,134
不仅仅是这类蓝领工作 .
And also don't think of this blue collar job only,

925
00:40:38,154 --> 00:40:40,899
我觉得很多医生也会被替换
because I think many doctor jobs will get be replaced.

926
00:40:41,024 --> 00:40:45,770
例如 我们不想成为放射科医生
For example, we wouldn't want to be a radiologist,

927
00:40:46,239 --> 00:40:50,340
因为你要查看所有有关这些肿瘤
because you will read all these pictures for tumors and

928
00:40:50,360 --> 00:40:51,852
或类似东西的放射片
things like that.

929
00:40:51,872 --> 00:40:53,762
但是 机器操作起来就好多了
But this is much better done by machine.

930
00:40:53,782 --> 00:40:55,916
还没有对它们输入足够的数据和进行培训
They just haven't got enough data and training yet.

931
00:40:55,936 --> 00:40:57,650
但总有一天 它们会做到的
But someday, they will.

932
00:40:57,670 --> 00:41:04,635
所以我觉得很多这些工作 一项项概括..
So I think a lot of these jobs, one generalization…

933
00:41:04,655 --> 00:41:06,202
哪一类工作最安全了？
what's the safest job.

934
00:41:07,245 --> 00:41:10,315
喜剧演员
safest job would be a comedian,

935
00:41:10,335 --> 00:41:14,929
精神科医生 他们是最安全的
psychiatrist, that is pretty safe.

936
00:41:14,949 --> 00:41:16,091
不 未必
no, no, no.

937
00:41:17,631 --> 00:41:20,966
这可能是由于数据还没有达到一定的程度
it's maybe there are not enough data.

938
00:41:20,986 --> 00:41:21,783
额 好吧 
Ok.

939
00:41:27,572 --> 00:41:30,197
任何能够夺人眼球
anything that that requires personal attention,

940
00:41:30,217 --> 00:41:32,646
且对创造力有一定要求的东西
anything that requires creativity,

941
00:41:32,666 --> 00:41:34,951
才是真正富有艺术创造力
true artistic creativity.

942
00:41:36,311 --> 00:41:39,111
经验法则告诉你哪些事情
One rule of thumb is the job you do

943
00:41:39,365 --> 00:41:41,139
可以做
can be done with something.

944
00:41:45,588 --> 00:41:47,674
但不总是真的 只是大致如此
Not always true, but roughly.

945
00:41:48,260 --> 00:41:50,782
问题是你提到全球AI技术方面
the question is you mentioned shortage of

946
00:41:50,802 --> 00:41:53,641
人才欠缺
AI related talents globally.

947
00:41:54,051 --> 00:41:56,981
为什么会有这样的问题以及如何解决呢？
Why there is such a shortage and how to solve it?

948
00:41:57,192 --> 00:41:59,301
你有什么可以解决这个问题的办法吗？
Do you see any solution to this challenge?

949
00:41:59,700 --> 00:42:02,899
好的 这可以为优达学城
ok. This gonna be an advertisement for

950
00:42:02,919 --> 00:42:05,723
深度学习课程做一次广告
Udacity courses of deep learning.

951
00:42:06,321 --> 00:42:08,939
我认为问题在于...
I think the shortage is…

952
00:42:08,959 --> 00:42:15,100
学习AI技术需要扎实的
it does require good fundamentals

953
00:42:15,120 --> 00:42:18,229
计算机科学和数学基础
in computer science and mathematics to learn AI

954
00:42:18,390 --> 00:42:20,182
并不是每个人都可以做到这一点
and not every body has that.

955
00:42:20,358 --> 00:42:23,030
它不只是从教科书中学习
And it is not learning only from the textbook.

956
00:42:23,050 --> 00:42:27,064
还需要一个好老师
Doing, requires a good teacher,

957
00:42:27,084 --> 00:42:29,010
能够一对一
who is on one-on-one.

958
00:42:29,150 --> 00:42:30,896
所以 我认为这是非常好的
So, I think it is very good,

959
00:42:31,256 --> 00:42:33,404
并不是每个大学
and I think not every university

960
00:42:33,424 --> 00:42:35,170
都要进行这样的教学
should be in place to teach that.

961
00:42:35,190 --> 00:42:39,186
在线教学是让你进入状态并且操作自如的
So online teaching as the first step to get you in,

962
00:42:39,206 --> 00:42:40,241
关键一步
and feel comfortable,

963
00:42:40,261 --> 00:42:43,334
如果你想取得进步 那么你可以尝试下一步
if you want to make progress then you can try to the next,

964
00:42:43,354 --> 00:42:46,147
找一个导师 找一份工作 学习...
getting a mentor, getting a job, learning…

965
00:42:48,578 --> 00:42:49,539
这是我的团队
This is my team,

966
00:42:49,559 --> 00:42:52,011
这里我要做一些说明 此处应该加上括号
put here my notes and say, in brackets,

967
00:42:52,164 --> 00:42:53,347
"Sebastian
"Sebastian,

968
00:42:53,367 --> 00:42:56,547
你可以介绍一下 Udacity 是做什么的"
you could introduce what is Udacity doing here",

969
00:42:58,258 --> 00:43:00,092
我要以一个很短的商业广告
and I should start a short commercial

970
00:43:00,112 --> 00:43:02,035
作为开始

971
00:43:02,055 --> 00:43:04,774
预计该广告今天就能推出
the commercial is expected to be launched today,

972
00:43:04,926 --> 00:43:07,492
这是我们深度学习课程的中文版
a Chinese version of our deep learning curriculum,

973
00:43:07,512 --> 00:43:10,067
也是最受欢迎的课程
the most popular curriculum.

974
00:43:10,087 --> 00:43:12,223
这是世界上唯一的深度学习课程
It's the only deep learning curriculum in the world.

975
00:43:12,243 --> 00:43:14,985
目前还没有中文版本
There are no versions of Chinese right now.

976
00:43:15,005 --> 00:43:17,141
它主要由Google完成
and it's done by Google mostly

977
00:43:17,610 --> 00:43:23,862
然后进行出版
and published a most popular deep learning.

978
00:43:23,882 --> 00:43:27,237
深刻学习课程非常受欢迎
Deep learning is here with a crazy demand.

979
00:43:27,257 --> 00:43:29,658
如果你是一名滴滴司机
So you are a DD driver

980
00:43:29,848 --> 00:43:31,329
但是你不喜欢你的工作
and you don't like your job.

981
00:43:32,041 --> 00:43:34,737
（当然我喜欢滴滴 ）
I love DD.

982
00:43:34,757 --> 00:43:37,119
你想要增加薪水
And you want to double your salary,

983
00:43:37,659 --> 00:43:40,260
深度学习就可以帮你实现这一点
deep learning is exactly the magic that the people do

984
00:43:40,280 --> 00:43:41,701
而你所谈论的大部分有关AI技术
and most of the AI exactly

985
00:43:41,721 --> 00:43:44,053
其实就是深度学习
you talk about is about deep learning.

986
00:43:44,073 --> 00:43:47,850
所以有一个中文版的Udacity.com
So there is a Chinese version of Udacity.com.

987
00:43:48,143 --> 00:43:51,612
如果您在接下来的两天内注册
In the next two days we will take 300

988
00:43:51,632 --> 00:43:54,424
我们将收取您300的学费
in your tuition if you enroll right now.

989
00:43:54,694 --> 00:43:56,768
希望你们会喜欢我所讲的内容
Hope guys you will like me for saying this.

990
00:43:57,799 --> 00:43:58,654
成交
Deal.

991
00:43:58,674 --> 00:43:59,107
顺便说一下
By the way,

992
00:43:59,127 --> 00:44:01,068
在移动设备上工作时
works on the mobile device,

993
00:44:01,088 --> 00:44:03,131
滴滴司机在遇到交通堵塞时
DD driver when they are stuck in traffic

994
00:44:03,151 --> 00:44:04,288
可以去那边和...
can go over there and …

995
00:44:04,308 --> 00:44:06,620
不要在开车的同时
don't drive and (inaudible) at the same time.

996
00:44:11,232 --> 00:44:13,963
就我认为的有关自驾车这个关键问题
Give us a layout of the crucial question

997
00:44:13,983 --> 00:44:16,600
请给我们一个规划
that's in my heart about the self-driving car,

998
00:44:16,620 --> 00:44:19,510
特别是中国在未来扮演的角色
specifically China's role in the future.

999
00:44:19,990 --> 00:44:23,064
好的 在参观了美国之后
Ok. I think China will have a big role

1000
00:44:23,084 --> 00:44:26,924
我觉得中国将在自动驾驶上发挥巨大的潜力
in autonomous vehicles when I visited US,

1001
00:44:26,944 --> 00:44:28,502
不仅体现在技术上
not necessarily technology,

1002
00:44:28,522 --> 00:44:30,645
我发现中国在自动驾驶方面
China is significantly behind,

1003
00:44:30,665 --> 00:44:32,247
已经严重落后于美国
in autonomous vehicle technology,

1004
00:44:32,267 --> 00:44:34,331
至少要三到五年才能赶上
at least three to five years behind.

1005
00:44:34,351 --> 00:44:36,178
我们一定会赶上美国的
We will catch up.

1006
00:44:36,198 --> 00:44:39,099
而我认为一个有趣的问题是
And I think the big interesting issue is

1007
00:44:39,119 --> 00:44:42,812
如何协调监管 民族 道德
how will the regulatory, ethnical, moral,

1008
00:44:42,832 --> 00:44:45,921
环境与自动驾驶之间的关系
environment cause this to take off.

1009
00:44:45,941 --> 00:44:47,697
当我去美国的时候
When I go to America,

1010
00:44:47,909 --> 00:44:50,088
我的朋友们（不是电脑专业）
my friends, not computer friends

1011
00:44:50,108 --> 00:44:52,368
只谈谈两件事情
only want to talk about two things,

1012
00:44:52,388 --> 00:44:54,170
一个是有关手摇车的问题
one is the trolley problem,

1013
00:44:54,190 --> 00:45:00,388
另一个是自动驾驶在实际操作前
and the second is how good an autonomous vehicle

1014
00:45:00,408 --> 00:45:02,790
是怎么的好
has to be before it is allowed to be launched.

1015
00:45:02,810 --> 00:45:03,850
这是两个相关的问题
They are related problems,

1016
00:45:03,870 --> 00:45:05,714
第一个是从伦理方面来说
the first one is an ethical problem,

1017
00:45:05,734 --> 00:45:08,293
比如说你现在独自推着手推车
you now, trolley goes alone, you are driving the trolley

1018
00:45:08,313 --> 00:45:11,673
正好前面有一个人
and there is one person ahead of you,

1019
00:45:12,269 --> 00:45:14,047
哦 不对 是五个人
sorry, the five people ahead of you,

1020
00:45:14,067 --> 00:45:18,157
你可以选择继续前进杀死这五个人
if you don't do anything you kill the five people

1021
00:45:18,177 --> 00:45:20,528
或者你可以选择转向
or you could turn and there is one person,

1022
00:45:20,548 --> 00:45:21,917
杀死后面的一个人
there you kill one person.

1023
00:45:21,937 --> 00:45:27,134
那么你是故意选择主动杀死一个人
So do you purposefully and actively kill one person

1024
00:45:27,154 --> 00:45:29,711
还是装作不知道地杀死五个人
or close your eyes and kill five people.

1025
00:45:30,193 --> 00:45:34,221
对我来说 答案是不重要的
To me, I thing the answer is unimportant.

1026
00:45:34,241 --> 00:45:35,234
我有我的答案
I have my answer,

1027
00:45:35,254 --> 00:45:36,399
但我觉得不重要
but I think it is unimportant.

1028
00:45:36,419 --> 00:45:37,671
我认为对于这样一个事实
I think it's a fact

1029
00:45:37,691 --> 00:45:43,040
美国人似乎在无休止地在辩论
that Americans seem to endlessly want to debate this topic

1030
00:45:43,060 --> 00:45:46,455
将技术问题上升到道德上
and turn a technology into a moral problem

1031
00:45:46,475 --> 00:45:47,860
这样会阻碍一个国家的发展
that would slow the country down.

1032
00:45:47,880 --> 00:45:49,203
我觉得这就像教授们
I think this is like

1033
00:45:49,223 --> 00:45:51,570
所研究的哲学问题一样
professors' philosophy problems.

1034
00:45:52,794 --> 00:45:54,208
我不喜欢这个问题
I hate the problem.

1035
00:45:54,228 --> 00:45:55,934
我会选择杀死一个人
I would choose to kill the one person.

1036
00:45:57,347 --> 00:45:58,148
如果你每年
who cares,

1037
00:45:58,168 --> 00:45:59,902
能拯救50万人的话 但是谁会在乎呢？
if you save half a million people every year

1038
00:45:59,922 --> 00:46:00,491
我知道
I know.

1039
00:46:00,511 --> 00:46:03,686
但这种无休止的辩论非常可怕
But this kind of endless debate is terrible.

1040
00:46:03,706 --> 00:46:06,465
另一件事是自动驾驶的系统要达到什么程度
The other thing is how good the system has to be.

1041
00:46:06,485 --> 00:46:08,518
再次有人强调系统
And again there are people who feel like

1042
00:46:08,538 --> 00:46:10,296
一定要贴近完美
it has to be almost perfect,

1043
00:46:10,316 --> 00:46:12,015
有些人觉得一定要比
and then people think it has to be

1044
00:46:12,035 --> 00:46:14,430
人类操作好得多
absolutely a lot better than human,

1045
00:46:14,450 --> 00:46:17,306
有些人又觉得有一点进步就可以了
and then the people think just a little bit better,

1046
00:46:17,459 --> 00:46:18,649
我觉得
and I think

1047
00:46:19,056 --> 00:46:21,765
在中国可能会有更加务实的讨论
China would probably take the more pragmatic rout.

1048
00:46:21,785 --> 00:46:25,144
所以 当科技与人类的同步
so, you think China is going to be breaking ground

1049
00:46:25,164 --> 00:46:26,409
而不是略占优势的时候
when the technology gets

1050
00:46:26,429 --> 00:46:28,732
你觉得中国会打破常规吗？
as good as the human performance but not better.

1051
00:46:30,067 --> 00:46:31,656
我不知道中国每天会发生
I don't know how many accidents kill

1052
00:46:31,676 --> 00:46:32,669
多少起死亡事故
people in China everyday,

1053
00:46:32,689 --> 00:46:36,226
至少有500？
so at least 500 at least?

1054
00:46:36,246 --> 00:46:36,889
也许是1000？
Maybe 1000?

1055
00:46:36,909 --> 00:46:37,808
我不知道
I don't know.

1056
00:46:37,828 --> 00:46:41,957
在美国 每年有4万人死亡
In the US, there are 40,000 deaths a year,

1057
00:46:42,181 --> 00:46:43,394
每天有100人死亡
so 100 people per day.

1058
00:46:44,065 --> 00:46:45,466
假设中国的数字是1000
Let's say the number is 1000 in China.

1059
00:46:45,486 --> 00:46:48,484
那么使用自驾车就如同每年杀800人
So using self-driving car is like

1060
00:46:48,504 --> 00:46:51,825
或一天杀500人一样
killing 800 people's a day or 500 a day.

1061
00:46:51,845 --> 00:46:55,426
你说中国更务实 说的很好
You say China is more pragmatic and say it's fine

1062
00:46:55,446 --> 00:46:57,392
在中国你将不会遇到太多的交通问题
because you will have less traffic

1063
00:46:57,412 --> 00:47:01,376
并且会有更多安静的时间
you have more quiet time than in US

1064
00:47:01,396 --> 00:47:02,813
在美国你每天可能会杀死一个人
where you may kill 1 person a day

1065
00:47:02,833 --> 00:47:04,096
可能你不会这么做
might not do it.

1066
00:47:04,379 --> 00:47:06,711
我不知道中国人会怎样回答这个问题
well, I don't know the answer for China

1067
00:47:06,731 --> 00:47:08,571
中国人口稠密
and China has a lot of people and

1068
00:47:08,591 --> 00:47:10,338
政府官员众多
many different government officials.

1069
00:47:10,358 --> 00:47:12,469
但是我觉得对完美的要求
But I'm saying there will be less obsession

1070
00:47:12,489 --> 00:47:13,745
不会这么高
in demanding perfection.

1071
00:47:14,110 --> 00:47:16,489
所以这一点
So if it's a bit better than people

1072
00:47:16,509 --> 00:47:18,012
不错
maybe it's good enough.

1073
00:47:18,032 --> 00:47:22,369
但在美国有这么多的辩论
But in the US there are so much debate.

1074
00:47:22,499 --> 00:47:25,407
所有这些辩论都会阻碍美国的发展
US will slow this down with all the debates.

1075
00:47:25,427 --> 00:47:28,555
美国的自驾车公司要到中国来吗？
Should self-driving car US company come to China?

1076
00:47:29,497 --> 00:47:33,725
我试过了 这非常难！
It's very difficult to come to China. I've tried but.

1077
00:47:33,745 --> 00:47:35,158
我在中国有公司
well my company is in China,

1078
00:47:35,178 --> 00:47:36,861
是一家自驾汽车公司
we are a self-driving car company now.

1079
00:47:36,881 --> 00:47:38,498
我们也要来中国
so should we come to China.

1080
00:47:39,402 --> 00:47:41,086
好吧 优达学城来中国
well, Udacity should come to China,

1081
00:47:41,106 --> 00:47:44,359
这是一个非常普通的事情
because it's a very universal thing.

1082
00:47:44,505 --> 00:47:46,212
对于自驾汽车公司
The self-driving car company

1083
00:47:46,232 --> 00:47:48,379
我想你需要一个中国合作伙伴
I think you need a Chinese partner to come in.

1084
00:47:48,399 --> 00:47:50,020
所以请跟我谈谈
So please talk to us about

1085
00:47:50,040 --> 00:47:51,492
我可能会投资你的公司
maybe investing in your company.

1086
00:47:51,512 --> 00:47:53,423
凡事参与美国自驾
the audience involved in

1087
00:47:53,443 --> 00:47:56,132
汽车公司的成员
the US self-driving car companies.

1088
00:47:56,152 --> 00:47:59,477
如新加坡等国家
There are countries like Singapore

1089
00:47:59,497 --> 00:48:02,201
都在极力支持这项技术
which actively encourage this technology.

1090
00:48:02,221 --> 00:48:02,778
那不错
that's good.

1091
00:48:02,798 --> 00:48:04,156
你觉得他们会这么做吗？
do you think they will leg up?

1092
00:48:06,040 --> 00:48:07,500
新加坡确实会这样做
I think Singapore does,

1093
00:48:07,520 --> 00:48:10,734
因为这是一项技术
because it's kind of technology

1094
00:48:10,754 --> 00:48:13,440
得益于一个控制力良好的
that benefits from a well-controlled

1095
00:48:13,460 --> 00:48:15,332
管理环境
and managed environment.

1096
00:48:15,352 --> 00:48:17,224
新加坡和中国都是自上而下
Both Singapore and China are relatively

1097
00:48:17,244 --> 00:48:19,516
相对制约的管理模式
managed from top down,

1098
00:48:19,536 --> 00:48:22,603
新加坡有额外的优势 就是它很小
and Singapore has the additional advantage of being small.

1099
00:48:22,623 --> 00:48:24,160
正因为如此才能够控制住
So it's controllable.

1100
00:48:24,180 --> 00:48:27,453
所以我觉得新加坡政府鼓励
So I think the Singaporean government actually

1101
00:48:27,473 --> 00:48:30,877
创新的方式其实是非常明智的
has been very smart in the way they encourage innovation,

1102
00:48:30,897 --> 00:48:32,844
他们通过各种各样的方法
they have various ways to fund

1103
00:48:32,864 --> 00:48:35,450
来为创业公司提供资金援助
start up companies with incentives

1104
00:48:35,470 --> 00:48:37,346
同时 他们也在开发无人驾驶汽车
and also doing the autonomous vehicle.

1105
00:48:37,366 --> 00:48:38,743
他们的治理方式给我留下了深刻的印象
I'm very impressed by their government.

1106
00:48:39,383 --> 00:48:42,730
因为你是最成功、最了不起
since you are one of the most amazing entrepreneurs,

1107
00:48:42,750 --> 00:48:45,502
最具有远见的企业家、科学家和投资商
amazing scientist, amazing investor,

1108
00:48:45,644 --> 00:48:47,871
连我都觉得你是一个传奇
I also think you are an amazing visionary.

1109
00:48:49,482 --> 00:48:53,440
可以给我们说说30年后
Tell us something about how technologies

1110
00:48:53,460 --> 00:48:56,860
会是什么样的呢？
could be 30 years from now?

1111
00:48:57,490 --> 00:48:59,158
你指的是技术还是这个社会？
technology or the world?

1112
00:48:59,302 --> 00:49:00,094
都有
both.

1113
00:49:00,259 --> 00:49:05,833
对于还在投资期间的一些技术而言
Some technologies, maybe on the investment horizon

1114
00:49:05,853 --> 00:49:07,894
这可能是我们的孩子要担心的
but our kids will worry about

1115
00:49:08,356 --> 00:49:09,931
他们可能会有更疯狂的举动
and something crazy to do.

1116
00:49:12,419 --> 00:49:16,872
我不怎么在乎自己在做什么 我们知道就行
I don't think too much about what I'm doing but we do know.

1117
00:49:16,892 --> 00:49:17,749
当你60岁呢？
you will be 60 then.

1118
00:49:18,767 --> 00:49:21,160
好吧 我想我还活着
well I think I would be alive,

1119
00:49:21,180 --> 00:49:24,098
长寿是 AI 技术
because human longevity is one of the great

1120
00:49:24,118 --> 00:49:26,811
最大的成就之一
beneficiary outcomes of AI,

1121
00:49:26,831 --> 00:49:27,783
这样的话我们会活得更久
we will live longer.

1122
00:49:27,803 --> 00:49:30,330
大部分癌症将会消失
Cancer will be largely eradicated.

1123
00:49:30,350 --> 00:49:31,810
到那时我想去哪里就去哪里
So I would be around.

1124
00:49:31,830 --> 00:49:32,522
这很重要
That's important.

1125
00:49:32,542 --> 00:49:33,931
是我们的目标之一
That's for one.

1126
00:49:34,488 --> 00:49:36,229
其实 在接下来的30年里
I think the world actually faces

1127
00:49:36,249 --> 00:49:38,966
世界将面临着非常严峻的挑战
very difficult challenging in the next 30 years,

1128
00:49:39,120 --> 00:49:41,904
因为AI技术正在取代所有的工作
because AI is taking over all these jobs.

1129
00:49:41,924 --> 00:49:44,544
我认为这个结果既好又不好
I think there is a positive negative outcome

1130
00:49:44,564 --> 00:49:49,377
因为人们可能会失去努力工作的
that people could lose their incentive to work hard

1131
00:49:49,397 --> 00:49:51,475
激情和动力
and lose their motivation.

1132
00:49:51,495 --> 00:49:54,555
而且 VR 技术的发展也很好
And also with the VR working so well,

1133
00:49:54,575 --> 00:49:56,131
人们只需坐在家里
people could just sit in home

1134
00:49:56,151 --> 00:49:58,358
整天玩游戏
and let their brain stop developing

1135
00:49:58,378 --> 00:49:59,626
让大脑放松
by playing games all day.

1136
00:49:59,866 --> 00:50:02,152
这个结果可能很糟糕
That's possibly one negative outcome.

1137
00:50:02,172 --> 00:50:04,474
但我还是比较乐观的
But I think I'm more optimistic

1138
00:50:04,494 --> 00:50:07,104
也许还有一个比较好的结果
that maybe a more positive outcome would be

1139
00:50:07,124 --> 00:50:10,362
那就是人类再也不需要
that I thing human race was never

1140
00:50:10,382 --> 00:50:14,011
去做一些重复的工作
put into place to do just repetitive jobs.

1141
00:50:14,142 --> 00:50:17,032
为了追逐金钱和名望
I think we continue to fall into traps

1142
00:50:17,052 --> 00:50:22,399
可能还有他人的尊重
because we chase money and fame,

1143
00:50:23,048 --> 00:50:26,850
人们可能会继续选择这种生活
Or respect, I should say.

1144
00:50:26,870 --> 00:50:31,150
我们的父母告诉我们去当医生 当律师
When our parents tell us, be a doctor, lawyer,

1145
00:50:31,269 --> 00:50:35,083
去商学院 做工程师
go to businees school, be an engineer

1146
00:50:35,237 --> 00:50:37,614
他们实际上是在和我们说追逐声望和金钱
They are telling us to chase after respect and money.

1147
00:50:37,744 --> 00:50:41,346
但是这类工作 很多都会消失
But many of these jobs will be gone. 

1148
00:50:41,366 --> 00:50:44,189
就好像是造物主在说
So this may be our creator's way to tell us that, 

1149
00:50:44,209 --> 00:50:47,369
你看 既然你没办法找到自己的人生方向
look, you cannot seem to find your own path, 

1150
00:50:47,389 --> 00:50:50,390
那我就创造一个 AI
So I'm gonna create an AI to 

1151
00:50:50,508 --> 00:50:54,785
让你根本没有选择可选
remove those possiblities from your consideration. 

1152
00:50:54,805 --> 00:50:58,084
你们人类得找到自己的命运和归宿
So you guys, human kinds, need to find your own destiny. 

1153
00:50:58,104 --> 00:51:01,614
所以我想加入这次大探险
So I'd love to be part of that exploration, 

1154
00:51:01,634 --> 00:51:04,954
看看这次冒险里 是科学与创造性更加重要
to see whether that's something scientific and creative

1155
00:51:04,974 --> 00:51:08,899
还是信仰更加重要
or something that's spiritual and religious,

1156
00:51:08,919 --> 00:51:12,110
这就是继无聊的工作之后人类的真实命运
that's the true destiny after the boring jobs are gone,

1157
00:51:12,130 --> 00:51:13,129
还是有一些事情值得我们去做
there's something worth our work.

1158
00:51:13,149 --> 00:51:15,320
我喜欢这个 因为对我来说
I love this because to me

1159
00:51:15,340 --> 00:51:17,701
最值得尊重的人
the people who get the most respect

1160
00:51:17,974 --> 00:51:20,817
是那些不听从父母安排、自立自强的人
are the ones who don't follow their parent's advice.

1161
00:51:21,066 --> 00:51:21,504
是的
yes.

1162
00:51:21,524 --> 00:51:23,345
那些一路疯狂成长的人
the ones who grow something crazy,

1163
00:51:23,365 --> 00:51:26,934
比如我 父母不会告诉你如何
like, I don't think your parents have told you

1164
00:51:26,954 --> 00:51:30,050
才能成为世界最强的奥赛罗球员
to build the world strongest Othello player,

1165
00:51:30,263 --> 00:51:33,296
如何建立世界最强的语音识别系统
build the world strongest speech recognition system

1166
00:51:33,316 --> 00:51:34,659
包括你的导师也不会告诉你
and your advisor told you

1167
00:51:34,679 --> 00:51:36,365
如何使用专家系统...
to use Expert System…

1168
00:51:36,385 --> 00:51:38,213
是的 但我不同意这一点
yes but I didn't.

1169
00:51:40,866 --> 00:51:43,841
我的父母出生在20世纪初
But I'm deeply grateful for my parents

1170
00:51:43,861 --> 00:51:46,660
我非常感激他们
who were born in the early 1900s,

1171
00:51:46,680 --> 00:51:48,994
是他们教我追求梦想
that they let me pursue my dream

1172
00:51:49,014 --> 00:51:51,091
选择自己的学校、工作
and let me pick the schools and jobs

1173
00:51:51,111 --> 00:51:53,295
事业以及专业
and career and the major.

1174
00:51:53,315 --> 00:51:54,325
我真心地感谢他们
I'm deeply grateful for that.

1175
00:51:54,479 --> 00:51:58,701
这里有很多你的粉丝 全是年轻人
you have a great audience here, really young people.

1176
00:51:58,721 --> 00:52:03,415
如果让你回到年轻时
But if you talked your young self,

1177
00:52:03,435 --> 00:52:05,442
比如30岁 25岁
you are 30, 25 years old,

1178
00:52:05,691 --> 00:52:07,918
你又会给出什么建议？
what's your advice?

1179
00:52:08,894 --> 00:52:12,234
我的建议是跟随你的内心
I would advice follow your heart,

1180
00:52:12,388 --> 00:52:16,105
因为这样你才能认清自己
because this is the way how you differentiate yourself.

1181
00:52:16,425 --> 00:52:18,936
做和其他人一样的事情
Working on things that everybody else is doing,

1182
00:52:18,956 --> 00:52:20,346
你的优势是什么？
what is your edge?

1183
00:52:20,547 --> 00:52:23,094
是与其他人及AI技术对着干？
Against other people as well the AI.

1184
00:52:23,213 --> 00:52:26,186
还有一件事让我感触很深
The other thing I would say is go very deep,

1185
00:52:26,407 --> 00:52:29,925
多台机器同时以五秒的时间
because at the time where five second decisions

1186
00:52:29,945 --> 00:52:32,709
重复做功时
are replicated are done by machines,

1187
00:52:33,053 --> 00:52:35,007
你必须非常努力地去工作
you have to work hard

1188
00:52:35,027 --> 00:52:36,998
才能发现规律
and find the (inaudible) rule

1189
00:52:37,018 --> 00:52:42,506
然后为了生存而成为该方面的专家
and really becoming an expert in order to just survive.

1190
00:52:43,193 --> 00:52:45,497
开复 很高兴能邀请到你
Kai-fu, I've been, I believe, an honor

1191
00:52:45,517 --> 00:52:50,826
并和你畅谈
and pleasure to be with you and ask you questions.

1192
00:52:50,846 --> 00:52:51,182
谢谢
Thanks.

1193
00:52:51,202 --> 00:52:53,374
和你交谈
Listen to your answer,

1194
00:52:53,394 --> 00:52:56,466
感觉我们就像好兄弟一样
it sounds like a brother from a different mother,

1195
00:52:56,486 --> 00:53:00,743
老实说 我非常赞同你的所有观点
because I completely agree with whatever you say, honestly.

1196
00:53:01,987 --> 00:53:03,910
谢谢你 Sebastian 和你交流也很开心
Thank you Sebastian, always pleasure talking to you,

1197
00:53:03,930 --> 00:53:05,818
让我们继续做好哥们
please will continue to call me brother.

1198
00:53:05,838 --> 00:53:06,505
当然没问题
Yes.

1199
00:53:07,085 --> 00:53:08,661
让我们来宣布最后一条消息
We will make one last announcement.

1200
00:53:08,681 --> 00:53:10,378
这里是 Udacity Talk
This is Udacity Talk,

1201
00:53:10,398 --> 00:53:11,339
你可以在线观看我们的节目
you can see us online

1202
00:53:11,359 --> 00:53:12,820
之前我们也采访过 Tony Fodana
and we have people like Tony Fodana

1203
00:53:12,840 --> 00:53:14,407
等人
and interviewed in the past,

1204
00:53:14,537 --> 00:53:16,160
我们会采访更多了不起的人物
and we will interview more fascinating people.

1205
00:53:16,180 --> 00:53:20,501
这是我们在中国做的第一期节目
This is our first edition outside the US, in China.

1206
00:53:20,667 --> 00:53:22,823
每次来中国我都非常高兴
I'm delighted every time I come to China.

1207
00:53:22,843 --> 00:53:25,678
因为这个国家取得了很多的成就
I found this country more accomplishments

1208
00:53:25,698 --> 00:53:28,295
到处都是企业家 能量
I think you have many entrepreneurs, energy,

1209
00:53:28,315 --> 00:53:31,205
创造力 不断推动着你们发展
creativity that blows in your way,

1210
00:53:31,225 --> 00:53:33,515
在许多方面你们都创建了一个新的硅谷
I think you are the new Silicon Valley in many ways.

1211
00:53:33,535 --> 00:53:36,714
非常荣幸能与开复博士
This's great pleasure to be with Kai-fu,

1212
00:53:36,734 --> 00:53:41,656
创新工厂、滴滴等许多公司合作
Sinovation Ventures, DD with many other companies

1213
00:53:41,905 --> 00:53:45,009
并向您学习如何建立一个卓越的企业
and learning from you how to build a company.

1214
00:53:45,672 --> 00:53:47,094
最后一次
One last time,

1215
00:53:47,114 --> 00:53:51,750
如果你喜欢 Udacity 的深度学习课程
if you like this Udacity courses on deep learning,

1216
00:53:52,449 --> 00:53:57,173
我们有中文的在线课程 cn.udacity.com
we have courses on line in Chinese, cn.udacity.com,

1217
00:53:57,493 --> 00:54:00,549
最近两天报名 会有折扣
for two days if you sign up you get a rebate.

1218
00:54:00,569 --> 00:54:02,232
提醒一下 数学上
We recommended you to know

1219
00:54:02,252 --> 00:54:03,926
有个自由的模式
there is a liberal pattern in math.

1220
00:54:03,946 --> 00:54:08,012
深度学习的特点之一就
One thing about deep learning is

1221
00:54:08,522 --> 00:54:10,334
是软件工程师们非常努力
software engineers work really hard,

1222
00:54:10,354 --> 00:54:14,087
你必须考虑每一个可能的规则
you have to think every possible rule.

1223
00:54:14,407 --> 00:54:16,918
深度学习是一种使之变得容易的方式
Deep learning is a way to make it easy.

1224
00:54:16,938 --> 00:54:18,998
只是举个例子 由你来制定规则
You just put example and you make rules.

1225
00:54:19,018 --> 00:54:21,213
在计算机程序领域
I think it's an area of computer programing

1226
00:54:21,233 --> 00:54:22,872
软件工程师已经过时了
where software engineers are obsolete

1227
00:54:22,892 --> 00:54:25,811
拥有非常简单技能的人们
and people with very simple skills can do

1228
00:54:25,831 --> 00:54:28,772
可以通过最近在皮肤癌检测
amazing stuff by the recent

1229
00:54:28,792 --> 00:54:32,196
的进展中取得惊人的成就
progress on skin cancer detection.

1230
00:54:32,216 --> 00:54:33,803
所以 去看看我们的网站
So, go to our website.

1231
00:54:33,823 --> 00:54:37,618
我想特别感谢一下李开复博士
I want to thank, specifically Kai-fu Lee of course,

1232
00:54:37,638 --> 00:54:41,669
感谢创新工厂、斗鱼直播
his company Sinovation Ventures, Douyu TV,

1233
00:54:41,689 --> 00:54:45,543
品玩、机器之心和果壳网MOOC学院
Ping West, Synced and Guokr MOOC

1234
00:54:46,112 --> 00:54:49,038
今晚为我们带来的伟大贡献
who was holding us tonight for you contributions.

1235
00:54:49,058 --> 00:54:51,715
再次感谢你参与我们的在线访谈
Thank you once more online great questions.

1236
00:54:51,735 --> 00:54:54,879
感谢创新工厂的观众
Thank youaudience here in Sinovation Ventures

1237
00:54:54,899 --> 00:54:58,303
希望下一次的 Udacity Talks 能继续见到您！
and see you for the next Udacity Talks!

1238
00:57:06,654 --> 00:57:08,574
再见！
bye bye

